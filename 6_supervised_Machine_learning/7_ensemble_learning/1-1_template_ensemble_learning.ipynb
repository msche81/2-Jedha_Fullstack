{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# import ensemble methods\n",
    "from sklearn.ensemble import (\n",
    "    BaggingClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    VotingClassifier,\n",
    "    StackingClassifier,\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# import base estimators\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    ConfusionMatrixDisplay,\n",
    "    RocCurveDisplay,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", category=DeprecationWarning\n",
    ")  # to avoid deprecation warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "...Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import dataset\n",
    "print(\"Loading dataset...\")\n",
    "dataset = pd.read_csv(\"src/Data.csv\")\n",
    "print(\"...Done.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 10\n",
      "Number of columns: 4\n",
      "\n",
      "   Country   Age  Salary Purchased\n",
      "0   France  44.0   72000        No\n",
      "1    Spain  27.0   48000       Yes\n",
      "2  Germany  30.0   54000        No\n",
      "3    Spain  38.0   61000        No\n",
      "4  Germany  40.0   69000       Yes\n",
      "\n",
      "       Country        Age        Salary Purchased\n",
      "count       10   9.000000     10.000000        10\n",
      "unique       3        NaN           NaN         2\n",
      "top     France        NaN           NaN        No\n",
      "freq         4        NaN           NaN         5\n",
      "mean       NaN  38.777778  64300.000000       NaN\n",
      "std        NaN   7.693793  11681.419244       NaN\n",
      "min        NaN  27.000000  48000.000000       NaN\n",
      "25%        NaN  35.000000  55000.000000       NaN\n",
      "50%        NaN  38.000000  64000.000000       NaN\n",
      "75%        NaN  44.000000  71250.000000       NaN\n",
      "max        NaN  50.000000  83000.000000       NaN\n",
      "\n",
      "Country       0.0\n",
      "Age          10.0\n",
      "Salary        0.0\n",
      "Purchased     0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Basic statistics and dataset overview\n",
    "print(f\"Number of rows: {dataset.shape[0]}\")\n",
    "print(f\"Number of columns: {dataset.shape[1]}\")\n",
    "print()\n",
    "\n",
    "# Display first few rows of the dataset\n",
    "print(dataset.head())\n",
    "print()\n",
    "\n",
    "# Basic statistics\n",
    "data_desc = dataset.describe(include=\"all\")\n",
    "print(data_desc)\n",
    "print()\n",
    "\n",
    "# Percentage of missing values for each column\n",
    "missing_values = (dataset.isnull().sum() / dataset.shape[0]) * 100\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating labels from features...\n",
      "...Done.\n",
      "\n",
      "Y (Target variable):\n",
      "0     No\n",
      "1    Yes\n",
      "2     No\n",
      "3     No\n",
      "4    Yes\n",
      "Name: Purchased, dtype: object\n",
      "\n",
      "X (Features):\n",
      "   Country   Age  Salary\n",
      "0   France  44.0   72000\n",
      "1    Spain  27.0   48000\n",
      "2  Germany  30.0   54000\n",
      "3    Spain  38.0   61000\n",
      "4  Germany  40.0   69000\n"
     ]
    }
   ],
   "source": [
    "# Separate target variable Y from features X\n",
    "print(\"Separating labels from features...\")\n",
    "target_variable = \"Purchased\"\n",
    "\n",
    "X = dataset.drop(columns=[target_variable], axis= 1)\n",
    "Y = dataset[target_variable]\n",
    "\n",
    "print(\"...Done.\")\n",
    "print()\n",
    "\n",
    "print(\"Y (Target variable):\")\n",
    "print(Y.head())\n",
    "print(\"\\nX (Features):\")\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numeric_features:\n",
      "['Age', 'Salary']\n",
      "\n",
      "categorical_features:\n",
      "['Country']\n"
     ]
    }
   ],
   "source": [
    "numeric_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(exclude=[\"int64\", \"float64\"]).columns.tolist()\n",
    "print(\"numeric_features:\")\n",
    "print(numeric_features)\n",
    "print(\"\\ncategorical_features:\")\n",
    "print(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(drop=\"first\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing preprocessings on train set...\n",
      "X_train done\n",
      "[[ 1.61706195e+00  1.46885753e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 8.22715727e-01  1.09777773e+00  1.00000000e+00  0.00000000e+00]\n",
      " [-1.41104234e-15 -1.00500778e+00  0.00000000e+00  1.00000000e+00]\n",
      " [ 2.26956063e-01  8.50391200e-01  0.00000000e+00  0.00000000e+00]\n",
      " [ 4.25542617e-01  1.08231607e-01  0.00000000e+00  1.00000000e+00]]\n",
      "\n",
      "Label Encoding on train set:\n",
      "y_train done\n",
      "[0 1 0 1 0]\n",
      "\n",
      "Performing preprocessings on test set...\n",
      "[[2.80858127 2.82948345 1.         0.        ]\n",
      " [2.41140816 2.33471038 0.         0.        ]]\n",
      "\n",
      "Encoding labels...\n",
      "8     No\n",
      "7    Yes\n",
      "Name: Purchased, dtype: object\n",
      "...Done\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# Preprocessings on train set\n",
    "print(\"Performing preprocessings on train set...\")\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "print(\"X_train done\")\n",
    "print(X_train[0:5])\n",
    "print()\n",
    "\n",
    "# Label encoding\n",
    "print(\"Label Encoding on train set:\")\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "print(\"y_train done\")\n",
    "print(y_train[0:5])\n",
    "print()\n",
    "\n",
    "# Preprocessings on test set\n",
    "print(\"Performing preprocessings on test set...\")\n",
    "X_test = preprocessor.transform(X_test)\n",
    "print(X_test[0:5,:])\n",
    "print()\n",
    "\n",
    "# Label encoding\n",
    "print(\"Encoding labels...\")\n",
    "print(y_test[0:5])\n",
    "Y_test = encoder.transform(y_test)\n",
    "print(\"...Done\")\n",
    "print(Y_test[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging with logistic regression as base estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[CV] END ..................estimator__C=0.01, n_estimators=5; total time=   0.0s\n",
      "[CV] END ..................estimator__C=0.01, n_estimators=5; total time=   0.0s\n",
      "[CV] END .................estimator__C=0.01, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..................estimator__C=0.01, n_estimators=5; total time=   0.0s\n",
      "[CV] END .................estimator__C=0.01, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..................estimator__C=0.05, n_estimators=5; total time=   0.0s\n",
      "[CV] END .................estimator__C=0.01, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..................estimator__C=0.05, n_estimators=5; total time=   0.0s\n",
      "[CV] END ..................estimator__C=0.05, n_estimators=5; total time=   0.0s\n",
      "[CV] END .................estimator__C=0.01, n_estimators=20; total time=   0.1s\n",
      "[CV] END .................estimator__C=0.01, n_estimators=30; total time=   0.0s\n",
      "[CV] END .................estimator__C=0.05, n_estimators=10; total time=   0.0s\n",
      "[CV] END .................estimator__C=0.01, n_estimators=20; total time=   0.1s\n",
      "[CV] END .................estimator__C=0.05, n_estimators=10; total time=   0.0s\n",
      "[CV] END .................estimator__C=0.01, n_estimators=20; total time=   0.1s\n",
      "[CV] END ...................estimator__C=0.1, n_estimators=5; total time=   0.0s\n",
      "[CV] END .................estimator__C=0.05, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...................estimator__C=0.1, n_estimators=5; total time=   0.0s\n",
      "[CV] END .................estimator__C=0.01, n_estimators=30; total time=   0.1s\n",
      "[CV] END ...................estimator__C=0.1, n_estimators=5; total time=   0.0s\n",
      "[CV] END .................estimator__C=0.01, n_estimators=30; total time=   0.1s\n",
      "[CV] END ..................estimator__C=0.1, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..................estimator__C=0.1, n_estimators=10; total time=   0.0s\n",
      "[CV] END .................estimator__C=0.05, n_estimators=20; total time=   0.1s\n",
      "[CV] END ...................estimator__C=0.5, n_estimators=5; total time=   0.0s\n",
      "[CV] END ..................estimator__C=0.1, n_estimators=20; total time=   0.0s\n",
      "[CV] END .................estimator__C=0.05, n_estimators=20; total time=   0.0s\n",
      "[CV] END ...................estimator__C=0.5, n_estimators=5; total time=   0.0s\n",
      "[CV] END ..................estimator__C=0.1, n_estimators=20; total time=   0.0s\n",
      "[CV] END ...................estimator__C=0.5, n_estimators=5; total time=   0.0s\n",
      "[CV] END ..................estimator__C=0.1, n_estimators=10; total time=   0.0s\n",
      "[CV] END .................estimator__C=0.05, n_estimators=30; total time=   0.1s\n",
      "[CV] END ..................estimator__C=0.5, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..................estimator__C=0.5, n_estimators=10; total time=   0.0s\n",
      "[CV] END .................estimator__C=0.05, n_estimators=20; total time=   0.0s\n",
      "[CV] END .................estimator__C=0.05, n_estimators=30; total time=   0.0s\n",
      "[CV] END ..................estimator__C=0.1, n_estimators=30; total time=   0.1s\n",
      "[CV] END ..................estimator__C=0.5, n_estimators=10; total time=   0.0s\n",
      "[CV] END ..................estimator__C=0.5, n_estimators=20; total time=   0.0s\n",
      "[CV] END ..................estimator__C=0.1, n_estimators=20; total time=   0.1s\n",
      "[CV] END ..................estimator__C=0.5, n_estimators=20; total time=   0.0s\n",
      "[CV] END ..................estimator__C=0.1, n_estimators=30; total time=   0.1s\n",
      "[CV] END ..................estimator__C=0.5, n_estimators=30; total time=   0.0s\n",
      "[CV] END ..................estimator__C=0.5, n_estimators=20; total time=   0.0s\n",
      "[CV] END .................estimator__C=0.05, n_estimators=30; total time=   0.1s\n",
      "[CV] END ..................estimator__C=0.1, n_estimators=30; total time=   0.0s\n",
      "[CV] END ..................estimator__C=0.5, n_estimators=30; total time=   0.0s\n",
      "[CV] END ..................estimator__C=0.5, n_estimators=30; total time=   0.0s\n",
      "Grid search completed.\n",
      "Best hyperparameters: {'estimator__C': 0.5, 'n_estimators': 10}\n",
      "Best cross-validation accuracy: 0.5000\n",
      "Training accuracy: 0.7500\n",
      "Test accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Initialize logistic regression with increased max_iter to handle convergence warnings\n",
    "logistic_regression = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Initialize BaggingClassifier with logistic regression as the base estimator\n",
    "model = BaggingClassifier(estimator=logistic_regression)\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "params = {\n",
    "    \"estimator__C\": [0.01, 0.05, 0.1, 0.5],  # C is a hyperparameter of LogisticRegression\n",
    "    \"n_estimators\": [5, 10, 20, 30]  # n_estimators is a hyperparameter of BaggingClassifier\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV with 3-fold cross-validation\n",
    "gridsearch = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=params,\n",
    "    cv=3,\n",
    "    n_jobs=-1,  # Utilize all available cores for parallel processing\n",
    "    verbose=2   # Increase verbosity for detailed output\n",
    ")\n",
    "\n",
    "# Perform grid search\n",
    "print(\"Performing grid search...\")\n",
    "gridsearch.fit(X_train, y_train)\n",
    "print(\"Grid search completed.\")\n",
    "\n",
    "# Display results\n",
    "print(f\"Best hyperparameters: {gridsearch.best_params_}\")\n",
    "print(f\"Best cross-validation accuracy: {gridsearch.best_score_:.4f}\")\n",
    "print(f\"Training accuracy: {gridsearch.score(X_train, y_train):.4f}\")\n",
    "print(f\"Test accuracy: {gridsearch.score(X_test, Y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging with decision tree as base estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search...\n",
      "Fitting 3 folds for each of 135 candidates, totalling 405 fits\n",
      "Grid search complete.\n",
      "Best hyperparameters: {'estimator__max_depth': 1, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'n_estimators': 4}\n",
      "Best cross-validation accuracy: 0.6111\n",
      "Training set accuracy: 0.6250\n",
      "Test set accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marie-sophiechenevier/Library/CloudStorage/Dropbox/8-Jedha/GitHub/2-Jedha_Fullstack/.venv/lib/python3.12/site-packages/numpy/ma/core.py:2881: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    }
   ],
   "source": [
    "# Initialisation du modèle de base et de l'algorithme d'ensemble\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "# Initialize BaggingClassifier with decision_tree as the base estimator\n",
    "model = BaggingClassifier(estimator=decision_tree)\n",
    "\n",
    "# Grille d'hyperparamètres pour la recherche par grille\n",
    "params = {\n",
    "    \"estimator__max_depth\": [1, 2, 3],\n",
    "    \"estimator__min_samples_leaf\": [1, 2, 3],\n",
    "    \"estimator__min_samples_split\": [2, 3, 4],\n",
    "    \"n_estimators\": [2, 4, 6, 8, 10],\n",
    "}\n",
    "\n",
    "# Exécution de la recherche par grille avec validation croisée\n",
    "print(\"Running grid search...\")\n",
    "gridsearch = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=params,\n",
    "    cv=3, verbose=1,\n",
    "    n_jobs=-1  # Parallel processing for efficiency\n",
    ")\n",
    "gridsearch.fit(X_train, y_train)\n",
    "\n",
    "# Affichage des meilleurs paramètres et performances\n",
    "print(\"Grid search complete.\")\n",
    "print(f\"Best hyperparameters: {gridsearch.best_params_}\")\n",
    "print(f\"Best cross-validation accuracy: {gridsearch.best_score_:.4f}\")\n",
    "\n",
    "# Évaluation des performances sur les ensembles d'entraînement et de test\n",
    "train_accuracy = gridsearch.score(X_train, y_train)\n",
    "test_accuracy = gridsearch.score(X_test, Y_test)\n",
    "print(f\"Training set accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test set accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for NaN or infinite values in X_train and X_test...\n",
      "NaN values in X_train: 0\n",
      "NaN values in X_test: 0\n",
      "Infinite values in X_train: 0\n",
      "Infinite values in X_test: 0\n"
     ]
    }
   ],
   "source": [
    "# vérifier si X_train et X_test contiennent des valeurs manquantes ou infinies :\n",
    "print(\"Checking for NaN or infinite values in X_train and X_test...\")\n",
    "print(\"NaN values in X_train:\", np.isnan(X_train).sum())\n",
    "print(\"NaN values in X_test:\", np.isnan(X_test).sum())\n",
    "print(\"Infinite values in X_train:\", np.isinf(X_train).sum())\n",
    "print(\"Infinite values in X_test:\", np.isinf(X_test).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of X_train: float64\n",
      "Data type of X_test: float64\n"
     ]
    }
   ],
   "source": [
    "# vérifier le type de données\n",
    "print(\"Data type of X_train:\", X_train.dtype)\n",
    "print(\"Data type of X_test:\", X_test.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting\n",
    "Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaboost with logistic regression as base estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search...\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Grid search complete.\n",
      "Best hyperparameters: {'estimator__C': 0.5, 'n_estimators': 5}\n",
      "Best cross-validation accuracy: 0.6111\n",
      "Training set accuracy: 0.8750\n",
      "Test set accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Initialisation du modèle de base et de l'algorithme d'ensemble\n",
    "logistic_regression = LogisticRegression(max_iter=1000)  # max_iter augmenté pour éviter les avertissements de convergence\n",
    "model = AdaBoostClassifier(estimator=logistic_regression, algorithm='SAMME')  # Utilisation explicite de SAMME pour éviter l'avertissement\n",
    "\n",
    "# Grille d'hyperparamètres pour la recherche par grille\n",
    "params = {\n",
    "    \"estimator__C\": [0.01, 0.05, 0.1, 0.5],  # 'estimator__' nécessaire pour les hyperparamètres de LogisticRegression\n",
    "    \"n_estimators\": [5, 10, 20, 30],         # Hyperparamètre de AdaBoost pour le nombre d'estimateurs\n",
    "}\n",
    "\n",
    "# Exécution de la recherche par grille avec validation croisée\n",
    "print(\"Running grid search...\")\n",
    "gridsearch = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=params,\n",
    "    cv=3,\n",
    "    verbose=1,  # Affiche la progression de la recherche\n",
    "    n_jobs=-1   # Utilise tous les cœurs de processeur pour accélérer la recherche\n",
    ")\n",
    "gridsearch.fit(X_train, y_train)\n",
    "\n",
    "# Affichage des meilleurs paramètres et performances\n",
    "print(\"Grid search complete.\")\n",
    "print(f\"Best hyperparameters: {gridsearch.best_params_}\")\n",
    "print(f\"Best cross-validation accuracy: {gridsearch.best_score_:.4f}\")\n",
    "\n",
    "# Évaluation des performances sur les ensembles d'entraînement et de test\n",
    "train_accuracy = gridsearch.score(X_train, y_train)\n",
    "test_accuracy = gridsearch.score(X_test, Y_test)\n",
    "print(f\"Training set accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test set accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaboost with decision tree as base estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search...\n",
      "Fitting 3 folds for each of 135 candidates, totalling 405 fits\n",
      "Grid search complete.\n",
      "Best hyperparameters: {'estimator__max_depth': 1, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'n_estimators': 2}\n",
      "Best cross-validation accuracy: 0.3889\n",
      "Training set accuracy: 0.6250\n",
      "Test set accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Initialisation du modèle de base et de l'algorithme d'ensemble avec SAMME pour éviter l'avertissement de dépréciation\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "model = AdaBoostClassifier(estimator=decision_tree, algorithm='SAMME')\n",
    "\n",
    "# Grille d'hyperparamètres pour la recherche par grille\n",
    "params = {\n",
    "    \"estimator__max_depth\": [1, 2, 3],           # Profondeur de l'arbre de décision\n",
    "    \"estimator__min_samples_leaf\": [1, 2, 3],    # Nombre min. d'échantillons par feuille\n",
    "    \"estimator__min_samples_split\": [2, 3, 4],   # Nombre min. d'échantillons pour diviser un nœud\n",
    "    \"n_estimators\": [2, 4, 6, 8, 10],            # Nombre d'estimateurs dans AdaBoost\n",
    "}\n",
    "\n",
    "# Exécution de la recherche par grille avec validation croisée\n",
    "print(\"Running grid search...\")\n",
    "gridsearch = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=params,\n",
    "    cv=3,\n",
    "    verbose=1,  # Affiche la progression de la recherche\n",
    "    n_jobs=-1   # Utilise tous les cœurs pour accélérer la recherche\n",
    ")\n",
    "gridsearch.fit(X_train, y_train)\n",
    "\n",
    "# Affichage des meilleurs paramètres et performances\n",
    "print(\"Grid search complete.\")\n",
    "print(f\"Best hyperparameters: {gridsearch.best_params_}\")\n",
    "print(f\"Best cross-validation accuracy: {gridsearch.best_score_:.4f}\")\n",
    "\n",
    "# Évaluation des performances sur les ensembles d'entraînement et de test\n",
    "train_accuracy = gridsearch.score(X_train, y_train)\n",
    "test_accuracy = gridsearch.score(X_test, Y_test)\n",
    "print(f\"Training set accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test set accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn's GradientBoosting\n",
    "Boosting with logistic regression as base estimator: forbidden ⛔️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search...\n",
      "Fitting 3 folds for each of 135 candidates, totalling 405 fits\n",
      "Grid search complete.\n",
      "Best hyperparameters: {'max_depth': 1, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 2}\n",
      "Best cross-validation accuracy: 0.3889\n",
      "Training set accuracy: 0.7500\n",
      "Test set accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Initialisation du modèle de gradient boosting\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "# Grille d'hyperparamètres pour la recherche par grille\n",
    "params = {\n",
    "    \"max_depth\": [1, 2, 3],                 # Profondeur maximale des arbres\n",
    "    \"min_samples_leaf\": [1, 2, 3],          # Nombre min. d'échantillons dans une feuille\n",
    "    \"min_samples_split\": [2, 3, 4],         # Nombre min. d'échantillons pour diviser un nœud\n",
    "    \"n_estimators\": [2, 4, 6, 8, 10],       # Nombre d'arbres dans l'ensemble\n",
    "}\n",
    "\n",
    "# Exécution de la recherche par grille avec validation croisée\n",
    "print(\"Running grid search...\")\n",
    "gridsearch = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=params,\n",
    "    cv=3,\n",
    "    verbose=1,  # Affiche la progression de la recherche\n",
    "    n_jobs=-1   # Utilise tous les cœurs pour accélérer la recherche\n",
    ")\n",
    "gridsearch.fit(X_train, y_train)\n",
    "\n",
    "# Affichage des meilleurs paramètres et performances\n",
    "print(\"Grid search complete.\")\n",
    "print(f\"Best hyperparameters: {gridsearch.best_params_}\")\n",
    "print(f\"Best cross-validation accuracy: {gridsearch.best_score_:.4f}\")\n",
    "\n",
    "# Évaluation des performances sur les ensembles d'entraînement et de test\n",
    "train_accuracy = gridsearch.score(X_train, y_train)\n",
    "test_accuracy = gridsearch.score(X_test, Y_test)\n",
    "print(f\"Training set accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test set accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "XGBoost is a different library, but it provides a scikit-learn API that allows to train a model as if it had been built from a scikit-learn class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search...\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "Grid search complete.\n",
      "Best hyperparameters: {'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 2}\n",
      "Best cross-validation accuracy: 0.3889\n",
      "Training set accuracy: 0.5000\n",
      "Test set accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Initialisation du modèle XGBoost\n",
    "xgboost = XGBClassifier(eval_metric='logloss')  # Spécifie eval_metric pour éviter un avertissement\n",
    "\n",
    "# Grille d'hyperparamètres pour la recherche par grille\n",
    "params = {\n",
    "    \"max_depth\": [2, 4, 6],               # Profondeur maximale des arbres\n",
    "    \"min_child_weight\": [1, 2, 3],        # Contraintes similaires à min_samples_leaf de scikit-learn\n",
    "    \"n_estimators\": [2, 4, 6, 8],         # Nombre d'arbres dans l'ensemble\n",
    "}\n",
    "\n",
    "# Exécution de la recherche par grille avec validation croisée\n",
    "print(\"Running grid search...\")\n",
    "gridsearch = GridSearchCV(\n",
    "    estimator=xgboost,\n",
    "    param_grid=params,\n",
    "    cv=3,\n",
    "    verbose=1,  # Affiche la progression de la recherche\n",
    "    n_jobs=-1   # Utilise tous les cœurs pour accélérer la recherche\n",
    ")\n",
    "gridsearch.fit(X_train, y_train)\n",
    "\n",
    "# Affichage des meilleurs paramètres et performances\n",
    "print(\"Grid search complete.\")\n",
    "print(f\"Best hyperparameters: {gridsearch.best_params_}\")\n",
    "print(f\"Best cross-validation accuracy: {gridsearch.best_score_:.4f}\")\n",
    "\n",
    "# Évaluation des performances sur les ensembles d'entraînement et de test\n",
    "train_accuracy = gridsearch.score(X_train, y_train)\n",
    "test_accuracy = gridsearch.score(X_test, Y_test)\n",
    "print(f\"Training set accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test set accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting\n",
    "Contrary to bagging and boosting, the voting classifier is meant to mix different base estimators. Let's see an example with three base estimators:\n",
    "\n",
    "logistic regression\n",
    "\n",
    "decision tree\n",
    "\n",
    "SVM with rbf kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search...\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Grid search complete.\n",
      "Best hyperparameters: {'C': 10.0}\n",
      "Best cross-validation accuracy: 0.6111\n",
      "Training set accuracy: 0.7500\n",
      "Test set accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Initialisation du modèle de régression logistique avec un nombre d'itérations plus élevé pour éviter les avertissements de convergence\n",
    "logreg = LogisticRegression(max_iter=1000)  # Augmenté pour des modèles complexes\n",
    "\n",
    "# Grille d'hyperparamètres pour la recherche par grille\n",
    "params = {\"C\": [0.1, 1.0, 10.0]}  # Valeurs de régularisation à tester\n",
    "\n",
    "# Exécution de la recherche par grille avec validation croisée\n",
    "print(\"Running grid search...\")\n",
    "logreg_opt = GridSearchCV(\n",
    "    estimator=logreg,\n",
    "    param_grid=params,\n",
    "    cv=3,\n",
    "    verbose=1,  # Affiche la progression de la recherche\n",
    "    n_jobs=-1   # Utilise tous les cœurs disponibles pour accélérer la recherche\n",
    ")\n",
    "logreg_opt.fit(X_train, y_train)\n",
    "\n",
    "# Affichage des meilleurs paramètres et performances\n",
    "print(\"Grid search complete.\")\n",
    "print(f\"Best hyperparameters: {logreg_opt.best_params_}\")\n",
    "print(f\"Best cross-validation accuracy: {logreg_opt.best_score_:.4f}\")\n",
    "\n",
    "# Évaluation des performances sur les ensembles d'entraînement et de test\n",
    "train_accuracy = logreg_opt.score(X_train, y_train)\n",
    "test_accuracy = logreg_opt.score(X_test, Y_test)\n",
    "print(f\"Training set accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test set accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voting with decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search...\n",
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "Grid search complete.\n",
      "Best hyperparameters: {'max_depth': 1, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "Best cross-validation accuracy: 0.5000\n",
      "Training set accuracy: 0.6250\n",
      "Test set accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Initialisation du modèle d'arbre de décision\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Grille d'hyperparamètres pour la recherche par grille\n",
    "params = {\n",
    "    \"max_depth\": [1, 2, 3],               # Profondeur maximale de l'arbre\n",
    "    \"min_samples_leaf\": [1, 2, 3],        # Nombre min. d'échantillons par feuille\n",
    "    \"min_samples_split\": [2, 3, 4],       # Nombre min. d'échantillons pour diviser un nœud\n",
    "}\n",
    "\n",
    "# Exécution de la recherche par grille avec validation croisée\n",
    "print(\"Running grid search...\")\n",
    "dt_opt = GridSearchCV(\n",
    "    estimator=dt,\n",
    "    param_grid=params,\n",
    "    cv=3,\n",
    "    verbose=1,  # Affiche la progression de la recherche\n",
    "    n_jobs=-1   # Utilise tous les cœurs pour accélérer la recherche\n",
    ")\n",
    "dt_opt.fit(X_train, y_train)\n",
    "\n",
    "# Affichage des meilleurs paramètres et performances\n",
    "print(\"Grid search complete.\")\n",
    "print(f\"Best hyperparameters: {dt_opt.best_params_}\")\n",
    "print(f\"Best cross-validation accuracy: {dt_opt.best_score_:.4f}\")\n",
    "\n",
    "# Évaluation des performances sur les ensembles d'entraînement et de test\n",
    "train_accuracy = dt_opt.score(X_train, y_train)\n",
    "test_accuracy = dt_opt.score(X_test, Y_test)\n",
    "print(f\"Training set accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test set accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voting with SVM with rbf kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search...\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "Grid search complete.\n",
      "Best hyperparameters: {'C': 0.1, 'gamma': 10.0}\n",
      "Best cross-validation accuracy: 0.5556\n",
      "Training set accuracy: 1.0000\n",
      "Test set accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Initialisation du modèle SVM avec un noyau radial de base (RBF) et des probabilités activées\n",
    "svm = SVC(kernel=\"rbf\", probability=True)\n",
    "\n",
    "# Grille d'hyperparamètres pour la recherche par grille\n",
    "params = {\n",
    "    \"C\": [0.1, 1.0, 10.0],         # Paramètre de régularisation\n",
    "    \"gamma\": [0.1, 1.0, 10.0],     # Coefficient du noyau RBF\n",
    "}\n",
    "\n",
    "# Exécution de la recherche par grille avec validation croisée\n",
    "print(\"Running grid search...\")\n",
    "svm_opt = GridSearchCV(\n",
    "    estimator=svm,\n",
    "    param_grid=params,\n",
    "    cv=3,\n",
    "    verbose=1,  # Affiche la progression de la recherche\n",
    "    n_jobs=-1   # Utilise tous les cœurs pour accélérer la recherche\n",
    ")\n",
    "svm_opt.fit(X_train, y_train)\n",
    "\n",
    "# Affichage des meilleurs paramètres et performances\n",
    "print(\"Grid search complete.\")\n",
    "print(f\"Best hyperparameters: {svm_opt.best_params_}\")\n",
    "print(f\"Best cross-validation accuracy: {svm_opt.best_score_:.4f}\")\n",
    "\n",
    "# Évaluation des performances sur les ensembles d'entraînement et de test\n",
    "train_accuracy = svm_opt.score(X_train, y_train)\n",
    "test_accuracy = svm_opt.score(X_test, Y_test)\n",
    "print(f\"Training set accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test set accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VOTING CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 0.7500\n",
      "Test set accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Initialisation du VotingClassifier avec un vote soft basé sur les probabilités des modèles optimisés\n",
    "voting = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"logistic\", logreg_opt.best_estimator_),  # Meilleur modèle de régression logistique\n",
    "        (\"tree\", dt_opt.best_estimator_),          # Meilleur modèle d'arbre de décision\n",
    "        (\"svm\", svm_opt.best_estimator_)           # Meilleur modèle SVM\n",
    "    ],\n",
    "    voting=\"soft\"  # Utilise les probabilités pour le vote\n",
    ")\n",
    "\n",
    "# Entraînement du VotingClassifier sur l'ensemble d'entraînement\n",
    "voting.fit(X_train, y_train)\n",
    "\n",
    "# Évaluation des performances du VotingClassifier sur les ensembles d'entraînement et de test\n",
    "train_accuracy = voting.score(X_train, y_train)\n",
    "test_accuracy = voting.score(X_test, Y_test)\n",
    "\n",
    "print(f\"Training set accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test set accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As voting, the stacking concerns different base estimators, but this time they will be used to estimate independent probabilities that will be plugged as input of a final estimator. The default final estimator is LogisticRegression, but it can be changed using the final_estimator parameter.\n",
    "\n",
    "In the examples below, the models logreg, tree and svm have already been optimized through a grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training stacking classifier...\n",
      "...Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logistic</th>\n",
       "      <th>tree</th>\n",
       "      <th>svm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.427365</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.543419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.436559</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.456637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.132388</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.543419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.801265</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.456637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.278854</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.543419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.669254</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.456637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.653240</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.543419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.601132</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.456637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   logistic      tree       svm\n",
       "0  0.427365  0.400000  0.543419\n",
       "1  0.436559  0.400000  0.456637\n",
       "2  0.132388  0.400000  0.543419\n",
       "3  0.801265  0.400000  0.456637\n",
       "4  0.278854  0.400000  0.543419\n",
       "5  0.669254  0.666667  0.456637\n",
       "6  0.653240  0.666667  0.543419\n",
       "7  0.601132  0.666667  0.456637"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 0.2500\n",
      "Test set accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Initialisation du StackingClassifier avec les modèles optimisés\n",
    "print(\"Training stacking classifier...\")\n",
    "stacking = StackingClassifier(\n",
    "    estimators=[\n",
    "        (\"logistic\", logreg_opt.best_estimator_),  # Meilleur modèle de régression logistique\n",
    "        (\"tree\", dt_opt.best_estimator_),          # Meilleur modèle d'arbre de décision\n",
    "        (\"svm\", svm_opt.best_estimator_)           # Meilleur modèle SVM\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(),  # Estimateur final par défaut (régression logistique)\n",
    "    cv=3  # Validation croisée à 3 plis pour le niveau 1\n",
    ")\n",
    "\n",
    "# Entraînement et transformation des données avec le StackingClassifier\n",
    "preds = stacking.fit_transform(X_train, y_train)\n",
    "predictions = pd.DataFrame(preds, columns=stacking.named_estimators_.keys())\n",
    "print(\"...Done.\")\n",
    "display(predictions)\n",
    "\n",
    "# Évaluation des performances sur les ensembles d'entraînement et de test\n",
    "train_accuracy = stacking.score(X_train, y_train)\n",
    "test_accuracy = stacking.score(X_test, Y_test)\n",
    "\n",
    "print(f\"Training set accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test set accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TIP\n",
    "\n",
    "Check for correlations\n",
    "\n",
    "As the predictions used in stacking are supposed to be independent, it's a good practice to check the correlation matrix of the outputs from the different estimators. If some predictions have a strong correlation, it's better to re-train the stacking model by dropping one of the estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorscale": [
          [
           0,
           "#440154"
          ],
          [
           0.1111111111111111,
           "#482878"
          ],
          [
           0.2222222222222222,
           "#3e4989"
          ],
          [
           0.3333333333333333,
           "#31688e"
          ],
          [
           0.4444444444444444,
           "#26828e"
          ],
          [
           0.5555555555555556,
           "#1f9e89"
          ],
          [
           0.6666666666666666,
           "#35b779"
          ],
          [
           0.7777777777777778,
           "#6ece58"
          ],
          [
           0.8888888888888888,
           "#b5de2b"
          ],
          [
           1,
           "#fde725"
          ]
         ],
         "reversescale": false,
         "showscale": false,
         "type": "heatmap",
         "x": [
          "logistic",
          "tree",
          "svm"
         ],
         "y": [
          "logistic",
          "tree",
          "svm"
         ],
         "z": [
          [
           1,
           0.53,
           -0.61
          ],
          [
           0.53,
           1,
           -0.26
          ],
          [
           -0.61,
           -0.26,
           1
          ]
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "1.0",
          "x": "logistic",
          "xref": "x",
          "y": "logistic",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0.53",
          "x": "tree",
          "xref": "x",
          "y": "logistic",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.61",
          "x": "svm",
          "xref": "x",
          "y": "logistic",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0.53",
          "x": "logistic",
          "xref": "x",
          "y": "tree",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "1.0",
          "x": "tree",
          "xref": "x",
          "y": "tree",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.26",
          "x": "svm",
          "xref": "x",
          "y": "tree",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.61",
          "x": "logistic",
          "xref": "x",
          "y": "svm",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.26",
          "x": "tree",
          "xref": "x",
          "y": "svm",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "1.0",
          "x": "svm",
          "xref": "x",
          "y": "svm",
          "yref": "y"
         }
        ],
        "margin": {
         "b": 50,
         "l": 100,
         "r": 100,
         "t": 50
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Correlation Matrix of Base Model Predictions"
        },
        "xaxis": {
         "dtick": 1,
         "gridcolor": "rgb(0, 0, 0)",
         "side": "top",
         "ticks": "",
         "title": {
          "text": "Models"
         }
        },
        "yaxis": {
         "dtick": 1,
         "ticks": "",
         "ticksuffix": "  ",
         "title": {
          "text": "Models"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calcul de la matrice de corrélation et arrondi des valeurs\n",
    "corr_matrix = predictions.corr().round(2)\n",
    "\n",
    "# Création d'une heatmap annotée pour la matrice de corrélation\n",
    "fig = ff.create_annotated_heatmap(\n",
    "    z=corr_matrix.values,                     # Valeurs de la matrice de corrélation\n",
    "    x=corr_matrix.columns.tolist(),           # Noms des colonnes (modèles de base)\n",
    "    y=corr_matrix.index.tolist(),             # Noms des lignes (modèles de base)\n",
    "    colorscale=\"Viridis\"                      # Palette de couleurs pour une meilleure lisibilité\n",
    ")\n",
    "\n",
    "# Affichage de la heatmap\n",
    "fig.update_layout(\n",
    "    title=\"Correlation Matrix of Base Model Predictions\",\n",
    "    xaxis_title=\"Models\",\n",
    "    yaxis_title=\"Models\",\n",
    "    margin=dict(l=100, r=100, t=50, b=50)     # Ajustement des marges pour une meilleure visualisation\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training stacking classifier without the tree estimator due to correlation with SVM...\n",
      "...Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logistic</th>\n",
       "      <th>svm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.427365</td>\n",
       "      <td>0.544746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.436559</td>\n",
       "      <td>0.459113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.132388</td>\n",
       "      <td>0.544746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.801265</td>\n",
       "      <td>0.459113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.278854</td>\n",
       "      <td>0.544746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.669254</td>\n",
       "      <td>0.459113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.653240</td>\n",
       "      <td>0.544746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.601132</td>\n",
       "      <td>0.459113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   logistic       svm\n",
       "0  0.427365  0.544746\n",
       "1  0.436559  0.459113\n",
       "2  0.132388  0.544746\n",
       "3  0.801265  0.459113\n",
       "4  0.278854  0.544746\n",
       "5  0.669254  0.459113\n",
       "6  0.653240  0.544746\n",
       "7  0.601132  0.459113"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 0.1250\n",
      "Test set accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Réentraîner le StackingClassifier en supprimant l'arbre de décision\n",
    "print(\"Training stacking classifier without the tree estimator due to correlation with SVM...\")\n",
    "stacking = StackingClassifier(\n",
    "    estimators=[\n",
    "        (\"logistic\", logreg_opt.best_estimator_),  # Meilleur modèle de régression logistique\n",
    "        (\"svm\", svm_opt.best_estimator_)           # Meilleur modèle SVM\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(),          # Estimateur final par défaut\n",
    "    cv=3                                           # Validation croisée à 3 plis pour le niveau 1\n",
    ")\n",
    "\n",
    "# Entraînement et transformation des données avec le StackingClassifier\n",
    "preds = stacking.fit_transform(X_train, y_train)\n",
    "predictions = pd.DataFrame(preds, columns=stacking.named_estimators_.keys())\n",
    "print(\"...Done.\")\n",
    "display(predictions)\n",
    "\n",
    "# Évaluation des performances sur les ensembles d'entraînement et de test\n",
    "train_accuracy = stacking.score(X_train, y_train)\n",
    "test_accuracy = stacking.score(X_test, Y_test)\n",
    "\n",
    "print(f\"Training set accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test set accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training stacking classifier with DecisionTree as the final estimator...\n",
      "...Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logistic</th>\n",
       "      <th>svm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.427365</td>\n",
       "      <td>0.544746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.436559</td>\n",
       "      <td>0.459113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.132388</td>\n",
       "      <td>0.544746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.801265</td>\n",
       "      <td>0.459113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.278854</td>\n",
       "      <td>0.544746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.669254</td>\n",
       "      <td>0.459113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.653240</td>\n",
       "      <td>0.544746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.601132</td>\n",
       "      <td>0.459113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   logistic       svm\n",
       "0  0.427365  0.544746\n",
       "1  0.436559  0.459113\n",
       "2  0.132388  0.544746\n",
       "3  0.801265  0.459113\n",
       "4  0.278854  0.544746\n",
       "5  0.669254  0.459113\n",
       "6  0.653240  0.544746\n",
       "7  0.601132  0.459113"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 0.6250\n",
      "Test set accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Entraînement du StackingClassifier avec un arbre de décision comme estimateur final\n",
    "print(\"Training stacking classifier with DecisionTree as the final estimator...\")\n",
    "stacking = StackingClassifier(\n",
    "    estimators=[\n",
    "        (\"logistic\", logreg_opt.best_estimator_),  # Meilleur modèle de régression logistique\n",
    "        (\"svm\", svm_opt.best_estimator_)           # Meilleur modèle SVM\n",
    "    ],\n",
    "    final_estimator=DecisionTreeClassifier(),      # Arbre de décision comme estimateur final\n",
    "    cv=3                                           # Validation croisée à 3 plis pour le niveau 1\n",
    ")\n",
    "\n",
    "# Entraînement et transformation des données avec le StackingClassifier\n",
    "preds = stacking.fit_transform(X_train, y_train)\n",
    "predictions = pd.DataFrame(preds, columns=stacking.named_estimators_.keys())\n",
    "print(\"...Done.\")\n",
    "display(predictions)\n",
    "\n",
    "# Évaluation des performances sur les ensembles d'entraînement et de test\n",
    "train_accuracy = stacking.score(X_train, y_train)\n",
    "test_accuracy = stacking.score(X_test, Y_test)\n",
    "\n",
    "print(f\"Training set accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test set accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
