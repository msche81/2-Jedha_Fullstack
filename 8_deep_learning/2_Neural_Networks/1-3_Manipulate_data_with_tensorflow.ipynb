{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a constant tensor named tensor1 containing the values [0,1,2,3,4,5,6,7] and a variable tensor named tensor2 containing the values [0,1,2,0,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor1: tf.Tensor([0 1 2 3 4 5 6 7], shape=(8,), dtype=int32)\n",
      "tensor2: <tf.Variable 'Variable:0' shape=(6,) dtype=int32, numpy=array([0, 1, 2, 0, 1, 2], dtype=int32)>\n"
     ]
    }
   ],
   "source": [
    "tensor1 = tf.constant([0,1,2,3,4,5,6,7])\n",
    "tensor2 = tf.Variable([0,1,2,0,1,2])\n",
    "print('tensor1:', tensor1)\n",
    "print('tensor2:', tensor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape tensor1 so it has 2 columns and 4 rows, and tensor2 so it has 2 rows and 3 columns. Has this operation changed the nature of tensor2? How could you change it back to its former nature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor1: tf.Tensor(\n",
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [6 7]], shape=(4, 2), dtype=int32)\n",
      "tensor2: tf.Tensor(\n",
      "[[0 1 2]\n",
      " [0 1 2]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tensor1 = tf.reshape(tensor1, [4,2])\n",
    "tensor2 = tf.reshape(tensor2, [2,3])\n",
    "print('tensor1:', tensor1)\n",
    "print('tensor2:', tensor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor2: <tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=\n",
      "array([[0, 1, 2],\n",
      "       [0, 1, 2]], dtype=int32)>\n"
     ]
    }
   ],
   "source": [
    "tensor2 = tf.Variable(tensor2)\n",
    "print('tensor2:', tensor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a tensorflow function to create tensor3 with the same shape as tensor2 but filled with 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor3 tf.Tensor(\n",
      "[[1 1 1]\n",
      " [1 1 1]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tensor3 = tf.ones_like(tensor2)\n",
    "print('tensor3', tensor3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the value of tensor2 by substracting the values in tensor3, use a method so that it is an in place operation. Why would not you be able to do that with tensor1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=int32, numpy=\n",
       "array([[-1,  0,  1],\n",
       "       [-1,  0,  1]], dtype=int32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2.assign_sub(tensor3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you multiply tensor1 and tensor2 pointwise? How about with a matrix multiplication? Display the result of the possible operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor1*tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=int32, numpy=\n",
       "array([[ -1,   0,   1],\n",
       "       [ -5,   0,   5],\n",
       "       [ -9,   0,   9],\n",
       "       [-13,   0,  13]], dtype=int32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(tensor1, tensor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular data\n",
    "\n",
    "This part of the exercise will let you deal with tabular data in order to make batch datasets ready to be fed to deep learning models.\n",
    "\n",
    "Using the sklearn.datasets module, load the mnist dataset thanks to the load_digits function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function gives you a Data Bunch object, which works basically like a dictionnary. Create an object data containing the value of the data key and an object target containing the value of the target key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data [[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n",
      "target [0 1 2 ... 8 9 8]\n"
     ]
    }
   ],
   "source": [
    "data = digits.data\n",
    "target = digits.target\n",
    "print('data', data)\n",
    "print('target', target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the shape of data and target? Can you understand what these objects represent using the DESCR key of the Data Bunch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      ":Number of Instances: 1797\n",
      ":Number of Attributes: 64\n",
      ":Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      ":Missing Attribute Values: None\n",
      ":Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      ":Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. dropdown:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you visualize the first image in data ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly import express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "xaxis": "x",
         "yaxis": "y",
         "z": [
          [
           0,
           0,
           5,
           13,
           9,
           1,
           0,
           0
          ],
          [
           0,
           0,
           13,
           15,
           10,
           15,
           5,
           0
          ],
          [
           0,
           3,
           15,
           2,
           0,
           11,
           8,
           0
          ],
          [
           0,
           4,
           12,
           0,
           0,
           8,
           8,
           0
          ],
          [
           0,
           5,
           8,
           0,
           0,
           9,
           8,
           0
          ],
          [
           0,
           4,
           11,
           0,
           1,
           12,
           7,
           0
          ],
          [
           0,
           2,
           14,
           5,
           10,
           12,
           0,
           0
          ],
          [
           0,
           0,
           6,
           13,
           10,
           0,
           0,
           0
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorscale": [
          [
           0,
           "rgb(0, 0, 0)"
          ],
          [
           0.09090909090909091,
           "rgb(16, 16, 16)"
          ],
          [
           0.18181818181818182,
           "rgb(38, 38, 38)"
          ],
          [
           0.2727272727272727,
           "rgb(59, 59, 59)"
          ],
          [
           0.36363636363636365,
           "rgb(81, 80, 80)"
          ],
          [
           0.45454545454545453,
           "rgb(102, 101, 101)"
          ],
          [
           0.5454545454545454,
           "rgb(124, 123, 122)"
          ],
          [
           0.6363636363636364,
           "rgb(146, 146, 145)"
          ],
          [
           0.7272727272727273,
           "rgb(171, 171, 170)"
          ],
          [
           0.8181818181818182,
           "rgb(197, 197, 195)"
          ],
          [
           0.9090909090909091,
           "rgb(224, 224, 223)"
          ],
          [
           1,
           "rgb(254, 254, 253)"
          ]
         ]
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_image = data[0,:].reshape([8,8])\n",
    "px.imshow(first_image, color_continuous_scale='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pixel values from those images is encoded in integers between 0 and 255, it is always better to feed your deep learning models with reasonnably scaled data to avoid the network not being able to learn. To do this we'll divide the value in each pixel by 255. Do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technique 1: Split the data with sklearn\n",
    "\n",
    "Most of the time when you will be dealing with data you want to feed to a deap learning model, you will have a pandas DataFrame or numpy array at some points that contains some representation of your data and the associated values of the target variable. In those cases, it's easier to just split the data in a train and validation set using sklearn. (Remember that for very large datasets or for training and evaluating deep learning models we most of the time use the three way hold out method, where on set serves as the training set, one as the validation set to control for overfitting, and the last one is the test set against which we will evaluate the model).\n",
    "\n",
    "Split the data and target into three different parts, one containing the train set (60%), another with the validation set (20%), and a third with the test set (20%), using sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valtest, y_train, y_valtest = train_test_split(\n",
    "    data,\n",
    "    target,\n",
    "    train_size=0.6,\n",
    "    random_state=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_val, y_test, y_val = train_test_split(\n",
    "    X_valtest,\n",
    "    y_valtest,\n",
    "    train_size=0.5,\n",
    "    random_state=0\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (1078, 64) y_train (1078,)\n",
      "X_val (360, 64) y_val (360,)\n",
      "X_test (359, 64) y_test (359,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train\", X_train.shape, \"y_train\", y_train.shape)\n",
    "print(\"X_val\", X_val.shape, \"y_val\", y_val.shape)\n",
    "print(\"X_test\", X_test.shape, \"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Form three tensor slice datasets using the training validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: <_TensorSliceDataset element_spec=(TensorSpec(shape=(64,), dtype=tf.float64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>\n",
      "val: <_TensorSliceDataset element_spec=(TensorSpec(shape=(64,), dtype=tf.float64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>\n",
      "test: <_TensorSliceDataset element_spec=(TensorSpec(shape=(64,), dtype=tf.float64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "train = tf.data.Dataset.from_tensor_slices((X_train,y_train))\n",
    "test = tf.data.Dataset.from_tensor_slices((X_test,y_test))\n",
    "val = tf.data.Dataset.from_tensor_slices((X_val,y_val))\n",
    "\n",
    "print(\"train:\",train)\n",
    "print(\"val:\", val)\n",
    "print(\"test:\", test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle these tensor slice datasets and arrange them in batches of 8 observations, then display one batch from each of these batch datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tf.Tensor(\n",
      "[[0.         0.         0.01960784 0.04705882 0.00392157 0.02352941\n",
      "  0.         0.         0.         0.         0.04313725 0.04705882\n",
      "  0.         0.0627451  0.00784314 0.         0.         0.\n",
      "  0.0627451  0.01960784 0.         0.04705882 0.01568627 0.\n",
      "  0.         0.01176471 0.05882353 0.         0.         0.03137255\n",
      "  0.01568627 0.         0.         0.02745098 0.04705882 0.\n",
      "  0.         0.01568627 0.02745098 0.         0.         0.00784314\n",
      "  0.05882353 0.00392157 0.00392157 0.04705882 0.01960784 0.\n",
      "  0.         0.         0.0627451  0.04313725 0.04705882 0.05882353\n",
      "  0.01176471 0.         0.         0.         0.01568627 0.04705882\n",
      "  0.04705882 0.01176471 0.         0.        ]\n",
      " [0.         0.         0.04313725 0.0627451  0.03921569 0.\n",
      "  0.         0.         0.         0.02352941 0.05882353 0.0627451\n",
      "  0.0627451  0.02352941 0.         0.         0.         0.\n",
      "  0.         0.00784314 0.04313725 0.04705882 0.         0.\n",
      "  0.         0.         0.         0.         0.03529412 0.03137255\n",
      "  0.         0.         0.         0.         0.         0.01568627\n",
      "  0.05882353 0.00784314 0.         0.         0.         0.00392157\n",
      "  0.03529412 0.05882353 0.03529412 0.01176471 0.         0.\n",
      "  0.         0.         0.0627451  0.0627451  0.0627451  0.0627451\n",
      "  0.02745098 0.         0.         0.         0.03921569 0.05098039\n",
      "  0.03137255 0.01568627 0.00392157 0.        ]\n",
      " [0.         0.02745098 0.0627451  0.0627451  0.0627451  0.04313725\n",
      "  0.00784314 0.         0.         0.01960784 0.0627451  0.04705882\n",
      "  0.03137255 0.02352941 0.00392157 0.         0.         0.03529412\n",
      "  0.0627451  0.00392157 0.         0.         0.         0.\n",
      "  0.         0.00784314 0.0627451  0.05882353 0.01176471 0.\n",
      "  0.         0.         0.         0.         0.01960784 0.0627451\n",
      "  0.05490196 0.00392157 0.         0.         0.         0.\n",
      "  0.         0.00784314 0.0627451  0.03921569 0.         0.\n",
      "  0.         0.00392157 0.02745098 0.05098039 0.0627451  0.01176471\n",
      "  0.         0.         0.         0.01568627 0.05882353 0.0627451\n",
      "  0.02352941 0.         0.         0.        ]\n",
      " [0.         0.         0.00784314 0.04705882 0.01568627 0.\n",
      "  0.         0.         0.         0.00392157 0.04705882 0.0627451\n",
      "  0.0627451  0.01176471 0.         0.         0.         0.02745098\n",
      "  0.0627451  0.02352941 0.01568627 0.05098039 0.         0.\n",
      "  0.         0.03137255 0.0627451  0.02352941 0.         0.05098039\n",
      "  0.01960784 0.         0.         0.00392157 0.0627451  0.01960784\n",
      "  0.         0.02745098 0.03529412 0.         0.         0.\n",
      "  0.0627451  0.03137255 0.         0.03137255 0.04705882 0.\n",
      "  0.         0.         0.05098039 0.05490196 0.05490196 0.0627451\n",
      "  0.03921569 0.         0.         0.         0.01568627 0.05490196\n",
      "  0.05882353 0.02745098 0.         0.        ]\n",
      " [0.         0.00392157 0.05098039 0.0627451  0.0627451  0.03921569\n",
      "  0.         0.         0.         0.03137255 0.05882353 0.03137255\n",
      "  0.05882353 0.05882353 0.         0.         0.         0.01176471\n",
      "  0.03137255 0.01960784 0.0627451  0.02352941 0.         0.\n",
      "  0.         0.         0.         0.01568627 0.0627451  0.03529412\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.02352941 0.0627451  0.01960784 0.         0.         0.\n",
      "  0.         0.         0.         0.01960784 0.0627451  0.\n",
      "  0.         0.         0.03137255 0.02352941 0.02352941 0.05098039\n",
      "  0.04705882 0.         0.         0.00392157 0.05882353 0.0627451\n",
      "  0.0627451  0.05490196 0.01176471 0.        ]\n",
      " [0.         0.         0.00392157 0.04705882 0.03921569 0.01176471\n",
      "  0.         0.         0.         0.         0.02745098 0.0627451\n",
      "  0.0627451  0.02745098 0.         0.         0.         0.\n",
      "  0.04705882 0.0627451  0.0627451  0.01176471 0.         0.\n",
      "  0.         0.         0.05490196 0.0627451  0.0627451  0.00784314\n",
      "  0.         0.         0.         0.00392157 0.05882353 0.0627451\n",
      "  0.0627451  0.01960784 0.         0.         0.         0.\n",
      "  0.05882353 0.0627451  0.05882353 0.00784314 0.         0.\n",
      "  0.         0.         0.04313725 0.0627451  0.0627451  0.03137255\n",
      "  0.         0.         0.         0.         0.00392157 0.02745098\n",
      "  0.04705882 0.03921569 0.         0.        ]\n",
      " [0.         0.         0.00392157 0.05098039 0.00784314 0.\n",
      "  0.         0.         0.         0.         0.03137255 0.05882353\n",
      "  0.00392157 0.         0.         0.         0.         0.\n",
      "  0.05490196 0.02745098 0.         0.         0.         0.\n",
      "  0.         0.         0.05490196 0.02352941 0.         0.\n",
      "  0.         0.         0.         0.         0.0627451  0.01960784\n",
      "  0.03529412 0.03529412 0.01176471 0.         0.         0.\n",
      "  0.04705882 0.0627451  0.05098039 0.03529412 0.05490196 0.00392157\n",
      "  0.         0.         0.03137255 0.05882353 0.         0.00392157\n",
      "  0.05490196 0.01960784 0.         0.         0.00392157 0.04313725\n",
      "  0.0627451  0.0627451  0.05098039 0.00392157]\n",
      " [0.         0.         0.01568627 0.05098039 0.04313725 0.02745098\n",
      "  0.         0.         0.         0.         0.05490196 0.0627451\n",
      "  0.05098039 0.0627451  0.00784314 0.         0.         0.01960784\n",
      "  0.0627451  0.01568627 0.         0.01960784 0.02745098 0.\n",
      "  0.         0.03137255 0.05490196 0.         0.         0.01568627\n",
      "  0.03137255 0.         0.         0.02352941 0.03529412 0.\n",
      "  0.         0.01568627 0.03137255 0.         0.         0.00784314\n",
      "  0.05490196 0.00392157 0.         0.03137255 0.02352941 0.\n",
      "  0.         0.         0.05098039 0.04705882 0.03529412 0.05882353\n",
      "  0.00784314 0.         0.         0.         0.01176471 0.0627451\n",
      "  0.04705882 0.01960784 0.         0.        ]], shape=(8, 64), dtype=float64)\n",
      "y: tf.Tensor([0 2 5 0 3 1 6 0], shape=(8,), dtype=int64)\n",
      "x: tf.Tensor(\n",
      "[[0.         0.         0.01568627 0.05098039 0.0627451  0.05490196\n",
      "  0.         0.         0.         0.00784314 0.05490196 0.0627451\n",
      "  0.04705882 0.01568627 0.         0.         0.         0.05098039\n",
      "  0.0627451  0.01960784 0.         0.         0.         0.\n",
      "  0.         0.04313725 0.0627451  0.03921569 0.00392157 0.\n",
      "  0.         0.         0.         0.01960784 0.05882353 0.0627451\n",
      "  0.01960784 0.         0.         0.         0.         0.\n",
      "  0.00784314 0.05882353 0.03529412 0.         0.         0.\n",
      "  0.         0.         0.01960784 0.05882353 0.03529412 0.\n",
      "  0.         0.         0.         0.         0.01568627 0.0627451\n",
      "  0.01960784 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.02745098 0.0627451  0.04705882\n",
      "  0.         0.         0.         0.         0.02745098 0.0627451\n",
      "  0.0627451  0.04705882 0.         0.         0.         0.01176471\n",
      "  0.0627451  0.0627451  0.0627451  0.03137255 0.         0.\n",
      "  0.         0.02745098 0.0627451  0.0627451  0.0627451  0.03137255\n",
      "  0.         0.         0.         0.         0.         0.04313725\n",
      "  0.0627451  0.04705882 0.         0.         0.         0.\n",
      "  0.         0.02745098 0.0627451  0.05882353 0.         0.\n",
      "  0.         0.         0.         0.02352941 0.0627451  0.0627451\n",
      "  0.01960784 0.         0.         0.         0.         0.02352941\n",
      "  0.05882353 0.05882353 0.00784314 0.        ]\n",
      " [0.         0.         0.03529412 0.0627451  0.0627451  0.02745098\n",
      "  0.         0.         0.         0.05098039 0.05882353 0.03529412\n",
      "  0.04705882 0.05882353 0.         0.         0.         0.01960784\n",
      "  0.01568627 0.         0.05098039 0.05098039 0.         0.\n",
      "  0.         0.         0.         0.04313725 0.0627451  0.01960784\n",
      "  0.         0.         0.         0.         0.         0.04313725\n",
      "  0.0627451  0.03921569 0.01176471 0.         0.         0.\n",
      "  0.         0.         0.01568627 0.04705882 0.05098039 0.\n",
      "  0.         0.         0.02745098 0.00392157 0.00392157 0.04705882\n",
      "  0.05490196 0.         0.         0.         0.03529412 0.0627451\n",
      "  0.0627451  0.05490196 0.01960784 0.        ]\n",
      " [0.         0.         0.05098039 0.0627451  0.03529412 0.01568627\n",
      "  0.         0.         0.         0.         0.05882353 0.03529412\n",
      "  0.03529412 0.05882353 0.00392157 0.         0.         0.\n",
      "  0.04313725 0.03529412 0.05098039 0.04313725 0.         0.\n",
      "  0.         0.         0.01960784 0.0627451  0.05490196 0.00392157\n",
      "  0.         0.         0.         0.         0.02745098 0.0627451\n",
      "  0.03921569 0.         0.         0.         0.         0.\n",
      "  0.05490196 0.03921569 0.0627451  0.00784314 0.         0.\n",
      "  0.         0.         0.0627451  0.01568627 0.05882353 0.02745098\n",
      "  0.         0.         0.         0.         0.04313725 0.0627451\n",
      "  0.0627451  0.01176471 0.         0.        ]\n",
      " [0.         0.         0.03921569 0.05882353 0.00392157 0.\n",
      "  0.         0.         0.         0.         0.04313725 0.0627451\n",
      "  0.00392157 0.         0.         0.         0.         0.00392157\n",
      "  0.0627451  0.0627451  0.00392157 0.         0.         0.\n",
      "  0.         0.         0.03137255 0.0627451  0.01960784 0.\n",
      "  0.         0.         0.         0.         0.         0.05490196\n",
      "  0.03921569 0.         0.         0.         0.         0.\n",
      "  0.         0.03921569 0.05490196 0.         0.         0.\n",
      "  0.         0.         0.01960784 0.04313725 0.05882353 0.02352941\n",
      "  0.01568627 0.00392157 0.         0.         0.03921569 0.0627451\n",
      "  0.0627451  0.0627451  0.0627451  0.03921569]\n",
      " [0.         0.         0.         0.02352941 0.05490196 0.01176471\n",
      "  0.         0.         0.         0.         0.00784314 0.0627451\n",
      "  0.04313725 0.         0.         0.         0.         0.\n",
      "  0.04313725 0.05882353 0.00784314 0.         0.         0.\n",
      "  0.         0.00392157 0.05882353 0.05098039 0.00784314 0.\n",
      "  0.         0.         0.         0.01176471 0.0627451  0.0627451\n",
      "  0.0627451  0.02745098 0.         0.         0.         0.01568627\n",
      "  0.0627451  0.05490196 0.03137255 0.05098039 0.02745098 0.\n",
      "  0.         0.         0.04705882 0.0627451  0.01960784 0.04705882\n",
      "  0.03921569 0.         0.         0.         0.         0.03137255\n",
      "  0.05490196 0.05098039 0.01960784 0.        ]\n",
      " [0.         0.         0.         0.02745098 0.04313725 0.\n",
      "  0.         0.         0.         0.         0.00392157 0.0627451\n",
      "  0.03921569 0.         0.         0.         0.         0.\n",
      "  0.02745098 0.04313725 0.         0.         0.         0.\n",
      "  0.         0.         0.04313725 0.03137255 0.00392157 0.00392157\n",
      "  0.         0.         0.         0.         0.04705882 0.0627451\n",
      "  0.0627451  0.05882353 0.01960784 0.         0.         0.\n",
      "  0.05490196 0.04313725 0.         0.00392157 0.05882353 0.\n",
      "  0.         0.         0.02352941 0.04313725 0.00392157 0.01176471\n",
      "  0.05490196 0.00784314 0.         0.         0.         0.03137255\n",
      "  0.0627451  0.0627451  0.02745098 0.        ]\n",
      " [0.         0.00784314 0.02352941 0.03921569 0.04705882 0.00392157\n",
      "  0.         0.         0.         0.05490196 0.05098039 0.03921569\n",
      "  0.01960784 0.00392157 0.         0.         0.         0.03921569\n",
      "  0.02352941 0.         0.         0.         0.         0.\n",
      "  0.         0.03921569 0.05098039 0.04705882 0.04705882 0.01960784\n",
      "  0.         0.         0.         0.00784314 0.03137255 0.01960784\n",
      "  0.02745098 0.05490196 0.03137255 0.         0.         0.\n",
      "  0.         0.         0.         0.01960784 0.04705882 0.\n",
      "  0.         0.         0.00784314 0.00784314 0.00392157 0.03921569\n",
      "  0.03921569 0.         0.         0.         0.01960784 0.0627451\n",
      "  0.0627451  0.05490196 0.00392157 0.        ]], shape=(8, 64), dtype=float64)\n",
      "y: tf.Tensor([5 1 3 8 1 6 6 5], shape=(8,), dtype=int64)\n",
      "x: tf.Tensor(\n",
      "[[0.         0.00392157 0.05098039 0.0627451  0.0627451  0.0627451\n",
      "  0.04705882 0.00392157 0.         0.02352941 0.0627451  0.05490196\n",
      "  0.04705882 0.04313725 0.01960784 0.         0.         0.00784314\n",
      "  0.05882353 0.05882353 0.01960784 0.         0.         0.\n",
      "  0.         0.         0.03137255 0.05490196 0.05882353 0.00392157\n",
      "  0.         0.         0.         0.         0.         0.01176471\n",
      "  0.0627451  0.02352941 0.         0.         0.         0.\n",
      "  0.         0.01176471 0.0627451  0.01960784 0.         0.\n",
      "  0.         0.         0.02745098 0.03921569 0.0627451  0.01568627\n",
      "  0.         0.         0.         0.         0.05882353 0.0627451\n",
      "  0.03921569 0.         0.         0.        ]\n",
      " [0.         0.         0.01176471 0.04705882 0.0627451  0.05490196\n",
      "  0.         0.         0.         0.01176471 0.05882353 0.0627451\n",
      "  0.05882353 0.05490196 0.         0.         0.         0.01176471\n",
      "  0.04705882 0.00392157 0.05882353 0.03137255 0.         0.\n",
      "  0.         0.         0.         0.03529412 0.0627451  0.03137255\n",
      "  0.         0.         0.         0.         0.         0.03921569\n",
      "  0.0627451  0.0627451  0.03137255 0.         0.         0.\n",
      "  0.         0.00784314 0.01960784 0.05098039 0.03137255 0.\n",
      "  0.         0.         0.00784314 0.04313725 0.04313725 0.05882353\n",
      "  0.01960784 0.         0.         0.         0.01176471 0.0627451\n",
      "  0.0627451  0.03529412 0.         0.        ]\n",
      " [0.         0.         0.02352941 0.05490196 0.03921569 0.\n",
      "  0.         0.         0.         0.02352941 0.0627451  0.05490196\n",
      "  0.0627451  0.         0.         0.         0.         0.01960784\n",
      "  0.03921569 0.04313725 0.0627451  0.         0.         0.\n",
      "  0.         0.         0.         0.03529412 0.0627451  0.04705882\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01176471 0.0627451  0.02745098 0.         0.         0.01568627\n",
      "  0.02352941 0.         0.01176471 0.0627451  0.03137255 0.\n",
      "  0.         0.01960784 0.05882353 0.03529412 0.0627451  0.05098039\n",
      "  0.00392157 0.         0.         0.         0.03529412 0.05882353\n",
      "  0.03137255 0.         0.         0.        ]\n",
      " [0.         0.         0.00392157 0.05098039 0.0627451  0.03921569\n",
      "  0.         0.         0.         0.         0.03137255 0.05490196\n",
      "  0.05098039 0.05490196 0.         0.         0.         0.00392157\n",
      "  0.05882353 0.01960784 0.01960784 0.05882353 0.         0.\n",
      "  0.         0.02745098 0.04705882 0.         0.03529412 0.04313725\n",
      "  0.         0.         0.         0.00392157 0.00784314 0.04313725\n",
      "  0.05882353 0.0627451  0.02745098 0.         0.         0.\n",
      "  0.01568627 0.05882353 0.0627451  0.03529412 0.00392157 0.\n",
      "  0.         0.         0.         0.03921569 0.04313725 0.\n",
      "  0.         0.         0.         0.         0.00392157 0.05882353\n",
      "  0.02745098 0.         0.         0.        ]\n",
      " [0.         0.00784314 0.05098039 0.0627451  0.02745098 0.\n",
      "  0.         0.         0.         0.04705882 0.05098039 0.05490196\n",
      "  0.05098039 0.         0.         0.         0.         0.00784314\n",
      "  0.         0.03137255 0.04705882 0.         0.         0.\n",
      "  0.         0.         0.         0.04313725 0.03529412 0.\n",
      "  0.         0.         0.         0.         0.         0.05098039\n",
      "  0.01960784 0.         0.         0.         0.         0.\n",
      "  0.03137255 0.05882353 0.00784314 0.         0.         0.\n",
      "  0.         0.         0.0627451  0.0627451  0.0627451  0.03529412\n",
      "  0.00784314 0.         0.         0.00392157 0.0627451  0.05490196\n",
      "  0.05098039 0.0627451  0.03529412 0.        ]\n",
      " [0.         0.         0.01176471 0.04313725 0.05098039 0.05882353\n",
      "  0.01176471 0.         0.         0.01568627 0.0627451  0.05490196\n",
      "  0.04313725 0.0627451  0.03137255 0.         0.         0.00784314\n",
      "  0.01960784 0.         0.05490196 0.05882353 0.00392157 0.\n",
      "  0.         0.         0.         0.         0.0627451  0.04313725\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04313725 0.03921569 0.         0.         0.         0.\n",
      "  0.         0.         0.03137255 0.04705882 0.         0.\n",
      "  0.         0.         0.03137255 0.04313725 0.05882353 0.03137255\n",
      "  0.         0.         0.         0.         0.00784314 0.04705882\n",
      "  0.05490196 0.01176471 0.         0.        ]\n",
      " [0.         0.         0.00392157 0.03921569 0.05882353 0.00784314\n",
      "  0.         0.         0.         0.         0.02745098 0.0627451\n",
      "  0.02745098 0.01176471 0.01960784 0.         0.         0.01176471\n",
      "  0.0627451  0.02745098 0.01176471 0.0627451  0.04313725 0.\n",
      "  0.         0.03529412 0.05490196 0.00392157 0.03921569 0.05490196\n",
      "  0.00784314 0.         0.         0.04313725 0.0627451  0.0627451\n",
      "  0.0627451  0.03921569 0.         0.         0.         0.00784314\n",
      "  0.01568627 0.03137255 0.0627451  0.01176471 0.         0.\n",
      "  0.         0.         0.         0.03529412 0.05098039 0.\n",
      "  0.         0.         0.         0.         0.         0.04705882\n",
      "  0.03529412 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.03529412 0.05882353 0.00392157\n",
      "  0.         0.         0.         0.         0.03921569 0.05098039\n",
      "  0.01568627 0.         0.         0.         0.         0.00784314\n",
      "  0.05882353 0.00392157 0.         0.         0.         0.\n",
      "  0.         0.01960784 0.04313725 0.01568627 0.01568627 0.\n",
      "  0.         0.         0.         0.01568627 0.0627451  0.0627451\n",
      "  0.0627451  0.0627451  0.01568627 0.         0.         0.\n",
      "  0.0627451  0.00784314 0.         0.03921569 0.03137255 0.\n",
      "  0.         0.         0.03137255 0.04705882 0.01568627 0.05098039\n",
      "  0.02745098 0.         0.         0.         0.00392157 0.03529412\n",
      "  0.0627451  0.04313725 0.00392157 0.        ]], shape=(8, 64), dtype=float64)\n",
      "y: tf.Tensor([5 3 3 7 2 3 4 6], shape=(8,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "train_batch = train.shuffle(buffer_size=len(X_train)).batch(batch_size=8)\n",
    "test_batch = test.shuffle(buffer_size=len(X_test)).batch(batch_size=8)\n",
    "val_batch = val.shuffle(buffer_size=len(X_val)).batch(batch_size=8)\n",
    "\n",
    "for x, y in train_batch.take(1): \n",
    "  print('x:',x)\n",
    "  print('y:',y)\n",
    "\n",
    "for x, y in test_batch.take(1): \n",
    "  print('x:',x)\n",
    "  print('y:',y)\n",
    "\n",
    "for x, y in val_batch.take(1): \n",
    "  print('x:',x)\n",
    "  print('y:',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train batch: (<tf.Tensor: shape=(8, 64), dtype=float64, numpy=\n",
      "array([[0.        , 0.        , 0.03921569, 0.05882353, 0.05882353,\n",
      "        0.04313725, 0.01568627, 0.        , 0.        , 0.00392157,\n",
      "        0.03921569, 0.01960784, 0.02745098, 0.0627451 , 0.03921569,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
      "        0.05490196, 0.05490196, 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.04313725, 0.05098039, 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.01960784, 0.0627451 , 0.01960784, 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.00392157, 0.03921569,\n",
      "        0.05490196, 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.00784314, 0.02745098, 0.05882353, 0.01176471,\n",
      "        0.        , 0.        , 0.        , 0.02352941, 0.04313725,\n",
      "        0.0627451 , 0.03137255, 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.02745098, 0.05098039, 0.01568627,\n",
      "        0.00392157, 0.        , 0.        , 0.        , 0.00392157,\n",
      "        0.05882353, 0.05098039, 0.05882353, 0.04313725, 0.        ,\n",
      "        0.        , 0.        , 0.02745098, 0.0627451 , 0.00392157,\n",
      "        0.05098039, 0.0627451 , 0.01568627, 0.        , 0.        ,\n",
      "        0.01176471, 0.0627451 , 0.04705882, 0.0627451 , 0.0627451 ,\n",
      "        0.02745098, 0.        , 0.        , 0.        , 0.01568627,\n",
      "        0.04313725, 0.01960784, 0.0627451 , 0.03137255, 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.00784314,\n",
      "        0.0627451 , 0.01960784, 0.        , 0.        , 0.        ,\n",
      "        0.04705882, 0.02352941, 0.03529412, 0.05490196, 0.00392157,\n",
      "        0.        , 0.        , 0.        , 0.02352941, 0.05098039,\n",
      "        0.0627451 , 0.01960784, 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.00392157, 0.05098039, 0.03529412,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.03137255, 0.0627451 , 0.01568627, 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.0627451 , 0.04313725,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.00784314, 0.0627451 , 0.03921569, 0.00784314, 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.02745098, 0.0627451 ,\n",
      "        0.0627451 , 0.0627451 , 0.03921569, 0.00392157, 0.        ,\n",
      "        0.        , 0.01568627, 0.0627451 , 0.02352941, 0.00784314,\n",
      "        0.05490196, 0.02745098, 0.        , 0.        , 0.        ,\n",
      "        0.04313725, 0.05882353, 0.04705882, 0.05882353, 0.03137255,\n",
      "        0.        , 0.        , 0.        , 0.00784314, 0.05490196,\n",
      "        0.05882353, 0.02352941, 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.04313725, 0.03137255,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.01960784, 0.0627451 , 0.02745098, 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.03921569, 0.05490196,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.04705882, 0.03529412, 0.00392157, 0.01176471,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
      "        0.05490196, 0.05882353, 0.0627451 , 0.02745098, 0.        ,\n",
      "        0.        , 0.        , 0.03921569, 0.0627451 , 0.05882353,\n",
      "        0.04705882, 0.04705882, 0.        , 0.        , 0.        ,\n",
      "        0.02352941, 0.0627451 , 0.05098039, 0.05490196, 0.04705882,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.03529412,\n",
      "        0.05882353, 0.05882353, 0.01176471, 0.        ],\n",
      "       [0.        , 0.01568627, 0.02745098, 0.05098039, 0.0627451 ,\n",
      "        0.0627451 , 0.01568627, 0.        , 0.        , 0.04313725,\n",
      "        0.0627451 , 0.05490196, 0.03529412, 0.00784314, 0.        ,\n",
      "        0.        , 0.        , 0.05490196, 0.01960784, 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.04705882, 0.03137255, 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.03529412, 0.04705882,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.00784314, 0.05098039, 0.0627451 , 0.03529412,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
      "        0.01176471, 0.05490196, 0.0627451 , 0.01176471, 0.        ,\n",
      "        0.        , 0.        , 0.01568627, 0.05490196, 0.0627451 ,\n",
      "        0.05098039, 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.01176471, 0.04705882,\n",
      "        0.03921569, 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.00392157, 0.05490196, 0.02352941, 0.05882353, 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.0627451 ,\n",
      "        0.02352941, 0.03921569, 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.05490196, 0.0627451 , 0.00784314,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.01176471,\n",
      "        0.05490196, 0.05882353, 0.01176471, 0.        , 0.        ,\n",
      "        0.        , 0.00392157, 0.0627451 , 0.01568627, 0.03529412,\n",
      "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.01568627, 0.05098039, 0.01568627, 0.02745098, 0.03137255,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.01176471,\n",
      "        0.03921569, 0.04313725, 0.05882353, 0.00784314],\n",
      "       [0.        , 0.        , 0.        , 0.01568627, 0.05882353,\n",
      "        0.04313725, 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.00784314, 0.05882353, 0.0627451 , 0.05098039, 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.05098039, 0.05098039,\n",
      "        0.04313725, 0.03921569, 0.        , 0.        , 0.        ,\n",
      "        0.02745098, 0.05490196, 0.01176471, 0.05490196, 0.04705882,\n",
      "        0.02352941, 0.        , 0.        , 0.03137255, 0.0627451 ,\n",
      "        0.0627451 , 0.0627451 , 0.05882353, 0.03137255, 0.        ,\n",
      "        0.        , 0.00392157, 0.03137255, 0.03529412, 0.0627451 ,\n",
      "        0.01568627, 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.01176471, 0.0627451 , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.01176471,\n",
      "        0.05490196, 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.03921569, 0.0627451 , 0.0627451 ,\n",
      "        0.01568627, 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.03529412, 0.03137255, 0.05098039, 0.03921569, 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.01568627,\n",
      "        0.05882353, 0.02352941, 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.05098039, 0.0627451 , 0.02745098,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.01960784, 0.05098039, 0.0627451 , 0.00392157, 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.0627451 , 0.01568627, 0.        , 0.        , 0.        ,\n",
      "        0.02745098, 0.01176471, 0.01960784, 0.0627451 , 0.00784314,\n",
      "        0.        , 0.        , 0.        , 0.04313725, 0.0627451 ,\n",
      "        0.0627451 , 0.03921569, 0.        , 0.        ]])>, <tf.Tensor: shape=(8,), dtype=int64, numpy=array([3, 9, 6, 6, 5, 8, 4, 3])>)\n",
      "val batch: (<tf.Tensor: shape=(8, 64), dtype=float64, numpy=\n",
      "array([[0.        , 0.        , 0.01176471, 0.0627451 , 0.01568627,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.04705882, 0.05098039, 0.00784314, 0.01960784, 0.        ,\n",
      "        0.        , 0.        , 0.00784314, 0.0627451 , 0.02352941,\n",
      "        0.03921569, 0.05882353, 0.00392157, 0.        , 0.        ,\n",
      "        0.03529412, 0.05882353, 0.01176471, 0.0627451 , 0.04313725,\n",
      "        0.02745098, 0.        , 0.        , 0.04705882, 0.0627451 ,\n",
      "        0.0627451 , 0.05882353, 0.04313725, 0.01960784, 0.        ,\n",
      "        0.        , 0.01176471, 0.03529412, 0.0627451 , 0.01176471,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.00784314, 0.0627451 , 0.01176471, 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.02352941, 0.05490196,\n",
      "        0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.01960784, 0.04313725, 0.05098039,\n",
      "        0.01176471, 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.0627451 , 0.05098039, 0.05882353, 0.03529412, 0.        ,\n",
      "        0.        , 0.        , 0.01568627, 0.0627451 , 0.        ,\n",
      "        0.05098039, 0.05098039, 0.        , 0.        , 0.        ,\n",
      "        0.00392157, 0.04313725, 0.0627451 , 0.05882353, 0.05882353,\n",
      "        0.01176471, 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.04705882, 0.02745098, 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.02352941, 0.04705882, 0.        , 0.        , 0.        ,\n",
      "        0.02352941, 0.01568627, 0.00784314, 0.03529412, 0.04313725,\n",
      "        0.        , 0.        , 0.        , 0.02352941, 0.05098039,\n",
      "        0.0627451 , 0.0627451 , 0.02352941, 0.        ],\n",
      "       [0.        , 0.        , 0.00392157, 0.0627451 , 0.04313725,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.05882353, 0.0627451 , 0.00392157, 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.05882353,\n",
      "        0.05490196, 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.00784314, 0.0627451 , 0.05490196, 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
      "        0.0627451 , 0.05882353, 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.05490196, 0.05098039,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.05098039, 0.03921569, 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.04705882,\n",
      "        0.04313725, 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.00392157, 0.03921569, 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.02745098, 0.04705882, 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.04705882, 0.02745098,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.05490196, 0.01176471, 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.05882353,\n",
      "        0.03529412, 0.04705882, 0.03921569, 0.00784314, 0.        ,\n",
      "        0.        , 0.        , 0.0627451 , 0.05098039, 0.03137255,\n",
      "        0.03137255, 0.04313725, 0.        , 0.        , 0.        ,\n",
      "        0.05098039, 0.03921569, 0.01568627, 0.03529412, 0.05882353,\n",
      "        0.        , 0.        , 0.        , 0.01176471, 0.03921569,\n",
      "        0.05882353, 0.03529412, 0.00784314, 0.        ],\n",
      "       [0.        , 0.        , 0.02745098, 0.05098039, 0.03137255,\n",
      "        0.02352941, 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.0627451 , 0.05882353, 0.0627451 , 0.05490196, 0.03921569,\n",
      "        0.        , 0.        , 0.01568627, 0.0627451 , 0.05098039,\n",
      "        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.00392157, 0.03921569, 0.0627451 , 0.03529412, 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.01960784, 0.05098039, 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.01960784, 0.05882353,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.03137255, 0.04313725, 0.03137255, 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.03529412, 0.0627451 ,\n",
      "        0.01176471, 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.01568627, 0.0627451 , 0.05882353, 0.00392157,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.02352941,\n",
      "        0.05490196, 0.0627451 , 0.01568627, 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.0627451 ,\n",
      "        0.03137255, 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.01176471, 0.0627451 , 0.02352941, 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.02352941,\n",
      "        0.0627451 , 0.00392157, 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.05098039, 0.04313725, 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.01176471,\n",
      "        0.0627451 , 0.0627451 , 0.04705882, 0.03921569, 0.01960784,\n",
      "        0.        , 0.        , 0.01176471, 0.0627451 , 0.0627451 ,\n",
      "        0.0627451 , 0.0627451 , 0.03137255, 0.        ],\n",
      "       [0.        , 0.        , 0.04313725, 0.05882353, 0.01568627,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.01960784,\n",
      "        0.0627451 , 0.05882353, 0.05882353, 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.05490196, 0.04313725,\n",
      "        0.0627451 , 0.00784314, 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.01568627, 0.0627451 , 0.01960784,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.01568627, 0.0627451 , 0.02352941, 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.02745098, 0.0627451 ,\n",
      "        0.03921569, 0.01176471, 0.        , 0.        , 0.        ,\n",
      "        0.04313725, 0.0627451 , 0.0627451 , 0.0627451 , 0.0627451 ,\n",
      "        0.02352941, 0.        , 0.        , 0.04313725, 0.0627451 ,\n",
      "        0.03921569, 0.01960784, 0.05098039, 0.02352941],\n",
      "       [0.        , 0.        , 0.        , 0.05490196, 0.03921569,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.01176471,\n",
      "        0.05490196, 0.0627451 , 0.05098039, 0.        , 0.        ,\n",
      "        0.        , 0.00784314, 0.0627451 , 0.0627451 , 0.0627451 ,\n",
      "        0.01960784, 0.        , 0.        , 0.        , 0.00392157,\n",
      "        0.04313725, 0.05490196, 0.05882353, 0.00392157, 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.03137255,\n",
      "        0.0627451 , 0.00392157, 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.02745098, 0.0627451 , 0.00392157,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.00392157, 0.05882353, 0.01960784, 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.05098039,\n",
      "        0.05098039, 0.        , 0.        , 0.        ]])>, <tf.Tensor: shape=(8,), dtype=int64, numpy=array([4, 9, 1, 6, 5, 2, 2, 1])>)\n",
      "test batch: (<tf.Tensor: shape=(8, 64), dtype=float64, numpy=\n",
      "array([[0.        , 0.        , 0.05882353, 0.05098039, 0.        ,\n",
      "        0.01176471, 0.01176471, 0.        , 0.        , 0.        ,\n",
      "        0.05882353, 0.05882353, 0.03137255, 0.05882353, 0.01960784,\n",
      "        0.        , 0.        , 0.        , 0.03137255, 0.0627451 ,\n",
      "        0.0627451 , 0.02745098, 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.02745098, 0.0627451 , 0.0627451 , 0.00392157,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.04705882,\n",
      "        0.04705882, 0.05882353, 0.03921569, 0.        , 0.        ,\n",
      "        0.        , 0.01176471, 0.0627451 , 0.        , 0.03921569,\n",
      "        0.05882353, 0.00392157, 0.        , 0.        , 0.00784314,\n",
      "        0.0627451 , 0.01960784, 0.02745098, 0.05882353, 0.01176471,\n",
      "        0.        , 0.        , 0.00392157, 0.04705882, 0.0627451 ,\n",
      "        0.05882353, 0.02745098, 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.01568627, 0.05882353, 0.04313725,\n",
      "        0.00392157, 0.        , 0.        , 0.        , 0.00784314,\n",
      "        0.05490196, 0.05490196, 0.0627451 , 0.03137255, 0.        ,\n",
      "        0.        , 0.        , 0.03137255, 0.05882353, 0.00784314,\n",
      "        0.01176471, 0.05098039, 0.        , 0.        , 0.        ,\n",
      "        0.01568627, 0.0627451 , 0.        , 0.        , 0.04705882,\n",
      "        0.02745098, 0.        , 0.        , 0.02745098, 0.0627451 ,\n",
      "        0.        , 0.        , 0.04705882, 0.03137255, 0.        ,\n",
      "        0.        , 0.01176471, 0.0627451 , 0.02352941, 0.00392157,\n",
      "        0.05490196, 0.03529412, 0.        , 0.        , 0.        ,\n",
      "        0.05882353, 0.0627451 , 0.0627451 , 0.0627451 , 0.00784314,\n",
      "        0.        , 0.        , 0.        , 0.01568627, 0.05098039,\n",
      "        0.05490196, 0.02352941, 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.01176471, 0.05882353, 0.0627451 ,\n",
      "        0.04705882, 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.02352941, 0.0627451 , 0.02352941, 0.05490196, 0.02352941,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.01176471,\n",
      "        0.00392157, 0.05882353, 0.02352941, 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.00392157, 0.05490196, 0.0627451 ,\n",
      "        0.01176471, 0.        , 0.        , 0.01960784, 0.03137255,\n",
      "        0.00784314, 0.05098039, 0.0627451 , 0.01176471, 0.        ,\n",
      "        0.        , 0.01960784, 0.0627451 , 0.        , 0.        ,\n",
      "        0.03529412, 0.05098039, 0.        , 0.        , 0.00392157,\n",
      "        0.05882353, 0.04313725, 0.03137255, 0.04705882, 0.0627451 ,\n",
      "        0.00392157, 0.        , 0.        , 0.01176471, 0.05490196,\n",
      "        0.0627451 , 0.0627451 , 0.03529412, 0.        ],\n",
      "       [0.        , 0.        , 0.01176471, 0.04313725, 0.02352941,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.03921569, 0.05490196, 0.0627451 , 0.00784314, 0.        ,\n",
      "        0.        , 0.        , 0.01176471, 0.05882353, 0.00392157,\n",
      "        0.04313725, 0.04313725, 0.        , 0.        , 0.        ,\n",
      "        0.01568627, 0.04705882, 0.        , 0.00784314, 0.0627451 ,\n",
      "        0.00784314, 0.        , 0.        , 0.02745098, 0.04705882,\n",
      "        0.        , 0.        , 0.04705882, 0.03137255, 0.        ,\n",
      "        0.        , 0.01568627, 0.05490196, 0.        , 0.00392157,\n",
      "        0.05882353, 0.03137255, 0.        , 0.        , 0.00784314,\n",
      "        0.05882353, 0.05490196, 0.05882353, 0.05882353, 0.00392157,\n",
      "        0.        , 0.        , 0.        , 0.01960784, 0.05098039,\n",
      "        0.05490196, 0.01960784, 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.03529412, 0.05098039,\n",
      "        0.03921569, 0.00392157, 0.        , 0.        , 0.        ,\n",
      "        0.03529412, 0.04705882, 0.01568627, 0.05882353, 0.01960784,\n",
      "        0.        , 0.        , 0.        , 0.0627451 , 0.01568627,\n",
      "        0.        , 0.04705882, 0.01568627, 0.        , 0.        ,\n",
      "        0.01176471, 0.05882353, 0.03529412, 0.01176471, 0.05490196,\n",
      "        0.00392157, 0.        , 0.        , 0.        , 0.00784314,\n",
      "        0.03529412, 0.0627451 , 0.03921569, 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.01568627, 0.05490196,\n",
      "        0.05882353, 0.00784314, 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.03921569, 0.03137255, 0.05490196, 0.01176471,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.03921569,\n",
      "        0.0627451 , 0.04705882, 0.        , 0.        ],\n",
      "       [0.        , 0.01176471, 0.05098039, 0.0627451 , 0.03529412,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.03921569,\n",
      "        0.05882353, 0.05098039, 0.05882353, 0.00784314, 0.        ,\n",
      "        0.        , 0.        , 0.05882353, 0.01568627, 0.01568627,\n",
      "        0.0627451 , 0.00392157, 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.01960784, 0.0627451 , 0.00784314,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
      "        0.05490196, 0.05098039, 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.03921569, 0.0627451 , 0.01960784,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.01568627,\n",
      "        0.0627451 , 0.05098039, 0.03137255, 0.03921569, 0.03529412,\n",
      "        0.00392157, 0.        , 0.00784314, 0.0627451 , 0.0627451 ,\n",
      "        0.05490196, 0.04705882, 0.03529412, 0.00392157],\n",
      "       [0.        , 0.        , 0.01176471, 0.04705882, 0.05882353,\n",
      "        0.04313725, 0.00784314, 0.        , 0.        , 0.        ,\n",
      "        0.04313725, 0.05098039, 0.02745098, 0.05098039, 0.03137255,\n",
      "        0.        , 0.        , 0.02745098, 0.05882353, 0.00392157,\n",
      "        0.01960784, 0.05882353, 0.01176471, 0.        , 0.        ,\n",
      "        0.00392157, 0.04705882, 0.0627451 , 0.0627451 , 0.01960784,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.05098039, 0.05882353, 0.05882353, 0.00784314, 0.        ,\n",
      "        0.        , 0.        , 0.00784314, 0.05098039, 0.        ,\n",
      "        0.03921569, 0.01960784, 0.        , 0.        , 0.        ,\n",
      "        0.01568627, 0.04313725, 0.01568627, 0.04313725, 0.02352941,\n",
      "        0.        , 0.        , 0.        , 0.00784314, 0.05098039,\n",
      "        0.0627451 , 0.04705882, 0.        , 0.        ],\n",
      "       [0.        , 0.00784314, 0.04313725, 0.05490196, 0.05490196,\n",
      "        0.03529412, 0.        , 0.        , 0.        , 0.01176471,\n",
      "        0.03921569, 0.02745098, 0.03921569, 0.0627451 , 0.01176471,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.01568627,\n",
      "        0.05098039, 0.04705882, 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.05098039, 0.05882353, 0.00784314,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.05882353, 0.03529412, 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.03529412, 0.05882353,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.00392157, 0.05098039, 0.03529412, 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.00392157, 0.05882353, 0.05098039,\n",
      "        0.00392157, 0.        , 0.        , 0.        ]])>, <tf.Tensor: shape=(8,), dtype=int64, numpy=array([8, 0, 3, 0, 8, 2, 8, 3])>)\n"
     ]
    }
   ],
   "source": [
    "print(\"train batch:\", next(iter(train_batch)))\n",
    "print(\"val batch:\", next(iter(val_batch)))\n",
    "print(\"test batch:\", next(iter(test_batch)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to start training deep learning models!\n",
    "\n",
    "# Technique 2: split using tensorflow\n",
    "\n",
    "This technique is not so recommended because tensorflow is not able to work with datasets in the same way that sklearn does, it is not as practical to split the data in a random way, but we will show you how it can be done, as sometimes you will strictly be working with tensorflow objects.\n",
    "\n",
    "Create a tensor slice dataset object using data and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_ds: <_TensorSliceDataset element_spec=(TensorSpec(shape=(64,), dtype=tf.float64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "full_ds = tf.data.Dataset.from_tensor_slices((data,target))\n",
    "print(\"full_ds:\", full_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the commands take and skip, separate the tensor slice dataset into a train object containing 60% of the data, a val object (20%) and a test object (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: <_TakeDataset element_spec=(TensorSpec(shape=(64,), dtype=tf.float64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))> 1078\n",
      "val: <_TakeDataset element_spec=(TensorSpec(shape=(64,), dtype=tf.float64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))> 359\n",
      "test: <_SkipDataset element_spec=(TensorSpec(shape=(64,), dtype=tf.float64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))> 360\n"
     ]
    }
   ],
   "source": [
    "n_train = int(0.6*len(data))\n",
    "n_val = int(0.2*len(data))\n",
    "n_test = len(data) - n_train - n_val\n",
    "\n",
    "train = full_ds.take(n_train)\n",
    "valtest = full_ds.skip(n_train)\n",
    "val = valtest.take(n_val)\n",
    "test = valtest.skip(n_val)\n",
    "\n",
    "print(\"train:\", train, len(train))\n",
    "print(\"val:\", val, len(val))\n",
    "print(\"test:\", test, len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use methods shuffle and batch in order to create batch datasets with batches of 8 observations for train, val, and test, and show one batch from each of these objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = train.shuffle(buffer_size=len(X_train)).batch(batch_size=8)\n",
    "test_batch = test.shuffle(buffer_size=len(X_test)).batch(batch_size=8)\n",
    "val_batch = val.shuffle(buffer_size=len(X_val)).batch(batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you know two different ways of forming datasets that are fit for training deep learning models with tensorflow! This skill will come in very handy as we will try to focus more on building models from now on, and put less focus on preprocessing. Until then, happy learning!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
