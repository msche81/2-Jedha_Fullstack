{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMvSXurqqUrG43HdukGfeoO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":10,"metadata":{"id":"kjyQpFFPRPC7","executionInfo":{"status":"ok","timestamp":1736279153997,"user_tz":-60,"elapsed":229,"user":{"displayName":"marie-sophie chenevier","userId":"01317793668247273219"}}},"outputs":[],"source":["# Import Tensorflow & Pathlib librairies\n","import tensorflow as tf\n","import pathlib\n","import pandas as pd\n","import os\n","import io\n","import warnings\n","warnings.filterwarnings('ignore')\n","import json\n","from random import randint\n","from numpy import array\n","from numpy import argmax\n","from numpy import array_equal\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.layers import LSTM\n","from tensorflow.keras.layers import Dense"]},{"cell_type":"markdown","source":["# Generate data"],"metadata":{"id":"-je86AyxR69t"}},{"cell_type":"code","source":["input_dim = 100\n","input_seq_len = 10\n","target_seq_len = 5"],"metadata":{"id":"qtoXVK7hR10E","executionInfo":{"status":"ok","timestamp":1736279154377,"user_tz":-60,"elapsed":5,"user":{"displayName":"marie-sophie chenevier","userId":"01317793668247273219"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# generate a sequence of random integers\n","def generate_sequence(length, n_unique):\n","\treturn [randint(1, n_unique-1) for _ in range(length)]"],"metadata":{"id":"bRI4ggOuR9LF","executionInfo":{"status":"ok","timestamp":1736279154377,"user_tz":-60,"elapsed":4,"user":{"displayName":"marie-sophie chenevier","userId":"01317793668247273219"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["generate_sequence(input_seq_len,input_dim)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t8i3tkeqSBfx","executionInfo":{"status":"ok","timestamp":1736279154377,"user_tz":-60,"elapsed":4,"user":{"displayName":"marie-sophie chenevier","userId":"01317793668247273219"}},"outputId":"4679728f-d64b-4152-a63e-1af1e3aaa0d1"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[44, 20, 75, 83, 84, 60, 12, 57, 41, 67]"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# prepare data for the LSTM\n","def get_dataset(n_in, n_out, cardinality, n_samples, printing=False):\n","  X1, X2, y = list(), list(), list()\n","  for _ in range(n_samples):\n","    # generate source sequence\n","    source = generate_sequence(n_in, cardinality)\n","    if printing:\n","      print(\"source:\", source)\n","    # define padded target sequence\n","    target = source[:n_out]\n","    target.reverse()\n","    if printing:\n","      print(\"target:\", target)\n","    # create padded input target sequence\n","    target_in = [0] + target[:-1]\n","    if printing:\n","      print(\"padded target:\", target_in)\n","    # store\n","    X1.append(source)\n","    X2.append(target_in)\n","    y.append(target)\n","  return array(X1), array(X2), array(y)"],"metadata":{"id":"9RXqnTiuSJDA","executionInfo":{"status":"ok","timestamp":1736279154377,"user_tz":-60,"elapsed":2,"user":{"displayName":"marie-sophie chenevier","userId":"01317793668247273219"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["input, padded_target, target =  get_dataset(input_seq_len,target_seq_len,input_dim,1,True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aHa5xzj2SLL9","executionInfo":{"status":"ok","timestamp":1736279154607,"user_tz":-60,"elapsed":232,"user":{"displayName":"marie-sophie chenevier","userId":"01317793668247273219"}},"outputId":"d734796f-bb68-4201-ea3f-7e4d5f7df935"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["source: [44, 48, 65, 31, 80, 63, 21, 94, 87, 26]\n","target: [80, 31, 65, 48, 44]\n","padded target: [0, 80, 31, 65, 48]\n"]}]},{"cell_type":"markdown","source":[" training data and validation data"],"metadata":{"id":"-MEIX_MQSzMG"}},{"cell_type":"code","source":["X_train, padded_y_train, y_train = get_dataset(input_seq_len,target_seq_len,input_dim,10000)\n","X_val, padded_y_val, y_val = get_dataset(input_seq_len,target_seq_len,input_dim,5000)"],"metadata":{"id":"SqAxB_TzSeZ5","executionInfo":{"status":"ok","timestamp":1736279154607,"user_tz":-60,"elapsed":6,"user":{"displayName":"marie-sophie chenevier","userId":"01317793668247273219"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["# Create encoder model"],"metadata":{"id":"zSvMHkuLTNuE"}},{"cell_type":"code","source":["# let's start by defining the number of units needed for the embedding and\n","# the lstm layers\n","\n","n_embed = 32\n","n_lstm = 16"],"metadata":{"id":"yM3sUXntS5Il","executionInfo":{"status":"ok","timestamp":1736279154607,"user_tz":-60,"elapsed":5,"user":{"displayName":"marie-sophie chenevier","userId":"01317793668247273219"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["encoder_input = tf.keras.Input(shape=(input_seq_len,))\n","encoder_embed = tf.keras.layers.Embedding(input_dim=input_dim, output_dim=n_embed)\n","encoder_lstm = tf.keras.layers.LSTM(n_lstm, return_state=True)\n","\n","encoder_embed_ouput = encoder_embed(encoder_input)\n","encoder_output = encoder_lstm(encoder_embed_ouput)\n","\n","encoder = tf.keras.Model(inputs = encoder_input, outputs = encoder_output)"],"metadata":{"id":"sVWXU_USTLBM","executionInfo":{"status":"ok","timestamp":1736279370935,"user_tz":-60,"elapsed":434,"user":{"displayName":"marie-sophie chenevier","userId":"01317793668247273219"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["encoder(tf.expand_dims(X_train[0],0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nHkvHnpTTTi2","executionInfo":{"status":"ok","timestamp":1736279470071,"user_tz":-60,"elapsed":456,"user":{"displayName":"marie-sophie chenevier","userId":"01317793668247273219"}},"outputId":"d48b52ef-36fd-48a3-8be7-966753ac32db"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n"," array([[ 0.01129525,  0.00057226, -0.01966917,  0.01222087, -0.00189131,\n","         -0.01245521,  0.00573739,  0.0006013 , -0.00826717,  0.00604259,\n","          0.00121258,  0.00714384,  0.00167558,  0.00918821,  0.00246558,\n","         -0.00473987]], dtype=float32)>,\n"," <tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n"," array([[ 0.01129525,  0.00057226, -0.01966917,  0.01222087, -0.00189131,\n","         -0.01245521,  0.00573739,  0.0006013 , -0.00826717,  0.00604259,\n","          0.00121258,  0.00714384,  0.00167558,  0.00918821,  0.00246558,\n","         -0.00473987]], dtype=float32)>,\n"," <tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n"," array([[ 0.02269215,  0.0011284 , -0.04037379,  0.02373661, -0.00379216,\n","         -0.02531774,  0.01147833,  0.00118958, -0.01647645,  0.01219762,\n","          0.00242348,  0.01429096,  0.00337065,  0.01831792,  0.00495155,\n","         -0.00950271]], dtype=float32)>)"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["# Create decoder"],"metadata":{"id":"yKFq-SiWU3Jq"}},{"cell_type":"markdown","source":["Decoder for training"],"metadata":{"id":"YCKrDN8-Vrsq"}},{"cell_type":"code","source":["decoder_input = tf.keras.Input(shape=(target_seq_len,))\n","decoder_embed = tf.keras.layers.Embedding(input_dim=input_dim,output_dim=n_embed)\n","decoder_lstm = tf.keras.layers.LSTM(n_lstm, return_sequences=True, return_state=True)\n","decoder_pred = tf.keras.layers.Dense(input_dim, activation=\"softmax\")\n","\n","decoder_embed_output = decoder_embed(decoder_input) # teacher forcing happens here\n","# the decoder input is actually the padded target we created earlier, remember\n","# if target is: [91, 47, 89, 21, 62]\n","# the decoder input will be: [0, 91, 47, 89, 21]\n","decoder_lstm_output, _, _ = decoder_lstm(decoder_embed_output, initial_state=encoder_output[1:])\n","# in the step described above the decoder receives the encoder state as its\n","# initial state.\n","decoder_output = decoder_pred(decoder_lstm_output)\n","# then the dense layer will convert the vector representation for each element\n","# in the sequence into a probability distribution across all possible tokens\n","# in the vocabulary!\n","\n","decoder = tf.keras.Model(inputs = [encoder_input,decoder_input], outputs = decoder_output)\n","# all we need to do is put the model together using the input output framework!"],"metadata":{"id":"w6JlimeAUizk","executionInfo":{"status":"ok","timestamp":1736279666681,"user_tz":-60,"elapsed":250,"user":{"displayName":"marie-sophie chenevier","userId":"01317793668247273219"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["decoder([tf.expand_dims(X_train[0],0),tf.expand_dims(padded_y_train[0],0)])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H5unP_i7VQ2T","executionInfo":{"status":"ok","timestamp":1736279695207,"user_tz":-60,"elapsed":457,"user":{"displayName":"marie-sophie chenevier","userId":"01317793668247273219"}},"outputId":"f3a93ebd-e6ab-4fdc-b4ab-f47e12488251"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 5, 100), dtype=float32, numpy=\n","array([[[0.01007655, 0.00991192, 0.01004323, 0.00995273, 0.00999432,\n","         0.01000577, 0.009964  , 0.00999814, 0.01001697, 0.00993688,\n","         0.00995826, 0.00994203, 0.01007221, 0.01007764, 0.00994589,\n","         0.01002113, 0.01000798, 0.00994006, 0.01008088, 0.01002245,\n","         0.00999011, 0.0100556 , 0.01003337, 0.01000643, 0.00996418,\n","         0.01001138, 0.00991243, 0.00996589, 0.00990561, 0.00990576,\n","         0.00994765, 0.01001476, 0.01009693, 0.01002663, 0.00993641,\n","         0.01010018, 0.0099559 , 0.00999413, 0.00997098, 0.01000781,\n","         0.01010691, 0.00995029, 0.01006586, 0.01006585, 0.00990772,\n","         0.00997622, 0.00997525, 0.01006955, 0.01001726, 0.01003355,\n","         0.01002276, 0.00996693, 0.0099928 , 0.00997255, 0.01009978,\n","         0.01002527, 0.00995249, 0.00998849, 0.01007547, 0.01000005,\n","         0.01007481, 0.01000559, 0.0100099 , 0.00995716, 0.00996074,\n","         0.00998225, 0.01002841, 0.00996535, 0.01007062, 0.00998158,\n","         0.00998145, 0.00988632, 0.01000063, 0.01002562, 0.01000158,\n","         0.01001353, 0.01000172, 0.01001174, 0.01001572, 0.00990525,\n","         0.00995428, 0.01008328, 0.01008761, 0.00989795, 0.00993417,\n","         0.01006023, 0.00993773, 0.01008295, 0.0100045 , 0.01012215,\n","         0.01000624, 0.00997574, 0.00989192, 0.01002584, 0.01008004,\n","         0.00996336, 0.00996022, 0.01003638, 0.0100035 , 0.00997561],\n","        [0.0100689 , 0.00996519, 0.01001032, 0.00996169, 0.00997923,\n","         0.01005699, 0.00996803, 0.01002757, 0.01000936, 0.00997351,\n","         0.00994192, 0.00998256, 0.00999136, 0.01009485, 0.00997243,\n","         0.01002493, 0.00996986, 0.00993418, 0.01000127, 0.00997433,\n","         0.01004806, 0.01004497, 0.01002033, 0.00996458, 0.01000795,\n","         0.01001046, 0.00995595, 0.00998331, 0.00987899, 0.00994707,\n","         0.00995877, 0.01001923, 0.01003194, 0.01004344, 0.00989624,\n","         0.01000099, 0.01004285, 0.010025  , 0.00997274, 0.01002675,\n","         0.01010715, 0.00997674, 0.01007489, 0.01000751, 0.00993428,\n","         0.01000302, 0.00997697, 0.01004474, 0.00997849, 0.01004458,\n","         0.01000862, 0.00996784, 0.01002573, 0.00997042, 0.01004296,\n","         0.01006934, 0.00999398, 0.00999019, 0.01004571, 0.00997779,\n","         0.01001626, 0.0099992 , 0.01001567, 0.00995154, 0.01001008,\n","         0.00991124, 0.00997029, 0.01004382, 0.0100361 , 0.01003419,\n","         0.01000302, 0.00989067, 0.01002429, 0.01002254, 0.01001395,\n","         0.0100344 , 0.00998431, 0.01002451, 0.00998886, 0.00992956,\n","         0.00999826, 0.01010201, 0.01005209, 0.00999056, 0.00996166,\n","         0.01004818, 0.00998612, 0.01004891, 0.00999311, 0.01009737,\n","         0.01003622, 0.00999877, 0.00988846, 0.00997332, 0.01007956,\n","         0.00994066, 0.0099402 , 0.00999324, 0.00995154, 0.00998623],\n","        [0.01000372, 0.01000398, 0.0099849 , 0.00996089, 0.00997943,\n","         0.01007503, 0.00997625, 0.01005745, 0.01000109, 0.00996642,\n","         0.00989099, 0.00994216, 0.01001406, 0.01003834, 0.00994768,\n","         0.01003432, 0.01002208, 0.00997765, 0.00999269, 0.01004581,\n","         0.01005833, 0.00999464, 0.01010204, 0.00996137, 0.01003207,\n","         0.01002244, 0.00991429, 0.01002791, 0.00991972, 0.00997115,\n","         0.00992705, 0.01003493, 0.01001052, 0.01001042, 0.00991478,\n","         0.01003472, 0.00997666, 0.0100301 , 0.00998816, 0.01002552,\n","         0.01008593, 0.00994611, 0.01004587, 0.01002171, 0.00989741,\n","         0.00995749, 0.01000846, 0.0100334 , 0.01000121, 0.00998332,\n","         0.01006223, 0.00994448, 0.01003392, 0.00998972, 0.01008601,\n","         0.01003099, 0.00997711, 0.00990651, 0.00997108, 0.01002098,\n","         0.01003992, 0.00998691, 0.00998994, 0.01001123, 0.00999378,\n","         0.00999762, 0.01003764, 0.01002132, 0.00999854, 0.0100242 ,\n","         0.00996914, 0.0099204 , 0.01001819, 0.00999651, 0.00997217,\n","         0.00997402, 0.00996936, 0.0100808 , 0.00990663, 0.00988592,\n","         0.00995869, 0.01009282, 0.01008691, 0.01001278, 0.00993429,\n","         0.01002564, 0.00995992, 0.01011677, 0.0100519 , 0.01011788,\n","         0.01010212, 0.00998442, 0.00997197, 0.00997982, 0.01008981,\n","         0.00994345, 0.00993701, 0.00997739, 0.01000491, 0.00998152],\n","        [0.01000828, 0.0100147 , 0.01000813, 0.00996418, 0.00999694,\n","         0.01003569, 0.00995759, 0.01004737, 0.00998431, 0.0099461 ,\n","         0.00991511, 0.00992999, 0.01005506, 0.01001922, 0.00995052,\n","         0.0100417 , 0.01003076, 0.01001046, 0.01004621, 0.01005848,\n","         0.01001322, 0.00997267, 0.01010445, 0.00998206, 0.01000107,\n","         0.01000629, 0.00989687, 0.00999997, 0.00999514, 0.00997263,\n","         0.00994565, 0.01005065, 0.01001957, 0.01001135, 0.00993715,\n","         0.01007934, 0.00992132, 0.00999871, 0.01001446, 0.01001299,\n","         0.01006455, 0.00996916, 0.01001066, 0.0100248 , 0.00989129,\n","         0.00995148, 0.00998831, 0.01005006, 0.010022  , 0.00997881,\n","         0.01005097, 0.00997749, 0.0100126 , 0.00999983, 0.01007924,\n","         0.0100101 , 0.00994815, 0.00991448, 0.01000301, 0.00999889,\n","         0.01007306, 0.00998854, 0.00996519, 0.00999405, 0.00995226,\n","         0.01003097, 0.01005823, 0.00999574, 0.01001087, 0.00999603,\n","         0.00996604, 0.00993135, 0.01000827, 0.01001351, 0.00994925,\n","         0.00993376, 0.0100033 , 0.01004077, 0.0099321 , 0.00987811,\n","         0.00995805, 0.01005452, 0.01010457, 0.00997171, 0.00994072,\n","         0.01004914, 0.00995636, 0.01009874, 0.01003839, 0.01008472,\n","         0.01007851, 0.00995856, 0.0099814 , 0.01002507, 0.01006594,\n","         0.0099575 , 0.00996161, 0.01001692, 0.0100533 , 0.01002058],\n","        [0.00994235, 0.01003615, 0.01002273, 0.00998869, 0.01001554,\n","         0.01004139, 0.00996039, 0.01001227, 0.00997257, 0.00993209,\n","         0.00986717, 0.00989153, 0.01012225, 0.00992853, 0.00995708,\n","         0.01002777, 0.01009678, 0.01003842, 0.01005868, 0.01010429,\n","         0.0099714 , 0.0099395 , 0.01014607, 0.00999263, 0.0099882 ,\n","         0.01001118, 0.00985698, 0.00999456, 0.01004277, 0.00995282,\n","         0.00991365, 0.01004899, 0.01002204, 0.01002857, 0.00993317,\n","         0.01012497, 0.00985132, 0.01003803, 0.00998528, 0.01000643,\n","         0.00999546, 0.00997599, 0.00996644, 0.01004389, 0.00982872,\n","         0.00989661, 0.01002922, 0.01003967, 0.01004761, 0.00995365,\n","         0.01004643, 0.01000498, 0.01003256, 0.0100015 , 0.01013447,\n","         0.00998653, 0.00991264, 0.00985578, 0.00998051, 0.00999312,\n","         0.01007515, 0.01000697, 0.00995001, 0.01002648, 0.00993404,\n","         0.01010204, 0.0101301 , 0.00996119, 0.01002347, 0.00996016,\n","         0.0099433 , 0.00993142, 0.00998702, 0.00998395, 0.00994207,\n","         0.00988279, 0.01000349, 0.01008683, 0.00989305, 0.00988632,\n","         0.00994924, 0.00999817, 0.01016698, 0.00997711, 0.00991058,\n","         0.01003126, 0.00995763, 0.01017126, 0.01005873, 0.01011067,\n","         0.01013566, 0.00992065, 0.0100248 , 0.01003421, 0.01011223,\n","         0.00998193, 0.00999321, 0.01000477, 0.01012968, 0.01003037]]],\n","      dtype=float32)>"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["Decoder for inference (prediction)"],"metadata":{"id":"jmicc5L2VluY"}},{"cell_type":"code","source":["decoder_state_input_h = Input(shape=(n_lstm,))\n","decoder_state_input_c = Input(shape=(n_lstm,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","# at the first step of the inference, these input will be respectively the\n","# hidden state and C state of the encoder model\n","# for following steps, they will become the hidden and C state from the decoder\n","# itself since the input sequence is unknown we will have to predict step by step\n","# using a loop\n","\n","decoder_input_inf = tf.keras.Input(shape=(1,))\n","decoder_embed_output = decoder_embed(decoder_input_inf)\n","# the decoder input here is of shape 1 because we will feed the elements in the\n","# sequence one by one\n","\n","decoder_outputs, state_h, state_c = decoder_lstm(decoder_embed_output, initial_state=decoder_states_inputs)\n","# the lstm layer works in the same way, the output from the embedding is used\n","# and the decoder state is used as described above\n","\n","decoder_states = [state_h, state_c]\n","# we store the lstm states in a specific object as we'll have to use them as\n","# initial state for the next inference step\n","\n","decoder_outputs = decoder_pred(decoder_outputs)\n","# the lstm output is then converted to a probability distribution over the\n","# target vocabulary\n","\n","decoder_inf = Model(inputs = [decoder_input_inf, decoder_states_inputs],\n","                     outputs = [decoder_outputs, decoder_states])\n","# Finally we wrap up the model building by setting up the inputs and outputs"],"metadata":{"id":"frkbmFaKVZw_","executionInfo":{"status":"ok","timestamp":1736279834622,"user_tz":-60,"elapsed":228,"user":{"displayName":"marie-sophie chenevier","userId":"01317793668247273219"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["enc_input = tf.expand_dims(X_train[0],0)\n","#classic encoder input\n","\n","dec_input = tf.zeros(shape=(1,1))\n","# the first decoder input is the special token 0\n","\n","enc_out, state_h_inf, state_c_inf = encoder(enc_input)\n","# we compute once and for all the encoder output and the encoder\n","# h state and c state\n","\n","dec_state = [state_h_inf, state_c_inf]\n","# The encoder h state and c state will serve as initial states for the\n","# decoder\n","\n","pred = []  # we'll store the predictions in here\n","\n","# we loop over the expected length of the target, but actually the loop can run\n","# for as many steps as we wish, which is the advantage of the encoder decoder\n","# architecture\n","for i in range(target_seq_len):\n","  dec_out, dec_state = decoder_inf([dec_input, dec_state])\n","  # the decoder state is updated and we get the first prediction probability\n","  # vector\n","  decoded_out = tf.argmax(dec_out, axis=-1)\n","  # we decode the softmax vector into and index\n","  pred.append(decoded_out) # update the prediction list\n","  dec_input = decoded_out # the previous pred will be used as the new input\n","\n","pred"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4eta9rtjVujm","executionInfo":{"status":"ok","timestamp":1736279878635,"user_tz":-60,"elapsed":320,"user":{"displayName":"marie-sophie chenevier","userId":"01317793668247273219"}},"outputId":"d524277e-0ac5-40c4-f8f0-bfc22994c9c5"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[89]])>,\n"," <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[35]])>,\n"," <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[82]])>,\n"," <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[54]])>,\n"," <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[9]])>]"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","source":["# Training the encoder decoder model"],"metadata":{"id":"lng_-qhKWNLv"}},{"cell_type":"code","source":["decoder.compile(\n","    optimizer=\"Adam\",\n","    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",")"],"metadata":{"id":"TBnb2HQZWGlc","executionInfo":{"status":"ok","timestamp":1736279928890,"user_tz":-60,"elapsed":232,"user":{"displayName":"marie-sophie chenevier","userId":"01317793668247273219"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["decoder.fit(x=[X_train,padded_y_train],y=y_train,epochs=50, validation_data=([X_val,padded_y_val],y_val))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zCMcM7MWWS4K","executionInfo":{"status":"ok","timestamp":1736280200412,"user_tz":-60,"elapsed":263242,"user":{"displayName":"marie-sophie chenevier","userId":"01317793668247273219"}},"outputId":"8e794c6f-e162-4cac-944f-01c784aa1afd"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 4.5739 - sparse_categorical_accuracy: 0.0155 - val_loss: 4.4166 - val_sparse_categorical_accuracy: 0.0316\n","Epoch 2/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 4.3589 - sparse_categorical_accuracy: 0.0390 - val_loss: 4.2080 - val_sparse_categorical_accuracy: 0.0605\n","Epoch 3/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 4.1423 - sparse_categorical_accuracy: 0.0670 - val_loss: 4.0470 - val_sparse_categorical_accuracy: 0.0816\n","Epoch 4/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 3.9788 - sparse_categorical_accuracy: 0.0895 - val_loss: 3.9123 - val_sparse_categorical_accuracy: 0.0987\n","Epoch 5/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 3.8368 - sparse_categorical_accuracy: 0.1113 - val_loss: 3.7582 - val_sparse_categorical_accuracy: 0.1261\n","Epoch 6/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 3.6828 - sparse_categorical_accuracy: 0.1335 - val_loss: 3.5993 - val_sparse_categorical_accuracy: 0.1466\n","Epoch 7/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 3.5097 - sparse_categorical_accuracy: 0.1623 - val_loss: 3.4256 - val_sparse_categorical_accuracy: 0.1806\n","Epoch 8/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 3.3449 - sparse_categorical_accuracy: 0.1924 - val_loss: 3.2829 - val_sparse_categorical_accuracy: 0.2020\n","Epoch 9/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 3.1919 - sparse_categorical_accuracy: 0.2256 - val_loss: 3.1313 - val_sparse_categorical_accuracy: 0.2335\n","Epoch 10/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 3.0398 - sparse_categorical_accuracy: 0.2531 - val_loss: 2.9883 - val_sparse_categorical_accuracy: 0.2640\n","Epoch 11/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.9045 - sparse_categorical_accuracy: 0.2811 - val_loss: 2.8520 - val_sparse_categorical_accuracy: 0.2916\n","Epoch 12/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 2.7678 - sparse_categorical_accuracy: 0.3143 - val_loss: 2.7171 - val_sparse_categorical_accuracy: 0.3252\n","Epoch 13/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 2.6374 - sparse_categorical_accuracy: 0.3423 - val_loss: 2.5870 - val_sparse_categorical_accuracy: 0.3512\n","Epoch 14/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.5087 - sparse_categorical_accuracy: 0.3748 - val_loss: 2.4598 - val_sparse_categorical_accuracy: 0.3828\n","Epoch 15/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 2.3850 - sparse_categorical_accuracy: 0.4042 - val_loss: 2.3382 - val_sparse_categorical_accuracy: 0.4136\n","Epoch 16/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 2.2679 - sparse_categorical_accuracy: 0.4324 - val_loss: 2.2470 - val_sparse_categorical_accuracy: 0.4260\n","Epoch 17/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 2.1580 - sparse_categorical_accuracy: 0.4567 - val_loss: 2.1177 - val_sparse_categorical_accuracy: 0.4612\n","Epoch 18/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 2.0582 - sparse_categorical_accuracy: 0.4804 - val_loss: 2.0217 - val_sparse_categorical_accuracy: 0.4830\n","Epoch 19/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 1.9535 - sparse_categorical_accuracy: 0.5052 - val_loss: 1.9520 - val_sparse_categorical_accuracy: 0.4956\n","Epoch 20/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.8613 - sparse_categorical_accuracy: 0.5281 - val_loss: 1.8884 - val_sparse_categorical_accuracy: 0.5068\n","Epoch 21/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 1.7825 - sparse_categorical_accuracy: 0.5459 - val_loss: 1.7987 - val_sparse_categorical_accuracy: 0.5278\n","Epoch 22/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 1.7039 - sparse_categorical_accuracy: 0.5616 - val_loss: 1.7098 - val_sparse_categorical_accuracy: 0.5539\n","Epoch 23/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.6218 - sparse_categorical_accuracy: 0.5860 - val_loss: 1.6289 - val_sparse_categorical_accuracy: 0.5770\n","Epoch 24/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 1.5553 - sparse_categorical_accuracy: 0.5992 - val_loss: 1.5594 - val_sparse_categorical_accuracy: 0.5865\n","Epoch 25/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 1.4915 - sparse_categorical_accuracy: 0.6148 - val_loss: 1.5003 - val_sparse_categorical_accuracy: 0.6076\n","Epoch 26/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.4215 - sparse_categorical_accuracy: 0.6349 - val_loss: 1.4350 - val_sparse_categorical_accuracy: 0.6213\n","Epoch 27/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 1.3700 - sparse_categorical_accuracy: 0.6463 - val_loss: 1.3962 - val_sparse_categorical_accuracy: 0.6292\n","Epoch 28/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.3186 - sparse_categorical_accuracy: 0.6560 - val_loss: 1.3492 - val_sparse_categorical_accuracy: 0.6456\n","Epoch 29/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 1.2678 - sparse_categorical_accuracy: 0.6723 - val_loss: 1.2650 - val_sparse_categorical_accuracy: 0.6688\n","Epoch 30/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.2072 - sparse_categorical_accuracy: 0.6863 - val_loss: 1.2559 - val_sparse_categorical_accuracy: 0.6654\n","Epoch 31/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 1.1756 - sparse_categorical_accuracy: 0.6957 - val_loss: 1.2059 - val_sparse_categorical_accuracy: 0.6837\n","Epoch 32/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 1.1230 - sparse_categorical_accuracy: 0.7100 - val_loss: 1.1583 - val_sparse_categorical_accuracy: 0.6929\n","Epoch 33/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 1.0864 - sparse_categorical_accuracy: 0.7214 - val_loss: 1.1257 - val_sparse_categorical_accuracy: 0.7030\n","Epoch 34/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 1.0564 - sparse_categorical_accuracy: 0.7261 - val_loss: 1.1050 - val_sparse_categorical_accuracy: 0.7037\n","Epoch 35/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 1.0082 - sparse_categorical_accuracy: 0.7388 - val_loss: 1.0664 - val_sparse_categorical_accuracy: 0.7158\n","Epoch 36/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.9760 - sparse_categorical_accuracy: 0.7501 - val_loss: 1.0538 - val_sparse_categorical_accuracy: 0.7175\n","Epoch 37/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.9468 - sparse_categorical_accuracy: 0.7550 - val_loss: 1.0264 - val_sparse_categorical_accuracy: 0.7225\n","Epoch 38/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.9153 - sparse_categorical_accuracy: 0.7634 - val_loss: 0.9878 - val_sparse_categorical_accuracy: 0.7328\n","Epoch 39/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.8848 - sparse_categorical_accuracy: 0.7729 - val_loss: 0.9329 - val_sparse_categorical_accuracy: 0.7531\n","Epoch 40/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.8478 - sparse_categorical_accuracy: 0.7831 - val_loss: 0.9070 - val_sparse_categorical_accuracy: 0.7606\n","Epoch 41/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.8302 - sparse_categorical_accuracy: 0.7831 - val_loss: 0.8653 - val_sparse_categorical_accuracy: 0.7729\n","Epoch 42/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.8152 - sparse_categorical_accuracy: 0.7902 - val_loss: 0.8404 - val_sparse_categorical_accuracy: 0.7796\n","Epoch 43/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.7949 - sparse_categorical_accuracy: 0.7949 - val_loss: 0.8262 - val_sparse_categorical_accuracy: 0.7820\n","Epoch 44/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.7763 - sparse_categorical_accuracy: 0.7980 - val_loss: 0.8076 - val_sparse_categorical_accuracy: 0.7831\n","Epoch 45/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - loss: 0.7386 - sparse_categorical_accuracy: 0.8135 - val_loss: 0.7739 - val_sparse_categorical_accuracy: 0.7983\n","Epoch 46/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.7176 - sparse_categorical_accuracy: 0.8153 - val_loss: 0.7815 - val_sparse_categorical_accuracy: 0.7912\n","Epoch 47/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.7108 - sparse_categorical_accuracy: 0.8159 - val_loss: 0.7899 - val_sparse_categorical_accuracy: 0.7872\n","Epoch 48/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.6971 - sparse_categorical_accuracy: 0.8182 - val_loss: 0.7546 - val_sparse_categorical_accuracy: 0.7962\n","Epoch 49/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.6701 - sparse_categorical_accuracy: 0.8261 - val_loss: 0.7207 - val_sparse_categorical_accuracy: 0.8059\n","Epoch 50/50\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.6571 - sparse_categorical_accuracy: 0.8319 - val_loss: 0.6880 - val_sparse_categorical_accuracy: 0.8184\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7d6a26c36ce0>"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["# Make predictions with the inference model"],"metadata":{"id":"J__5rx-2WhyJ"}},{"cell_type":"code","source":["enc_input = X_val\n","#classic encoder input\n","\n","dec_input = tf.zeros(shape=(len(X_val),1))\n","# the first decoder input is the special token 0\n","\n","enc_out, state_h_inf, state_c_inf = encoder(enc_input)\n","# we compute once and for all the encoder output and the encoder\n","# h state and c state\n","\n","dec_state = [state_h_inf, state_c_inf]\n","# The encoder h state and c state will serve as initial states for the\n","# decoder\n","\n","pred = []  # we'll store the predictions in here\n","\n","# we loop over the expected length of the target, but actually the loop can run\n","# for as many steps as we wish, which is the advantage of the encoder decoder\n","# architecture\n","for i in range(target_seq_len):\n","  dec_out, dec_state = decoder_inf([dec_input, dec_state])\n","  # the decoder state is updated and we get the first prediction probability\n","  # vector\n","  decoded_out = tf.argmax(dec_out, axis=-1)\n","  # we decode the softmax vector into and index\n","  pred.append(decoded_out) # update the prediction list\n","  dec_input = decoded_out # the previous pred will be used as the new input\n","\n","pred = tf.concat(pred, axis=-1).numpy()\n","for i in range(10):\n","  print(\"pred:\", pred[i,:])\n","  print(\"true:\", y_val[i,:])\n","  print(\"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3N7rQ0RqWU9A","executionInfo":{"status":"ok","timestamp":1736280200800,"user_tz":-60,"elapsed":392,"user":{"displayName":"marie-sophie chenevier","userId":"01317793668247273219"}},"outputId":"c7d87999-4adf-4f9b-8dee-c29a2cff73dd"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["pred: [68 27 86 21 45]\n","true: [64 12 21 61 27]\n","\n","\n","pred: [88 49 95 12 77]\n","true: [88 49 95 77 88]\n","\n","\n","pred: [ 5 44 34 13 25]\n","true: [ 5 44 34 49 11]\n","\n","\n","pred: [85 54 92 16 43]\n","true: [85 54 92 76 43]\n","\n","\n","pred: [17 73 25 95 20]\n","true: [17 73 25 95 20]\n","\n","\n","pred: [71 18 49 35 71]\n","true: [71 18 87 27 24]\n","\n","\n","pred: [90  1 18 84 90]\n","true: [90  1 18 84 94]\n","\n","\n","pred: [82 72  7 43  4]\n","true: [82 72 55 51 75]\n","\n","\n","pred: [36 14 77 42 44]\n","true: [36 14 77  9 31]\n","\n","\n","pred: [32 69 33 57 65]\n","true: [ 8 33 49 56 88]\n","\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"pLMBhIVNWis-"},"execution_count":null,"outputs":[]}]}