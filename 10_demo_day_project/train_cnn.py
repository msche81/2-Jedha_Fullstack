import os
import tensorflow as tf
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import (
    Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Dropout, 
    BatchNormalization, Input
)
from tensorflow.keras.regularizers import l2
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from data_pipeline import get_data
import mlflow
import mlflow.tensorflow
from mlflow.models import ModelSignature
from mlflow.types.schema import Schema, TensorSpec

# ðŸ“Œ DÃ©finition des paramÃ¨tres
batch_size = 32
img_size = (224, 224)
num_classes = 3  # Dry, Normal, Oily
learning_rate = 0.005
num_epochs = 2

# ðŸ“Œ Initialisation de MLflow
mlflow.set_experiment("cnn_skin_type_classification")

with mlflow.start_run():
    print("âœ… MLflow Run dÃ©marrÃ©")

    # ðŸ“Œ Log des hyperparamÃ¨tres
    mlflow.log_param("batch_size", batch_size)
    mlflow.log_param("img_size", img_size)
    mlflow.log_param("num_classes", num_classes)
    mlflow.log_param("learning_rate", learning_rate)
    mlflow.log_param("num_epochs", num_epochs)

    print("âœ… HyperparamÃ¨tres loggÃ©s dans MLflow")

    # ðŸ“Œ Chargement des donnÃ©es
    train_generator, valid_generator, test_generator, _ = get_data(batch_size, img_size)
    print("âœ… Infos des datasets loggÃ©es dans MLflow")

    # ðŸ“Œ DÃ©finition du modÃ¨le CNN
    model = Sequential([
        Input(shape=(224, 224, 3)),  
        Conv2D(32, (3,3), activation='relu'),
        BatchNormalization(),
        MaxPooling2D(pool_size=(2,2)),

        Conv2D(64, (3,3), activation='relu'),
        BatchNormalization(),
        MaxPooling2D(pool_size=(2,2)),

        Conv2D(128, (3,3), activation='relu'),
        BatchNormalization(),
        MaxPooling2D(pool_size=(2,2)),

        GlobalAveragePooling2D(),
        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),
        Dropout(0.6),
        Dense(32, activation='relu', kernel_regularizer=l2(0.01)),
        Dense(num_classes, activation='softmax')
    ])

    # ðŸ“Œ Compilation du modÃ¨le
    model.compile(
        optimizer=Adam(learning_rate=learning_rate),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    # ðŸ“Œ EarlyStopping pour Ã©viter l'overfitting
    early_stopping = EarlyStopping(
        monitor="val_loss", patience=2, restore_best_weights=True, verbose=1
    )

    # ðŸ“Œ DÃ©sactivation de l'autolog car il empÃªche la signature manuelle
    mlflow.tensorflow.autolog(disable=True)

    # ðŸ“Œ Exemple d'entrÃ©e pour la signature MLflow (PRÃ‰LEVÃ‰ DU DATASET)
    example_batch = next(iter(train_generator))  # Prend un batch de l'iterator
    example_input = example_batch[0][:1]  # On prend la premiÃ¨re image

    # ðŸ“Œ DÃ©finition manuelle de la signature du modÃ¨le
    signature = ModelSignature(
        inputs=Schema([TensorSpec(np.dtype(np.float32), (-1, 224, 224, 3), name="input_image")]),
        outputs=Schema([TensorSpec(np.dtype(np.float32), (-1, num_classes), name="output_probabilities")])
    )

    # ðŸ“Œ EntraÃ®nement du modÃ¨le
    history = model.fit(
        train_generator,
        epochs=num_epochs,
        validation_data=valid_generator,
        callbacks=[early_stopping],
        verbose=1
    )

    # ðŸ“Œ Enregistrement des mÃ©triques finales
    final_loss, final_acc = model.evaluate(valid_generator)
    mlflow.log_metric("final_loss", final_loss)
    mlflow.log_metric("final_accuracy", final_acc)

    # ðŸ“Œ Enregistrement du modÃ¨le avec signature et input_example
    mlflow.tensorflow.log_model(
        model, 
        "cnn_model",
        signature=signature, 
        input_example=example_input
    )

    print(f"âœ… ModÃ¨le enregistrÃ© dans MLflow avec une accuracy de {final_acc:.4f}")

# ðŸ“Œ Affichage du rÃ©sumÃ© du modÃ¨le
model.summary()