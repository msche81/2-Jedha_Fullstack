{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edca343e-87a4-4ab3-a756-5e9cb2d1a15c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "items_exploded_path = \"s3://full-stack-bigdata-datasets/Big_Data/YOUTUBE/items_exploded.json\"\n",
    "\n",
    "df = spark.read.json(items_exploded_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b16018c-1a0d-43e4-8cb8-bcbc1fc0b045",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[2]: 3907"
     ]
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b65794b-fb96-44d3-995f-029d5ffb866a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- items: struct (nullable = true)\n |    |-- contentDetails: struct (nullable = true)\n |    |    |-- caption: string (nullable = true)\n |    |    |-- contentRating: struct (nullable = true)\n |    |    |    |-- ytRating: string (nullable = true)\n |    |    |-- definition: string (nullable = true)\n |    |    |-- dimension: string (nullable = true)\n |    |    |-- duration: string (nullable = true)\n |    |    |-- licensedContent: boolean (nullable = true)\n |    |    |-- projection: string (nullable = true)\n |    |    |-- regionRestriction: struct (nullable = true)\n |    |    |    |-- allowed: array (nullable = true)\n |    |    |    |    |-- element: string (containsNull = true)\n |    |    |    |-- blocked: array (nullable = true)\n |    |    |    |    |-- element: string (containsNull = true)\n |    |-- etag: string (nullable = true)\n |    |-- id: string (nullable = true)\n |    |-- kind: string (nullable = true)\n |    |-- snippet: struct (nullable = true)\n |    |    |-- categoryId: string (nullable = true)\n |    |    |-- channelId: string (nullable = true)\n |    |    |-- channelTitle: string (nullable = true)\n |    |    |-- defaultAudioLanguage: string (nullable = true)\n |    |    |-- defaultLanguage: string (nullable = true)\n |    |    |-- description: string (nullable = true)\n |    |    |-- liveBroadcastContent: string (nullable = true)\n |    |    |-- localized: struct (nullable = true)\n |    |    |    |-- description: string (nullable = true)\n |    |    |    |-- title: string (nullable = true)\n |    |    |-- publishedAt: string (nullable = true)\n |    |    |-- tags: array (nullable = true)\n |    |    |    |-- element: string (containsNull = true)\n |    |    |-- thumbnails: struct (nullable = true)\n |    |    |    |-- default: struct (nullable = true)\n |    |    |    |    |-- height: long (nullable = true)\n |    |    |    |    |-- url: string (nullable = true)\n |    |    |    |    |-- width: long (nullable = true)\n |    |    |    |-- high: struct (nullable = true)\n |    |    |    |    |-- height: long (nullable = true)\n |    |    |    |    |-- url: string (nullable = true)\n |    |    |    |    |-- width: long (nullable = true)\n |    |    |    |-- maxres: struct (nullable = true)\n |    |    |    |    |-- height: long (nullable = true)\n |    |    |    |    |-- url: string (nullable = true)\n |    |    |    |    |-- width: long (nullable = true)\n |    |    |    |-- medium: struct (nullable = true)\n |    |    |    |    |-- height: long (nullable = true)\n |    |    |    |    |-- url: string (nullable = true)\n |    |    |    |    |-- width: long (nullable = true)\n |    |    |    |-- standard: struct (nullable = true)\n |    |    |    |    |-- height: long (nullable = true)\n |    |    |    |    |-- url: string (nullable = true)\n |    |    |    |    |-- width: long (nullable = true)\n |    |    |-- title: string (nullable = true)\n |    |-- statistics: struct (nullable = true)\n |    |    |-- commentCount: string (nullable = true)\n |    |    |-- dislikeCount: string (nullable = true)\n |    |    |-- favoriteCount: string (nullable = true)\n |    |    |-- likeCount: string (nullable = true)\n |    |    |-- viewCount: string (nullable = true)\n |    |-- status: struct (nullable = true)\n |    |    |-- embeddable: boolean (nullable = true)\n |    |    |-- license: string (nullable = true)\n |    |    |-- madeForKids: boolean (nullable = true)\n |    |    |-- privacyStatus: string (nullable = true)\n |    |    |-- publicStatsViewable: boolean (nullable = true)\n |    |    |-- uploadStatus: string (nullable = true)\n |    |-- topicDetails: struct (nullable = true)\n |    |    |-- relevantTopicIds: array (nullable = true)\n |    |    |    |-- element: string (containsNull = true)\n |    |    |-- topicCategories: array (nullable = true)\n |    |    |    |-- element: string (containsNull = true)\n\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1892be06-5d1e-4527-a2ca-09c739714f34",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n|               title|\n+--------------------+\n|VOLO. \"L'air d'un...|\n|Julian Jeweil - A...|\n| Justice - D.A.N.C.E|\n|Gramatik - Tortur...|\n|Ben Howard - Oats...|\n+--------------------+\nonly showing top 5 rows\n\nOut[4]: DataFrame[items: struct<contentDetails:struct<caption:string,contentRating:struct<ytRating:string>,definition:string,dimension:string,duration:string,licensedContent:boolean,projection:string,regionRestriction:struct<allowed:array<string>,blocked:array<string>>>,etag:string,id:string,kind:string,snippet:struct<categoryId:string,channelId:string,channelTitle:string,defaultAudioLanguage:string,defaultLanguage:string,description:string,liveBroadcastContent:string,localized:struct<description:string,title:string>,publishedAt:string,tags:array<string>,thumbnails:struct<default:struct<height:bigint,url:string,width:bigint>,high:struct<height:bigint,url:string,width:bigint>,maxres:struct<height:bigint,url:string,width:bigint>,medium:struct<height:bigint,url:string,width:bigint>,standard:struct<height:bigint,url:string,width:bigint>>,title:string>,statistics:struct<commentCount:string,dislikeCount:string,favoriteCount:string,likeCount:string,viewCount:string>,status:struct<embeddable:boolean,license:string,madeForKids:boolean,privacyStatus:string,publicStatsViewable:boolean,uploadStatus:string>,topicDetails:struct<relevantTopicIds:array<string>,topicCategories:array<string>>>, items.snippet.title: string]"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df.select('items.snippet.title').show(5)\n",
    "df.withColumn('items.snippet.title', F.col('items.snippet.title'))\n",
    "# Alternative\n",
    "# df.select(F.col('items').getField('snippet').getField('title')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44057283-22ea-4354-8cf8-7dbb7a27857d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[5]: {'type': 'struct',\n 'fields': [{'name': 'items',\n   'type': {'type': 'struct',\n    'fields': [{'name': 'contentDetails',\n      'type': {'type': 'struct',\n       'fields': [{'name': 'caption',\n         'type': 'string',\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'contentRating',\n         'type': {'type': 'struct',\n          'fields': [{'name': 'ytRating',\n            'type': 'string',\n            'nullable': True,\n            'metadata': {}}]},\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'definition',\n         'type': 'string',\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'dimension',\n         'type': 'string',\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'duration',\n         'type': 'string',\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'licensedContent',\n         'type': 'boolean',\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'projection',\n         'type': 'string',\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'regionRestriction',\n         'type': {'type': 'struct',\n          'fields': [{'name': 'allowed',\n            'type': {'type': 'array',\n             'elementType': 'string',\n             'containsNull': True},\n            'nullable': True,\n            'metadata': {}},\n           {'name': 'blocked',\n            'type': {'type': 'array',\n             'elementType': 'string',\n             'containsNull': True},\n            'nullable': True,\n            'metadata': {}}]},\n         'nullable': True,\n         'metadata': {}}]},\n      'nullable': True,\n      'metadata': {}},\n     {'name': 'etag', 'type': 'string', 'nullable': True, 'metadata': {}},\n     {'name': 'id', 'type': 'string', 'nullable': True, 'metadata': {}},\n     {'name': 'kind', 'type': 'string', 'nullable': True, 'metadata': {}},\n     {'name': 'snippet',\n      'type': {'type': 'struct',\n       'fields': [{'name': 'categoryId',\n         'type': 'string',\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'channelId',\n         'type': 'string',\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'channelTitle',\n         'type': 'string',\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'defaultAudioLanguage',\n         'type': 'string',\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'defaultLanguage',\n         'type': 'string',\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'description',\n         'type': 'string',\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'liveBroadcastContent',\n         'type': 'string',\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'localized',\n         'type': {'type': 'struct',\n          'fields': [{'name': 'description',\n            'type': 'string',\n            'nullable': True,\n            'metadata': {}},\n           {'name': 'title',\n            'type': 'string',\n            'nullable': True,\n            'metadata': {}}]},\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'publishedAt',\n         'type': 'string',\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'tags',\n         'type': {'type': 'array',\n          'elementType': 'string',\n          'containsNull': True},\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'thumbnails',\n         'type': {'type': 'struct',\n          'fields': [{'name': 'default',\n            'type': {'type': 'struct',\n             'fields': [{'name': 'height',\n               'type': 'long',\n               'nullable': True,\n               'metadata': {}},\n              {'name': 'url',\n               'type': 'string',\n               'nullable': True,\n               'metadata': {}},\n              {'name': 'width',\n               'type': 'long',\n               'nullable': True,\n               'metadata': {}}]},\n            'nullable': True,\n            'metadata': {}},\n           {'name': 'high',\n            'type': {'type': 'struct',\n             'fields': [{'name': 'height',\n               'type': 'long',\n               'nullable': True,\n               'metadata': {}},\n              {'name': 'url',\n               'type': 'string',\n               'nullable': True,\n               'metadata': {}},\n              {'name': 'width',\n               'type': 'long',\n               'nullable': True,\n               'metadata': {}}]},\n            'nullable': True,\n            'metadata': {}},\n           {'name': 'maxres',\n            'type': {'type': 'struct',\n             'fields': [{'name': 'height',\n               'type': 'long',\n               'nullable': True,\n               'metadata': {}},\n              {'name': 'url',\n               'type': 'string',\n               'nullable': True,\n               'metadata': {}},\n              {'name': 'width',\n               'type': 'long',\n               'nullable': True,\n               'metadata': {}}]},\n            'nullable': True,\n            'metadata': {}},\n           {'name': 'medium',\n            'type': {'type': 'struct',\n             'fields': [{'name': 'height',\n               'type': 'long',\n               'nullable': True,\n               'metadata': {}},\n              {'name': 'url',\n               'type': 'string',\n               'nullable': True,\n               'metadata': {}},\n              {'name': 'width',\n               'type': 'long',\n               'nullable': True,\n               'metadata': {}}]},\n            'nullable': True,\n            'metadata': {}},\n           {'name': 'standard',\n            'type': {'type': 'struct',\n             'fields': [{'name': 'height',\n               'type': 'long',\n               'nullable': True,\n               'metadata': {}},\n              {'name': 'url',\n               'type': 'string',\n               'nullable': True,\n               'metadata': {}},\n              {'name': 'width',\n               'type': 'long',\n               'nullable': True,\n               'metadata': {}}]},\n            'nullable': True,\n            'metadata': {}}]},\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'title',\n         'type': 'string',\n         'nullable': True,\n         'metadata': {}}]},\n      'nullable': True,\n      'metadata': {}},\n     {'name': 'statistics',\n      'type': {'type': 'struct',\n       'fields': [{'name': 'commentCount',\n         'type': 'string',\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'dislikeCount',\n         'type': 'string',\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'favoriteCount',\n         'type': 'string',\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'likeCount',\n         'type': 'string',\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'viewCount',\n         'type': 'string',\n         'nullable': True,\n         'metadata': {}}]},\n      'nullable': True,\n      'metadata': {}},\n     {'name': 'status',\n      'type': {'type': 'struct',\n       'fields': [{'name': 'embeddable',\n         'type': 'boolean',\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'license',\n         'type': 'string',\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'madeForKids',\n         'type': 'boolean',\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'privacyStatus',\n         'type': 'string',\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'publicStatsViewable',\n         'type': 'boolean',\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'uploadStatus',\n         'type': 'string',\n         'nullable': True,\n         'metadata': {}}]},\n      'nullable': True,\n      'metadata': {}},\n     {'name': 'topicDetails',\n      'type': {'type': 'struct',\n       'fields': [{'name': 'relevantTopicIds',\n         'type': {'type': 'array',\n          'elementType': 'string',\n          'containsNull': True},\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'topicCategories',\n         'type': {'type': 'array',\n          'elementType': 'string',\n          'containsNull': True},\n         'nullable': True,\n         'metadata': {}}]},\n      'nullable': True,\n      'metadata': {}}]},\n   'nullable': True,\n   'metadata': {}}]}"
     ]
    }
   ],
   "source": [
    "# Let's give you the intuition for the flattening function we will share with you now\n",
    "# The idea is to automatically dig deeper and deeper into the schema in order to extract\n",
    "# all the column names in the form \"array1.array2.array3.field1\", let's go!\n",
    "\n",
    "# we'll work with the schema in json format, which will be way easier to manipulate\n",
    "df.schema.jsonValue()\n",
    "\n",
    "# It's nothing more than a dictionnary with keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3f0577e-1365-434f-b67f-49d1439e05ac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[6]: dict_keys(['type', 'fields'])"
     ]
    }
   ],
   "source": [
    "df.schema.jsonValue().keys()\n",
    "# Only two keys at this stage, type and fields, let's explore the type key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "724fe4e3-878b-4110-8368-e38c6c36bb1c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[7]: 'struct'"
     ]
    }
   ],
   "source": [
    "df.schema.jsonValue()[\"type\"]\n",
    "# The value associated is struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77bae7c2-a780-4bca-81df-c39664cb352d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[8]: [{'name': 'items',\n  'type': {'type': 'struct',\n   'fields': [{'name': 'contentDetails',\n     'type': {'type': 'struct',\n      'fields': [{'name': 'caption',\n        'type': 'string',\n        'nullable': True,\n        'metadata': {}},\n       {'name': 'contentRating',\n        'type': {'type': 'struct',\n         'fields': [{'name': 'ytRating',\n           'type': 'string',\n           'nullable': True,\n           'metadata': {}}]},\n        'nullable': True,\n        'metadata': {}},\n       {'name': 'definition',\n        'type': 'string',\n        'nullable': True,\n        'metadata': {}},\n       {'name': 'dimension',\n        'type': 'string',\n        'nullable': True,\n        'metadata': {}},\n       {'name': 'duration',\n        'type': 'string',\n        'nullable': True,\n        'metadata': {}},\n       {'name': 'licensedContent',\n        'type': 'boolean',\n        'nullable': True,\n        'metadata': {}},\n       {'name': 'projection',\n        'type': 'string',\n        'nullable': True,\n        'metadata': {}},\n       {'name': 'regionRestriction',\n        'type': {'type': 'struct',\n         'fields': [{'name': 'allowed',\n           'type': {'type': 'array',\n            'elementType': 'string',\n            'containsNull': True},\n           'nullable': True,\n           'metadata': {}},\n          {'name': 'blocked',\n           'type': {'type': 'array',\n            'elementType': 'string',\n            'containsNull': True},\n           'nullable': True,\n           'metadata': {}}]},\n        'nullable': True,\n        'metadata': {}}]},\n     'nullable': True,\n     'metadata': {}},\n    {'name': 'etag', 'type': 'string', 'nullable': True, 'metadata': {}},\n    {'name': 'id', 'type': 'string', 'nullable': True, 'metadata': {}},\n    {'name': 'kind', 'type': 'string', 'nullable': True, 'metadata': {}},\n    {'name': 'snippet',\n     'type': {'type': 'struct',\n      'fields': [{'name': 'categoryId',\n        'type': 'string',\n        'nullable': True,\n        'metadata': {}},\n       {'name': 'channelId',\n        'type': 'string',\n        'nullable': True,\n        'metadata': {}},\n       {'name': 'channelTitle',\n        'type': 'string',\n        'nullable': True,\n        'metadata': {}},\n       {'name': 'defaultAudioLanguage',\n        'type': 'string',\n        'nullable': True,\n        'metadata': {}},\n       {'name': 'defaultLanguage',\n        'type': 'string',\n        'nullable': True,\n        'metadata': {}},\n       {'name': 'description',\n        'type': 'string',\n        'nullable': True,\n        'metadata': {}},\n       {'name': 'liveBroadcastContent',\n        'type': 'string',\n        'nullable': True,\n        'metadata': {}},\n       {'name': 'localized',\n        'type': {'type': 'struct',\n         'fields': [{'name': 'description',\n           'type': 'string',\n           'nullable': True,\n           'metadata': {}},\n          {'name': 'title',\n           'type': 'string',\n           'nullable': True,\n           'metadata': {}}]},\n        'nullable': True,\n        'metadata': {}},\n       {'name': 'publishedAt',\n        'type': 'string',\n        'nullable': True,\n        'metadata': {}},\n       {'name': 'tags',\n        'type': {'type': 'array',\n         'elementType': 'string',\n         'containsNull': True},\n        'nullable': True,\n        'metadata': {}},\n       {'name': 'thumbnails',\n        'type': {'type': 'struct',\n         'fields': [{'name': 'default',\n           'type': {'type': 'struct',\n            'fields': [{'name': 'height',\n              'type': 'long',\n              'nullable': True,\n              'metadata': {}},\n             {'name': 'url',\n              'type': 'string',\n              'nullable': True,\n              'metadata': {}},\n             {'name': 'width',\n              'type': 'long',\n              'nullable': True,\n              'metadata': {}}]},\n           'nullable': True,\n           'metadata': {}},\n          {'name': 'high',\n           'type': {'type': 'struct',\n            'fields': [{'name': 'height',\n              'type': 'long',\n              'nullable': True,\n              'metadata': {}},\n             {'name': 'url',\n              'type': 'string',\n              'nullable': True,\n              'metadata': {}},\n             {'name': 'width',\n              'type': 'long',\n              'nullable': True,\n              'metadata': {}}]},\n           'nullable': True,\n           'metadata': {}},\n          {'name': 'maxres',\n           'type': {'type': 'struct',\n            'fields': [{'name': 'height',\n              'type': 'long',\n              'nullable': True,\n              'metadata': {}},\n             {'name': 'url',\n              'type': 'string',\n              'nullable': True,\n              'metadata': {}},\n             {'name': 'width',\n              'type': 'long',\n              'nullable': True,\n              'metadata': {}}]},\n           'nullable': True,\n           'metadata': {}},\n          {'name': 'medium',\n           'type': {'type': 'struct',\n            'fields': [{'name': 'height',\n              'type': 'long',\n              'nullable': True,\n              'metadata': {}},\n             {'name': 'url',\n              'type': 'string',\n              'nullable': True,\n              'metadata': {}},\n             {'name': 'width',\n              'type': 'long',\n              'nullable': True,\n              'metadata': {}}]},\n           'nullable': True,\n           'metadata': {}},\n          {'name': 'standard',\n           'type': {'type': 'struct',\n            'fields': [{'name': 'height',\n              'type': 'long',\n              'nullable': True,\n              'metadata': {}},\n             {'name': 'url',\n              'type': 'string',\n              'nullable': True,\n              'metadata': {}},\n             {'name': 'width',\n              'type': 'long',\n              'nullable': True,\n              'metadata': {}}]},\n           'nullable': True,\n           'metadata': {}}]},\n        'nullable': True,\n        'metadata': {}},\n       {'name': 'title', 'type': 'string', 'nullable': True, 'metadata': {}}]},\n     'nullable': True,\n     'metadata': {}},\n    {'name': 'statistics',\n     'type': {'type': 'struct',\n      'fields': [{'name': 'commentCount',\n        'type': 'string',\n        'nullable': True,\n        'metadata': {}},\n       {'name': 'dislikeCount',\n        'type': 'string',\n        'nullable': True,\n        'metadata': {}},\n       {'name': 'favoriteCount',\n        'type': 'string',\n        'nullable': True,\n        'metadata': {}},\n       {'name': 'likeCount',\n        'type': 'string',\n        'nullable': True,\n        'metadata': {}},\n       {'name': 'viewCount',\n        'type': 'string',\n        'nullable': True,\n        'metadata': {}}]},\n     'nullable': True,\n     'metadata': {}},\n    {'name': 'status',\n     'type': {'type': 'struct',\n      'fields': [{'name': 'embeddable',\n        'type': 'boolean',\n        'nullable': True,\n        'metadata': {}},\n       {'name': 'license', 'type': 'string', 'nullable': True, 'metadata': {}},\n       {'name': 'madeForKids',\n        'type': 'boolean',\n        'nullable': True,\n        'metadata': {}},\n       {'name': 'privacyStatus',\n        'type': 'string',\n        'nullable': True,\n        'metadata': {}},\n       {'name': 'publicStatsViewable',\n        'type': 'boolean',\n        'nullable': True,\n        'metadata': {}},\n       {'name': 'uploadStatus',\n        'type': 'string',\n        'nullable': True,\n        'metadata': {}}]},\n     'nullable': True,\n     'metadata': {}},\n    {'name': 'topicDetails',\n     'type': {'type': 'struct',\n      'fields': [{'name': 'relevantTopicIds',\n        'type': {'type': 'array',\n         'elementType': 'string',\n         'containsNull': True},\n        'nullable': True,\n        'metadata': {}},\n       {'name': 'topicCategories',\n        'type': {'type': 'array',\n         'elementType': 'string',\n         'containsNull': True},\n        'nullable': True,\n        'metadata': {}}]},\n     'nullable': True,\n     'metadata': {}}]},\n  'nullable': True,\n  'metadata': {}}]"
     ]
    }
   ],
   "source": [
    "# let's explore the content of the other key\n",
    "df.schema.jsonValue()[\"fields\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0d037a7-5755-4c51-bef0-977a32cb70c0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[9]: {'name': 'items',\n 'type': {'type': 'struct',\n  'fields': [{'name': 'contentDetails',\n    'type': {'type': 'struct',\n     'fields': [{'name': 'caption',\n       'type': 'string',\n       'nullable': True,\n       'metadata': {}},\n      {'name': 'contentRating',\n       'type': {'type': 'struct',\n        'fields': [{'name': 'ytRating',\n          'type': 'string',\n          'nullable': True,\n          'metadata': {}}]},\n       'nullable': True,\n       'metadata': {}},\n      {'name': 'definition',\n       'type': 'string',\n       'nullable': True,\n       'metadata': {}},\n      {'name': 'dimension',\n       'type': 'string',\n       'nullable': True,\n       'metadata': {}},\n      {'name': 'duration', 'type': 'string', 'nullable': True, 'metadata': {}},\n      {'name': 'licensedContent',\n       'type': 'boolean',\n       'nullable': True,\n       'metadata': {}},\n      {'name': 'projection',\n       'type': 'string',\n       'nullable': True,\n       'metadata': {}},\n      {'name': 'regionRestriction',\n       'type': {'type': 'struct',\n        'fields': [{'name': 'allowed',\n          'type': {'type': 'array',\n           'elementType': 'string',\n           'containsNull': True},\n          'nullable': True,\n          'metadata': {}},\n         {'name': 'blocked',\n          'type': {'type': 'array',\n           'elementType': 'string',\n           'containsNull': True},\n          'nullable': True,\n          'metadata': {}}]},\n       'nullable': True,\n       'metadata': {}}]},\n    'nullable': True,\n    'metadata': {}},\n   {'name': 'etag', 'type': 'string', 'nullable': True, 'metadata': {}},\n   {'name': 'id', 'type': 'string', 'nullable': True, 'metadata': {}},\n   {'name': 'kind', 'type': 'string', 'nullable': True, 'metadata': {}},\n   {'name': 'snippet',\n    'type': {'type': 'struct',\n     'fields': [{'name': 'categoryId',\n       'type': 'string',\n       'nullable': True,\n       'metadata': {}},\n      {'name': 'channelId',\n       'type': 'string',\n       'nullable': True,\n       'metadata': {}},\n      {'name': 'channelTitle',\n       'type': 'string',\n       'nullable': True,\n       'metadata': {}},\n      {'name': 'defaultAudioLanguage',\n       'type': 'string',\n       'nullable': True,\n       'metadata': {}},\n      {'name': 'defaultLanguage',\n       'type': 'string',\n       'nullable': True,\n       'metadata': {}},\n      {'name': 'description',\n       'type': 'string',\n       'nullable': True,\n       'metadata': {}},\n      {'name': 'liveBroadcastContent',\n       'type': 'string',\n       'nullable': True,\n       'metadata': {}},\n      {'name': 'localized',\n       'type': {'type': 'struct',\n        'fields': [{'name': 'description',\n          'type': 'string',\n          'nullable': True,\n          'metadata': {}},\n         {'name': 'title',\n          'type': 'string',\n          'nullable': True,\n          'metadata': {}}]},\n       'nullable': True,\n       'metadata': {}},\n      {'name': 'publishedAt',\n       'type': 'string',\n       'nullable': True,\n       'metadata': {}},\n      {'name': 'tags',\n       'type': {'type': 'array',\n        'elementType': 'string',\n        'containsNull': True},\n       'nullable': True,\n       'metadata': {}},\n      {'name': 'thumbnails',\n       'type': {'type': 'struct',\n        'fields': [{'name': 'default',\n          'type': {'type': 'struct',\n           'fields': [{'name': 'height',\n             'type': 'long',\n             'nullable': True,\n             'metadata': {}},\n            {'name': 'url',\n             'type': 'string',\n             'nullable': True,\n             'metadata': {}},\n            {'name': 'width',\n             'type': 'long',\n             'nullable': True,\n             'metadata': {}}]},\n          'nullable': True,\n          'metadata': {}},\n         {'name': 'high',\n          'type': {'type': 'struct',\n           'fields': [{'name': 'height',\n             'type': 'long',\n             'nullable': True,\n             'metadata': {}},\n            {'name': 'url',\n             'type': 'string',\n             'nullable': True,\n             'metadata': {}},\n            {'name': 'width',\n             'type': 'long',\n             'nullable': True,\n             'metadata': {}}]},\n          'nullable': True,\n          'metadata': {}},\n         {'name': 'maxres',\n          'type': {'type': 'struct',\n           'fields': [{'name': 'height',\n             'type': 'long',\n             'nullable': True,\n             'metadata': {}},\n            {'name': 'url',\n             'type': 'string',\n             'nullable': True,\n             'metadata': {}},\n            {'name': 'width',\n             'type': 'long',\n             'nullable': True,\n             'metadata': {}}]},\n          'nullable': True,\n          'metadata': {}},\n         {'name': 'medium',\n          'type': {'type': 'struct',\n           'fields': [{'name': 'height',\n             'type': 'long',\n             'nullable': True,\n             'metadata': {}},\n            {'name': 'url',\n             'type': 'string',\n             'nullable': True,\n             'metadata': {}},\n            {'name': 'width',\n             'type': 'long',\n             'nullable': True,\n             'metadata': {}}]},\n          'nullable': True,\n          'metadata': {}},\n         {'name': 'standard',\n          'type': {'type': 'struct',\n           'fields': [{'name': 'height',\n             'type': 'long',\n             'nullable': True,\n             'metadata': {}},\n            {'name': 'url',\n             'type': 'string',\n             'nullable': True,\n             'metadata': {}},\n            {'name': 'width',\n             'type': 'long',\n             'nullable': True,\n             'metadata': {}}]},\n          'nullable': True,\n          'metadata': {}}]},\n       'nullable': True,\n       'metadata': {}},\n      {'name': 'title', 'type': 'string', 'nullable': True, 'metadata': {}}]},\n    'nullable': True,\n    'metadata': {}},\n   {'name': 'statistics',\n    'type': {'type': 'struct',\n     'fields': [{'name': 'commentCount',\n       'type': 'string',\n       'nullable': True,\n       'metadata': {}},\n      {'name': 'dislikeCount',\n       'type': 'string',\n       'nullable': True,\n       'metadata': {}},\n      {'name': 'favoriteCount',\n       'type': 'string',\n       'nullable': True,\n       'metadata': {}},\n      {'name': 'likeCount',\n       'type': 'string',\n       'nullable': True,\n       'metadata': {}},\n      {'name': 'viewCount',\n       'type': 'string',\n       'nullable': True,\n       'metadata': {}}]},\n    'nullable': True,\n    'metadata': {}},\n   {'name': 'status',\n    'type': {'type': 'struct',\n     'fields': [{'name': 'embeddable',\n       'type': 'boolean',\n       'nullable': True,\n       'metadata': {}},\n      {'name': 'license', 'type': 'string', 'nullable': True, 'metadata': {}},\n      {'name': 'madeForKids',\n       'type': 'boolean',\n       'nullable': True,\n       'metadata': {}},\n      {'name': 'privacyStatus',\n       'type': 'string',\n       'nullable': True,\n       'metadata': {}},\n      {'name': 'publicStatsViewable',\n       'type': 'boolean',\n       'nullable': True,\n       'metadata': {}},\n      {'name': 'uploadStatus',\n       'type': 'string',\n       'nullable': True,\n       'metadata': {}}]},\n    'nullable': True,\n    'metadata': {}},\n   {'name': 'topicDetails',\n    'type': {'type': 'struct',\n     'fields': [{'name': 'relevantTopicIds',\n       'type': {'type': 'array',\n        'elementType': 'string',\n        'containsNull': True},\n       'nullable': True,\n       'metadata': {}},\n      {'name': 'topicCategories',\n       'type': {'type': 'array',\n        'elementType': 'string',\n        'containsNull': True},\n       'nullable': True,\n       'metadata': {}}]},\n    'nullable': True,\n    'metadata': {}}]},\n 'nullable': True,\n 'metadata': {}}"
     ]
    }
   ],
   "source": [
    "#it's a list, what's the first element?\n",
    "df.schema.jsonValue()[\"fields\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eca82324-ef0e-4ba0-9f48-512ed4639469",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[10]: dict_keys(['name', 'type', 'nullable', 'metadata'])"
     ]
    }
   ],
   "source": [
    "# what keys does it have ?\n",
    "df.schema.jsonValue()[\"fields\"][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2c8fa8a-2a21-4fa5-b3e1-f1518b1fef3c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[11]: 'items'"
     ]
    }
   ],
   "source": [
    "# the key name contains the name of the field\n",
    "df.schema.jsonValue()[\"fields\"][0][\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea0bb372-76a4-4185-a88a-643c3d1dc31a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[12]: {'type': 'struct',\n 'fields': [{'name': 'contentDetails',\n   'type': {'type': 'struct',\n    'fields': [{'name': 'caption',\n      'type': 'string',\n      'nullable': True,\n      'metadata': {}},\n     {'name': 'contentRating',\n      'type': {'type': 'struct',\n       'fields': [{'name': 'ytRating',\n         'type': 'string',\n         'nullable': True,\n         'metadata': {}}]},\n      'nullable': True,\n      'metadata': {}},\n     {'name': 'definition',\n      'type': 'string',\n      'nullable': True,\n      'metadata': {}},\n     {'name': 'dimension', 'type': 'string', 'nullable': True, 'metadata': {}},\n     {'name': 'duration', 'type': 'string', 'nullable': True, 'metadata': {}},\n     {'name': 'licensedContent',\n      'type': 'boolean',\n      'nullable': True,\n      'metadata': {}},\n     {'name': 'projection',\n      'type': 'string',\n      'nullable': True,\n      'metadata': {}},\n     {'name': 'regionRestriction',\n      'type': {'type': 'struct',\n       'fields': [{'name': 'allowed',\n         'type': {'type': 'array',\n          'elementType': 'string',\n          'containsNull': True},\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'blocked',\n         'type': {'type': 'array',\n          'elementType': 'string',\n          'containsNull': True},\n         'nullable': True,\n         'metadata': {}}]},\n      'nullable': True,\n      'metadata': {}}]},\n   'nullable': True,\n   'metadata': {}},\n  {'name': 'etag', 'type': 'string', 'nullable': True, 'metadata': {}},\n  {'name': 'id', 'type': 'string', 'nullable': True, 'metadata': {}},\n  {'name': 'kind', 'type': 'string', 'nullable': True, 'metadata': {}},\n  {'name': 'snippet',\n   'type': {'type': 'struct',\n    'fields': [{'name': 'categoryId',\n      'type': 'string',\n      'nullable': True,\n      'metadata': {}},\n     {'name': 'channelId', 'type': 'string', 'nullable': True, 'metadata': {}},\n     {'name': 'channelTitle',\n      'type': 'string',\n      'nullable': True,\n      'metadata': {}},\n     {'name': 'defaultAudioLanguage',\n      'type': 'string',\n      'nullable': True,\n      'metadata': {}},\n     {'name': 'defaultLanguage',\n      'type': 'string',\n      'nullable': True,\n      'metadata': {}},\n     {'name': 'description',\n      'type': 'string',\n      'nullable': True,\n      'metadata': {}},\n     {'name': 'liveBroadcastContent',\n      'type': 'string',\n      'nullable': True,\n      'metadata': {}},\n     {'name': 'localized',\n      'type': {'type': 'struct',\n       'fields': [{'name': 'description',\n         'type': 'string',\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'title',\n         'type': 'string',\n         'nullable': True,\n         'metadata': {}}]},\n      'nullable': True,\n      'metadata': {}},\n     {'name': 'publishedAt',\n      'type': 'string',\n      'nullable': True,\n      'metadata': {}},\n     {'name': 'tags',\n      'type': {'type': 'array', 'elementType': 'string', 'containsNull': True},\n      'nullable': True,\n      'metadata': {}},\n     {'name': 'thumbnails',\n      'type': {'type': 'struct',\n       'fields': [{'name': 'default',\n         'type': {'type': 'struct',\n          'fields': [{'name': 'height',\n            'type': 'long',\n            'nullable': True,\n            'metadata': {}},\n           {'name': 'url', 'type': 'string', 'nullable': True, 'metadata': {}},\n           {'name': 'width',\n            'type': 'long',\n            'nullable': True,\n            'metadata': {}}]},\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'high',\n         'type': {'type': 'struct',\n          'fields': [{'name': 'height',\n            'type': 'long',\n            'nullable': True,\n            'metadata': {}},\n           {'name': 'url', 'type': 'string', 'nullable': True, 'metadata': {}},\n           {'name': 'width',\n            'type': 'long',\n            'nullable': True,\n            'metadata': {}}]},\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'maxres',\n         'type': {'type': 'struct',\n          'fields': [{'name': 'height',\n            'type': 'long',\n            'nullable': True,\n            'metadata': {}},\n           {'name': 'url', 'type': 'string', 'nullable': True, 'metadata': {}},\n           {'name': 'width',\n            'type': 'long',\n            'nullable': True,\n            'metadata': {}}]},\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'medium',\n         'type': {'type': 'struct',\n          'fields': [{'name': 'height',\n            'type': 'long',\n            'nullable': True,\n            'metadata': {}},\n           {'name': 'url', 'type': 'string', 'nullable': True, 'metadata': {}},\n           {'name': 'width',\n            'type': 'long',\n            'nullable': True,\n            'metadata': {}}]},\n         'nullable': True,\n         'metadata': {}},\n        {'name': 'standard',\n         'type': {'type': 'struct',\n          'fields': [{'name': 'height',\n            'type': 'long',\n            'nullable': True,\n            'metadata': {}},\n           {'name': 'url', 'type': 'string', 'nullable': True, 'metadata': {}},\n           {'name': 'width',\n            'type': 'long',\n            'nullable': True,\n            'metadata': {}}]},\n         'nullable': True,\n         'metadata': {}}]},\n      'nullable': True,\n      'metadata': {}},\n     {'name': 'title', 'type': 'string', 'nullable': True, 'metadata': {}}]},\n   'nullable': True,\n   'metadata': {}},\n  {'name': 'statistics',\n   'type': {'type': 'struct',\n    'fields': [{'name': 'commentCount',\n      'type': 'string',\n      'nullable': True,\n      'metadata': {}},\n     {'name': 'dislikeCount',\n      'type': 'string',\n      'nullable': True,\n      'metadata': {}},\n     {'name': 'favoriteCount',\n      'type': 'string',\n      'nullable': True,\n      'metadata': {}},\n     {'name': 'likeCount', 'type': 'string', 'nullable': True, 'metadata': {}},\n     {'name': 'viewCount',\n      'type': 'string',\n      'nullable': True,\n      'metadata': {}}]},\n   'nullable': True,\n   'metadata': {}},\n  {'name': 'status',\n   'type': {'type': 'struct',\n    'fields': [{'name': 'embeddable',\n      'type': 'boolean',\n      'nullable': True,\n      'metadata': {}},\n     {'name': 'license', 'type': 'string', 'nullable': True, 'metadata': {}},\n     {'name': 'madeForKids',\n      'type': 'boolean',\n      'nullable': True,\n      'metadata': {}},\n     {'name': 'privacyStatus',\n      'type': 'string',\n      'nullable': True,\n      'metadata': {}},\n     {'name': 'publicStatsViewable',\n      'type': 'boolean',\n      'nullable': True,\n      'metadata': {}},\n     {'name': 'uploadStatus',\n      'type': 'string',\n      'nullable': True,\n      'metadata': {}}]},\n   'nullable': True,\n   'metadata': {}},\n  {'name': 'topicDetails',\n   'type': {'type': 'struct',\n    'fields': [{'name': 'relevantTopicIds',\n      'type': {'type': 'array', 'elementType': 'string', 'containsNull': True},\n      'nullable': True,\n      'metadata': {}},\n     {'name': 'topicCategories',\n      'type': {'type': 'array', 'elementType': 'string', 'containsNull': True},\n      'nullable': True,\n      'metadata': {}}]},\n   'nullable': True,\n   'metadata': {}}]}"
     ]
    }
   ],
   "source": [
    "# if we have the key type then we have subfields inside it\n",
    "df.schema.jsonValue()[\"fields\"][0][\"type\"]\n",
    "# and we are back to the same structure we had at the beginning and we can start digging again\n",
    "# that's the spirit of the function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d04c4817-c5e1-49af-9567-2172bff83bd0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField\n",
    "from typing import List, Dict, Generator, Union, Callable\n",
    "\n",
    "# This is actually written like a scala function, we'll walk you through it\n",
    "def walkSchema(schema: Union[StructType, StructField]) -> Generator[str, None, None]:\n",
    "    \"\"\"Explores a PySpark schema:\n",
    "    \n",
    "    schema: StructType | StructField\n",
    "    \n",
    "    Yield\n",
    "    -----\n",
    "    A generator of strings, the name of each field in the schema\n",
    "    \"\"\"\n",
    "    \n",
    "    # we define a function _walk that produces a string generator from\n",
    "    # a dictionnary \"schema_dct\", and a string \"prefix\"\n",
    "    def _walk(schema_dct: Dict['str', Union['str', list, dict]],\n",
    "              prefix: str = \"\") -> Generator[str, None, None]:\n",
    "        assert isinstance(prefix, str), \"prefix should be a string\" # check if prefix is a string\n",
    "        \n",
    "        # this function returns \"name\" if there's no prefix and \"prefix.name\" if prefix exists\n",
    "        fullName: Callable[str, str] = lambda name: ( \n",
    "            name if not prefix else f\"{prefix}.{name}\")\n",
    "        \n",
    "        # we get the next name one level lower from the dictionnary\n",
    "        name = schema_dct.get('name', '')\n",
    "        \n",
    "        # if the type is struct then we search for the fields key\n",
    "        # if fields is there we apply the function again and dig one level deeper in\n",
    "        # the schema and set a prefix\n",
    "        if schema_dct['type'] == 'struct':\n",
    "            assert 'fields' in schema_dct, (\n",
    "                \"It's a StructType, we should have some fields\")\n",
    "            for field in schema_dct['fields']:\n",
    "                yield from _walk(field, prefix=prefix)\n",
    "        # if we have a dict type and we can't find fields then we\n",
    "        # dig one level deeper and apply the _walk function again\n",
    "        elif isinstance(schema_dct['type'], dict):\n",
    "            assert 'fields' not in schema_dct, (\n",
    "                \"We're missing some keys here\")\n",
    "            yield from _walk(schema_dct['type'], prefix=fullName(name))\n",
    "        # If we finally reached the end and found a name we yield the full name\n",
    "        elif name:\n",
    "            yield fullName(name)\n",
    "    \n",
    "    yield from _walk(schema.jsonValue())\n",
    "\n",
    "# yield as opposed to return, returns a result but does not stop the function from running, it keeps\n",
    "# running even after returning one result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52c8a054-7278-4bcf-94e2-2ea6f47ac3fc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[14]: <generator object walkSchema at 0x7fc424480dd0>"
     ]
    }
   ],
   "source": [
    "col_names = walkSchema(df.schema)\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1641cc06-cbdc-4b4c-ac01-af4845e328ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items.contentDetails.caption\nitems.contentDetails.contentRating.ytRating\nitems.contentDetails.definition\nitems.contentDetails.dimension\nitems.contentDetails.duration\nitems.contentDetails.licensedContent\nitems.contentDetails.projection\nitems.etag\nitems.id\nitems.kind\nitems.snippet.categoryId\nitems.snippet.channelId\nitems.snippet.channelTitle\nitems.snippet.defaultAudioLanguage\nitems.snippet.defaultLanguage\nitems.snippet.description\nitems.snippet.liveBroadcastContent\nitems.snippet.localized.description\nitems.snippet.localized.title\nitems.snippet.publishedAt\nitems.snippet.thumbnails.default.height\nitems.snippet.thumbnails.default.url\nitems.snippet.thumbnails.default.width\nitems.snippet.thumbnails.high.height\nitems.snippet.thumbnails.high.url\nitems.snippet.thumbnails.high.width\nitems.snippet.thumbnails.maxres.height\nitems.snippet.thumbnails.maxres.url\nitems.snippet.thumbnails.maxres.width\nitems.snippet.thumbnails.medium.height\nitems.snippet.thumbnails.medium.url\nitems.snippet.thumbnails.medium.width\nitems.snippet.thumbnails.standard.height\nitems.snippet.thumbnails.standard.url\nitems.snippet.thumbnails.standard.width\nitems.snippet.title\nitems.statistics.commentCount\nitems.statistics.dislikeCount\nitems.statistics.favoriteCount\nitems.statistics.likeCount\nitems.statistics.viewCount\nitems.status.embeddable\nitems.status.license\nitems.status.madeForKids\nitems.status.privacyStatus\nitems.status.publicStatsViewable\nitems.status.uploadStatus\n"
     ]
    }
   ],
   "source": [
    "for col_name in walkSchema(df.schema):\n",
    "  print(col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39c7a4bf-da7b-4762-9619-94e4a57f522b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>items.contentDetails.caption</th>\n",
       "      <th>items.contentDetails.contentRating.ytRating</th>\n",
       "      <th>items.contentDetails.definition</th>\n",
       "      <th>items.contentDetails.dimension</th>\n",
       "      <th>items.contentDetails.duration</th>\n",
       "      <th>items.contentDetails.licensedContent</th>\n",
       "      <th>items.contentDetails.projection</th>\n",
       "      <th>items.etag</th>\n",
       "      <th>items.id</th>\n",
       "      <th>items.kind</th>\n",
       "      <th>...</th>\n",
       "      <th>items.statistics.dislikeCount</th>\n",
       "      <th>items.statistics.favoriteCount</th>\n",
       "      <th>items.statistics.likeCount</th>\n",
       "      <th>items.statistics.viewCount</th>\n",
       "      <th>items.status.embeddable</th>\n",
       "      <th>items.status.license</th>\n",
       "      <th>items.status.madeForKids</th>\n",
       "      <th>items.status.privacyStatus</th>\n",
       "      <th>items.status.publicStatsViewable</th>\n",
       "      <th>items.status.uploadStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>false</td>\n",
       "      <td>None</td>\n",
       "      <td>sd</td>\n",
       "      <td>2d</td>\n",
       "      <td>PT3M33S</td>\n",
       "      <td>True</td>\n",
       "      <td>rectangular</td>\n",
       "      <td>SqP7uUVSol30dxvuScN6JUny6T4</td>\n",
       "      <td>t1l8Z6gLPzo</td>\n",
       "      <td>youtube#video</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1028</td>\n",
       "      <td>223172</td>\n",
       "      <td>True</td>\n",
       "      <td>youtube</td>\n",
       "      <td>False</td>\n",
       "      <td>public</td>\n",
       "      <td>True</td>\n",
       "      <td>processed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>false</td>\n",
       "      <td>None</td>\n",
       "      <td>hd</td>\n",
       "      <td>2d</td>\n",
       "      <td>PT7M46S</td>\n",
       "      <td>False</td>\n",
       "      <td>rectangular</td>\n",
       "      <td>m3DnhzTEw9ABiqzBvdasfk5Av_8</td>\n",
       "      <td>we5gzZq5Avg</td>\n",
       "      <td>youtube#video</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>13409</td>\n",
       "      <td>True</td>\n",
       "      <td>youtube</td>\n",
       "      <td>False</td>\n",
       "      <td>public</td>\n",
       "      <td>True</td>\n",
       "      <td>processed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>false</td>\n",
       "      <td>None</td>\n",
       "      <td>sd</td>\n",
       "      <td>2d</td>\n",
       "      <td>PT3M7S</td>\n",
       "      <td>False</td>\n",
       "      <td>rectangular</td>\n",
       "      <td>zyzs7STAR3NG-_pZe-0nGkbKoqg</td>\n",
       "      <td>49esza4eiK4</td>\n",
       "      <td>youtube#video</td>\n",
       "      <td>...</td>\n",
       "      <td>780</td>\n",
       "      <td>0</td>\n",
       "      <td>25540</td>\n",
       "      <td>10106655</td>\n",
       "      <td>True</td>\n",
       "      <td>youtube</td>\n",
       "      <td>False</td>\n",
       "      <td>public</td>\n",
       "      <td>True</td>\n",
       "      <td>processed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>false</td>\n",
       "      <td>None</td>\n",
       "      <td>hd</td>\n",
       "      <td>2d</td>\n",
       "      <td>PT3M43S</td>\n",
       "      <td>False</td>\n",
       "      <td>rectangular</td>\n",
       "      <td>hX2C15F6fdO5A-stUFMU5Az2PvI</td>\n",
       "      <td>BoO6LfR7ca0</td>\n",
       "      <td>youtube#video</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>29153</td>\n",
       "      <td>True</td>\n",
       "      <td>youtube</td>\n",
       "      <td>False</td>\n",
       "      <td>public</td>\n",
       "      <td>True</td>\n",
       "      <td>processed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>false</td>\n",
       "      <td>None</td>\n",
       "      <td>hd</td>\n",
       "      <td>2d</td>\n",
       "      <td>PT5M</td>\n",
       "      <td>False</td>\n",
       "      <td>rectangular</td>\n",
       "      <td>rYHoV38PLpMbRuX_zhGTVBKNotw</td>\n",
       "      <td>DaH4W1rY9us</td>\n",
       "      <td>youtube#video</td>\n",
       "      <td>...</td>\n",
       "      <td>1784</td>\n",
       "      <td>0</td>\n",
       "      <td>136033</td>\n",
       "      <td>16488714</td>\n",
       "      <td>True</td>\n",
       "      <td>youtube</td>\n",
       "      <td>False</td>\n",
       "      <td>public</td>\n",
       "      <td>True</td>\n",
       "      <td>processed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>items.contentDetails.caption</th>\n      <th>items.contentDetails.contentRating.ytRating</th>\n      <th>items.contentDetails.definition</th>\n      <th>items.contentDetails.dimension</th>\n      <th>items.contentDetails.duration</th>\n      <th>items.contentDetails.licensedContent</th>\n      <th>items.contentDetails.projection</th>\n      <th>items.etag</th>\n      <th>items.id</th>\n      <th>items.kind</th>\n      <th>...</th>\n      <th>items.statistics.dislikeCount</th>\n      <th>items.statistics.favoriteCount</th>\n      <th>items.statistics.likeCount</th>\n      <th>items.statistics.viewCount</th>\n      <th>items.status.embeddable</th>\n      <th>items.status.license</th>\n      <th>items.status.madeForKids</th>\n      <th>items.status.privacyStatus</th>\n      <th>items.status.publicStatsViewable</th>\n      <th>items.status.uploadStatus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>false</td>\n      <td>None</td>\n      <td>sd</td>\n      <td>2d</td>\n      <td>PT3M33S</td>\n      <td>True</td>\n      <td>rectangular</td>\n      <td>SqP7uUVSol30dxvuScN6JUny6T4</td>\n      <td>t1l8Z6gLPzo</td>\n      <td>youtube#video</td>\n      <td>...</td>\n      <td>26</td>\n      <td>0</td>\n      <td>1028</td>\n      <td>223172</td>\n      <td>True</td>\n      <td>youtube</td>\n      <td>False</td>\n      <td>public</td>\n      <td>True</td>\n      <td>processed</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>false</td>\n      <td>None</td>\n      <td>hd</td>\n      <td>2d</td>\n      <td>PT7M46S</td>\n      <td>False</td>\n      <td>rectangular</td>\n      <td>m3DnhzTEw9ABiqzBvdasfk5Av_8</td>\n      <td>we5gzZq5Avg</td>\n      <td>youtube#video</td>\n      <td>...</td>\n      <td>3</td>\n      <td>0</td>\n      <td>124</td>\n      <td>13409</td>\n      <td>True</td>\n      <td>youtube</td>\n      <td>False</td>\n      <td>public</td>\n      <td>True</td>\n      <td>processed</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>false</td>\n      <td>None</td>\n      <td>sd</td>\n      <td>2d</td>\n      <td>PT3M7S</td>\n      <td>False</td>\n      <td>rectangular</td>\n      <td>zyzs7STAR3NG-_pZe-0nGkbKoqg</td>\n      <td>49esza4eiK4</td>\n      <td>youtube#video</td>\n      <td>...</td>\n      <td>780</td>\n      <td>0</td>\n      <td>25540</td>\n      <td>10106655</td>\n      <td>True</td>\n      <td>youtube</td>\n      <td>False</td>\n      <td>public</td>\n      <td>True</td>\n      <td>processed</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>false</td>\n      <td>None</td>\n      <td>hd</td>\n      <td>2d</td>\n      <td>PT3M43S</td>\n      <td>False</td>\n      <td>rectangular</td>\n      <td>hX2C15F6fdO5A-stUFMU5Az2PvI</td>\n      <td>BoO6LfR7ca0</td>\n      <td>youtube#video</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>255</td>\n      <td>29153</td>\n      <td>True</td>\n      <td>youtube</td>\n      <td>False</td>\n      <td>public</td>\n      <td>True</td>\n      <td>processed</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>false</td>\n      <td>None</td>\n      <td>hd</td>\n      <td>2d</td>\n      <td>PT5M</td>\n      <td>False</td>\n      <td>rectangular</td>\n      <td>rYHoV38PLpMbRuX_zhGTVBKNotw</td>\n      <td>DaH4W1rY9us</td>\n      <td>youtube#video</td>\n      <td>...</td>\n      <td>1784</td>\n      <td>0</td>\n      <td>136033</td>\n      <td>16488714</td>\n      <td>True</td>\n      <td>youtube</td>\n      <td>False</td>\n      <td>public</td>\n      <td>True</td>\n      <td>processed</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 47 columns</p>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Non-functional way: unpacking the generator\n",
    "# exploded_df = df.select(*walkSchema(df.schema))\n",
    "\n",
    "# The functional way, using functools' reduce\n",
    "exploded_df = reduce(\n",
    "  lambda memo_df, col_name: memo_df.withColumn(col_name, F.col(col_name)),\n",
    "  walkSchema(df.schema), df\n",
    ").drop('items')\n",
    "\n",
    "exploded_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "001577f2-0952-4262-9980-ac0b142e18c0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-262717713763680>:2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m output_filename \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms3://full-stack-bigdata-datasets/Big_Data/YOUTUBE/items_tidy.parquet\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
       "\u001B[0;32m----> 2\u001B[0m exploded_df\u001B[38;5;241m.\u001B[39mwrite \\\n",
       "\u001B[1;32m      3\u001B[0m   \u001B[38;5;241m.\u001B[39mparquet(output_filename, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moverwrite\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     51\u001B[0m     )\n",
       "\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/readwriter.py:1655\u001B[0m, in \u001B[0;36mDataFrameWriter.parquet\u001B[0;34m(self, path, mode, partitionBy, compression)\u001B[0m\n",
       "\u001B[1;32m   1653\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpartitionBy(partitionBy)\n",
       "\u001B[1;32m   1654\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_opts(compression\u001B[38;5;241m=\u001B[39mcompression)\n",
       "\u001B[0;32m-> 1655\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jwrite\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparquet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:228\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    226\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdeco\u001B[39m(\u001B[38;5;241m*\u001B[39ma: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n",
       "\u001B[1;32m    227\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m--> 228\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    229\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m Py4JJavaError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
       "\u001B[1;32m    230\u001B[0m         converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py:326\u001B[0m, in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n",
       "\u001B[1;32m    324\u001B[0m value \u001B[38;5;241m=\u001B[39m OUTPUT_CONVERTER[\u001B[38;5;28mtype\u001B[39m](answer[\u001B[38;5;241m2\u001B[39m:], gateway_client)\n",
       "\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m answer[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m REFERENCE_TYPE:\n",
       "\u001B[0;32m--> 326\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JJavaError(\n",
       "\u001B[1;32m    327\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n",
       "\u001B[1;32m    328\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name), value)\n",
       "\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    330\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JError(\n",
       "\u001B[1;32m    331\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m. Trace:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{3}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n",
       "\u001B[1;32m    332\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name, value))\n",
       "\n",
       "\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o936.parquet.\n",
       ": java.nio.file.AccessDeniedException: Big_Data/YOUTUBE/items_tidy.parquet: delete on Big_Data/YOUTUBE/items_tidy.parquet: com.amazonaws.services.s3.model.AmazonS3Exception: Access Denied; request: DELETE https://full-stack-bigdata-datasets.s3.eu-west-3.amazonaws.com Big_Data/YOUTUBE/items_tidy.parquet {} Hadoop 3.3.4, aws-sdk-java/1.12.189 Linux/5.15.0-1069-aws OpenJDK_64-Bit_Server_VM/25.382-b05 java/1.8.0_382 scala/2.12.14 kotlin/1.6.0 vendor/Azul_Systems,_Inc. cfg/retry-mode/legacy com.amazonaws.services.s3.model.DeleteObjectRequest; Request ID: TGRKWPY18C9X4YWE, Extended Request ID: bN1hTdCntpPr60rp1aS3Qluokr5TL3Eec9u1eZiSobz+zjJWLjxlmFYnoG9ArKEu0x76AvZS5NA=, Cloud Provider: AWS, Instance ID: i-0267df395b41f0ef1 credentials-provider: com.amazonaws.auth.AnonymousAWSCredentials credential-header: no-credential-header signature-present: false (Service: Amazon S3; Status Code: 403; Error Code: AccessDenied; Request ID: TGRKWPY18C9X4YWE; S3 Extended Request ID: bN1hTdCntpPr60rp1aS3Qluokr5TL3Eec9u1eZiSobz+zjJWLjxlmFYnoG9ArKEu0x76AvZS5NA=; Proxy: null), S3 Extended Request ID: bN1hTdCntpPr60rp1aS3Qluokr5TL3Eec9u1eZiSobz+zjJWLjxlmFYnoG9ArKEu0x76AvZS5NA=:AccessDenied\n",
       "\tat shaded.databricks.org.apache.hadoop.fs.s3a.S3AUtils.translateException(S3AUtils.java:296)\n",
       "\tat shaded.databricks.org.apache.hadoop.fs.s3a.Invoker.once(Invoker.java:121)\n",
       "\tat shaded.databricks.org.apache.hadoop.fs.s3a.Invoker.once(Invoker.java:113)\n",
       "\tat shaded.databricks.org.apache.hadoop.fs.s3a.Invoker.onceVoid(Invoker.java:135)\n",
       "\tat shaded.databricks.org.apache.hadoop.fs.s3a.S3AFileSystem$OperationCallbacksImpl.deleteObjectAtPath(S3AFileSystem.java:1952)\n",
       "\tat shaded.databricks.org.apache.hadoop.fs.s3a.impl.DeleteOperation.deleteObjectAtPath(DeleteOperation.java:478)\n",
       "\tat shaded.databricks.org.apache.hadoop.fs.s3a.impl.DeleteOperation.execute(DeleteOperation.java:285)\n",
       "\tat shaded.databricks.org.apache.hadoop.fs.s3a.S3AFileSystem.deleteWithInstrumentation(S3AFileSystem.java:3065)\n",
       "\tat shaded.databricks.org.apache.hadoop.fs.s3a.S3AFileSystem.delete(S3AFileSystem.java:3044)\n",
       "\tat com.databricks.common.filesystem.LokiFileSystem.delete(LokiFileSystem.scala:131)\n",
       "\tat org.apache.spark.internal.io.FileCommitProtocol.deleteWithJob(FileCommitProtocol.scala:192)\n",
       "\tat com.databricks.sql.transaction.directory.DirectoryAtomicCommitProtocol.deleteWithJob(DirectoryAtomicCommitProtocol.scala:173)\n",
       "\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.deleteMatchingPartitions(InsertIntoHadoopFsRelationCommand.scala:255)\n",
       "\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:149)\n",
       "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.$anonfun$sideEffectResult$3(commands.scala:132)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n",
       "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:130)\n",
       "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:129)\n",
       "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:144)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$3(QueryExecution.scala:256)\n",
       "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:165)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$2(QueryExecution.scala:256)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$9(SQLExecution.scala:258)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:448)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:203)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1073)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:131)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:398)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$1(QueryExecution.scala:255)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$withMVTagsIfNecessary(QueryExecution.scala:238)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:251)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:244)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:519)\n",
       "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:106)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:519)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:339)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:335)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:495)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:244)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:395)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:244)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:198)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:189)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:305)\n",
       "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:964)\n",
       "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:429)\n",
       "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:396)\n",
       "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:250)\n",
       "\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:897)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
       "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
       "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:306)\n",
       "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:195)\n",
       "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:115)\n",
       "\tat java.lang.Thread.run(Thread.java:750)\n",
       "Caused by: com.amazonaws.services.s3.model.AmazonS3Exception: Access Denied; request: DELETE https://full-stack-bigdata-datasets.s3.eu-west-3.amazonaws.com Big_Data/YOUTUBE/items_tidy.parquet {} Hadoop 3.3.4, aws-sdk-java/1.12.189 Linux/5.15.0-1069-aws OpenJDK_64-Bit_Server_VM/25.382-b05 java/1.8.0_382 scala/2.12.14 kotlin/1.6.0 vendor/Azul_Systems,_Inc. cfg/retry-mode/legacy com.amazonaws.services.s3.model.DeleteObjectRequest; Request ID: TGRKWPY18C9X4YWE, Extended Request ID: bN1hTdCntpPr60rp1aS3Qluokr5TL3Eec9u1eZiSobz+zjJWLjxlmFYnoG9ArKEu0x76AvZS5NA=, Cloud Provider: AWS, Instance ID: i-0267df395b41f0ef1 credentials-provider: com.amazonaws.auth.AnonymousAWSCredentials credential-header: no-credential-header signature-present: false (Service: Amazon S3; Status Code: 403; Error Code: AccessDenied; Request ID: TGRKWPY18C9X4YWE; S3 Extended Request ID: bN1hTdCntpPr60rp1aS3Qluokr5TL3Eec9u1eZiSobz+zjJWLjxlmFYnoG9ArKEu0x76AvZS5NA=; Proxy: null), S3 Extended Request ID: bN1hTdCntpPr60rp1aS3Qluokr5TL3Eec9u1eZiSobz+zjJWLjxlmFYnoG9ArKEu0x76AvZS5NA=\n",
       "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleErrorResponse(AmazonHttpClient.java:1862)\n",
       "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleServiceErrorResponse(AmazonHttpClient.java:1415)\n",
       "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1384)\n",
       "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:1154)\n",
       "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:811)\n",
       "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:779)\n",
       "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:753)\n",
       "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$500(AmazonHttpClient.java:713)\n",
       "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:695)\n",
       "\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:559)\n",
       "\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:539)\n",
       "\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5453)\n",
       "\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5400)\n",
       "\tat com.amazonaws.services.s3.AmazonS3Client.deleteObject(AmazonS3Client.java:2299)\n",
       "\tat shaded.databricks.org.apache.hadoop.fs.s3a.EnforcingDatabricksS3Client.deleteObject(EnforcingDatabricksS3Client.scala:95)\n",
       "\tat shaded.databricks.org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$deleteObject$9(S3AFileSystem.java:2420)\n",
       "\tat shaded.databricks.org.apache.hadoop.fs.s3a.Invoker.retryUntranslated(Invoker.java:418)\n",
       "\tat shaded.databricks.org.apache.hadoop.fs.s3a.Invoker.retryUntranslated(Invoker.java:379)\n",
       "\tat shaded.databricks.org.apache.hadoop.fs.s3a.S3AFileSystem.deleteObject(S3AFileSystem.java:2416)\n",
       "\tat shaded.databricks.org.apache.hadoop.fs.s3a.S3AFileSystem.deleteObjectAtPath(S3AFileSystem.java:2448)\n",
       "\tat shaded.databricks.org.apache.hadoop.fs.s3a.S3AFileSystem$OperationCallbacksImpl.lambda$deleteObjectAtPath$0(S3AFileSystem.java:1953)\n",
       "\tat shaded.databricks.org.apache.hadoop.fs.s3a.Invoker.lambda$onceVoid$0(Invoker.java:137)\n",
       "\tat shaded.databricks.org.apache.hadoop.fs.s3a.Invoker.once(Invoker.java:119)\n",
       "\t... 62 more\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)\nFile \u001B[0;32m<command-262717713763680>:2\u001B[0m\n\u001B[1;32m      1\u001B[0m output_filename \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms3://full-stack-bigdata-datasets/Big_Data/YOUTUBE/items_tidy.parquet\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m----> 2\u001B[0m exploded_df\u001B[38;5;241m.\u001B[39mwrite \\\n\u001B[1;32m      3\u001B[0m   \u001B[38;5;241m.\u001B[39mparquet(output_filename, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moverwrite\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     51\u001B[0m     )\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/readwriter.py:1655\u001B[0m, in \u001B[0;36mDataFrameWriter.parquet\u001B[0;34m(self, path, mode, partitionBy, compression)\u001B[0m\n\u001B[1;32m   1653\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpartitionBy(partitionBy)\n\u001B[1;32m   1654\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_opts(compression\u001B[38;5;241m=\u001B[39mcompression)\n\u001B[0;32m-> 1655\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jwrite\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparquet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:228\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    226\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdeco\u001B[39m(\u001B[38;5;241m*\u001B[39ma: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    227\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 228\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m Py4JJavaError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    230\u001B[0m         converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py:326\u001B[0m, in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    324\u001B[0m value \u001B[38;5;241m=\u001B[39m OUTPUT_CONVERTER[\u001B[38;5;28mtype\u001B[39m](answer[\u001B[38;5;241m2\u001B[39m:], gateway_client)\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m answer[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m REFERENCE_TYPE:\n\u001B[0;32m--> 326\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JJavaError(\n\u001B[1;32m    327\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name), value)\n\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    330\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JError(\n\u001B[1;32m    331\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m. Trace:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{3}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n\u001B[1;32m    332\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name, value))\n\n\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o936.parquet.\n: java.nio.file.AccessDeniedException: Big_Data/YOUTUBE/items_tidy.parquet: delete on Big_Data/YOUTUBE/items_tidy.parquet: com.amazonaws.services.s3.model.AmazonS3Exception: Access Denied; request: DELETE https://full-stack-bigdata-datasets.s3.eu-west-3.amazonaws.com Big_Data/YOUTUBE/items_tidy.parquet {} Hadoop 3.3.4, aws-sdk-java/1.12.189 Linux/5.15.0-1069-aws OpenJDK_64-Bit_Server_VM/25.382-b05 java/1.8.0_382 scala/2.12.14 kotlin/1.6.0 vendor/Azul_Systems,_Inc. cfg/retry-mode/legacy com.amazonaws.services.s3.model.DeleteObjectRequest; Request ID: TGRKWPY18C9X4YWE, Extended Request ID: bN1hTdCntpPr60rp1aS3Qluokr5TL3Eec9u1eZiSobz+zjJWLjxlmFYnoG9ArKEu0x76AvZS5NA=, Cloud Provider: AWS, Instance ID: i-0267df395b41f0ef1 credentials-provider: com.amazonaws.auth.AnonymousAWSCredentials credential-header: no-credential-header signature-present: false (Service: Amazon S3; Status Code: 403; Error Code: AccessDenied; Request ID: TGRKWPY18C9X4YWE; S3 Extended Request ID: bN1hTdCntpPr60rp1aS3Qluokr5TL3Eec9u1eZiSobz+zjJWLjxlmFYnoG9ArKEu0x76AvZS5NA=; Proxy: null), S3 Extended Request ID: bN1hTdCntpPr60rp1aS3Qluokr5TL3Eec9u1eZiSobz+zjJWLjxlmFYnoG9ArKEu0x76AvZS5NA=:AccessDenied\n\tat shaded.databricks.org.apache.hadoop.fs.s3a.S3AUtils.translateException(S3AUtils.java:296)\n\tat shaded.databricks.org.apache.hadoop.fs.s3a.Invoker.once(Invoker.java:121)\n\tat shaded.databricks.org.apache.hadoop.fs.s3a.Invoker.once(Invoker.java:113)\n\tat shaded.databricks.org.apache.hadoop.fs.s3a.Invoker.onceVoid(Invoker.java:135)\n\tat shaded.databricks.org.apache.hadoop.fs.s3a.S3AFileSystem$OperationCallbacksImpl.deleteObjectAtPath(S3AFileSystem.java:1952)\n\tat shaded.databricks.org.apache.hadoop.fs.s3a.impl.DeleteOperation.deleteObjectAtPath(DeleteOperation.java:478)\n\tat shaded.databricks.org.apache.hadoop.fs.s3a.impl.DeleteOperation.execute(DeleteOperation.java:285)\n\tat shaded.databricks.org.apache.hadoop.fs.s3a.S3AFileSystem.deleteWithInstrumentation(S3AFileSystem.java:3065)\n\tat shaded.databricks.org.apache.hadoop.fs.s3a.S3AFileSystem.delete(S3AFileSystem.java:3044)\n\tat com.databricks.common.filesystem.LokiFileSystem.delete(LokiFileSystem.scala:131)\n\tat org.apache.spark.internal.io.FileCommitProtocol.deleteWithJob(FileCommitProtocol.scala:192)\n\tat com.databricks.sql.transaction.directory.DirectoryAtomicCommitProtocol.deleteWithJob(DirectoryAtomicCommitProtocol.scala:173)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.deleteMatchingPartitions(InsertIntoHadoopFsRelationCommand.scala:255)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:149)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.$anonfun$sideEffectResult$3(commands.scala:132)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:130)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:129)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:144)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$3(QueryExecution.scala:256)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:165)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$2(QueryExecution.scala:256)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$9(SQLExecution.scala:258)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:448)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:203)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1073)\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:131)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:398)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$1(QueryExecution.scala:255)\n\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$withMVTagsIfNecessary(QueryExecution.scala:238)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:251)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:244)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:519)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:106)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:519)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:339)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:335)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:495)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:244)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:395)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:244)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:198)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:189)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:305)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:964)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:429)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:396)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:250)\n\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:897)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:195)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:115)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: com.amazonaws.services.s3.model.AmazonS3Exception: Access Denied; request: DELETE https://full-stack-bigdata-datasets.s3.eu-west-3.amazonaws.com Big_Data/YOUTUBE/items_tidy.parquet {} Hadoop 3.3.4, aws-sdk-java/1.12.189 Linux/5.15.0-1069-aws OpenJDK_64-Bit_Server_VM/25.382-b05 java/1.8.0_382 scala/2.12.14 kotlin/1.6.0 vendor/Azul_Systems,_Inc. cfg/retry-mode/legacy com.amazonaws.services.s3.model.DeleteObjectRequest; Request ID: TGRKWPY18C9X4YWE, Extended Request ID: bN1hTdCntpPr60rp1aS3Qluokr5TL3Eec9u1eZiSobz+zjJWLjxlmFYnoG9ArKEu0x76AvZS5NA=, Cloud Provider: AWS, Instance ID: i-0267df395b41f0ef1 credentials-provider: com.amazonaws.auth.AnonymousAWSCredentials credential-header: no-credential-header signature-present: false (Service: Amazon S3; Status Code: 403; Error Code: AccessDenied; Request ID: TGRKWPY18C9X4YWE; S3 Extended Request ID: bN1hTdCntpPr60rp1aS3Qluokr5TL3Eec9u1eZiSobz+zjJWLjxlmFYnoG9ArKEu0x76AvZS5NA=; Proxy: null), S3 Extended Request ID: bN1hTdCntpPr60rp1aS3Qluokr5TL3Eec9u1eZiSobz+zjJWLjxlmFYnoG9ArKEu0x76AvZS5NA=\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleErrorResponse(AmazonHttpClient.java:1862)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleServiceErrorResponse(AmazonHttpClient.java:1415)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1384)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:1154)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:811)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:779)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:753)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$500(AmazonHttpClient.java:713)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:695)\n\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:559)\n\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:539)\n\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5453)\n\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5400)\n\tat com.amazonaws.services.s3.AmazonS3Client.deleteObject(AmazonS3Client.java:2299)\n\tat shaded.databricks.org.apache.hadoop.fs.s3a.EnforcingDatabricksS3Client.deleteObject(EnforcingDatabricksS3Client.scala:95)\n\tat shaded.databricks.org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$deleteObject$9(S3AFileSystem.java:2420)\n\tat shaded.databricks.org.apache.hadoop.fs.s3a.Invoker.retryUntranslated(Invoker.java:418)\n\tat shaded.databricks.org.apache.hadoop.fs.s3a.Invoker.retryUntranslated(Invoker.java:379)\n\tat shaded.databricks.org.apache.hadoop.fs.s3a.S3AFileSystem.deleteObject(S3AFileSystem.java:2416)\n\tat shaded.databricks.org.apache.hadoop.fs.s3a.S3AFileSystem.deleteObjectAtPath(S3AFileSystem.java:2448)\n\tat shaded.databricks.org.apache.hadoop.fs.s3a.S3AFileSystem$OperationCallbacksImpl.lambda$deleteObjectAtPath$0(S3AFileSystem.java:1953)\n\tat shaded.databricks.org.apache.hadoop.fs.s3a.Invoker.lambda$onceVoid$0(Invoker.java:137)\n\tat shaded.databricks.org.apache.hadoop.fs.s3a.Invoker.once(Invoker.java:119)\n\t... 62 more\n",
       "errorSummary": "java.nio.file.AccessDeniedException: Big_Data/YOUTUBE/items_tidy.parquet: delete on Big_Data/YOUTUBE/items_tidy.parquet: com.amazonaws.services.s3.model.AmazonS3Exception: Access Denied; request: DELETE https://full-stack-bigdata-datasets.s3.eu-west-3.amazonaws.com Big_Data/YOUTUBE/items_tidy.parquet {} Hadoop 3.3.4, aws-sdk-java/1.12.189 Linux/5.15.0-1069-aws OpenJDK_64-Bit_Server_VM/25.382-b05 java/1.8.0_382 scala/2.12.14 kotlin/1.6.0 vendor/Azul_Systems,_Inc. cfg/retry-mode/legacy com.amazonaws.services.s3.model.DeleteObjectRequest; Request ID: TGRKWPY18C9X4YWE, Extended Request ID: bN1hTdCntpPr60rp1aS3Qluokr5TL3Eec9u1eZiSobz+zjJWLjxlmFYnoG9ArKEu0x76AvZS5NA=, Cloud Provider: AWS, Instance ID: i-0267df395b41f0ef1 credentials-provider: com.amazonaws.auth.AnonymousAWSCredentials credential-header: no-credential-header signature-present: false (Service: Amazon S3; Status Code: 403; Error Code: AccessDenied; Request ID: TGRKWPY18C9X4YWE; S3 Extended Request ID: bN1hTdCntpPr60rp1aS3Qluokr5TL3Eec9u1eZiSobz+zjJWLjxlmFYnoG9ArKEu0x76AvZS5NA=; Proxy: null), S3 Extended Request ID: bN1hTdCntpPr60rp1aS3Qluokr5TL3Eec9u1eZiSobz+zjJWLjxlmFYnoG9ArKEu0x76AvZS5NA=:AccessDenied",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_filename = 's3://full-stack-bigdata-datasets/Big_Data/YOUTUBE/items_tidy.parquet'\n",
    "exploded_df.write \\\n",
    "  .parquet(output_filename, mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5628e41-ba3e-4752-8fd7-8cc027943b22",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "3-5-Tidying-up-part2-exercice-Data-Warehousing.ipynb",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
