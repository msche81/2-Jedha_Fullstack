{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "183bd2d1-df60-4ed9-b9d3-fa91eb99064d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad1002dc-1429-4abf-877f-906ae93c1019",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F # This will load the class where spark sql functions are contained\n",
    "from pyspark.sql import Row # this will let us manipulate rows with spark sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6bbc7d0-66ad-4957-97b8-8703a125859f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+--------------------+\n| id|  name|              orders|\n+---+------+--------------------+\n|  1|George|[50.61, 31.32, 20.9]|\n|  2|Hugues|[133.8, 59.0, 40....|\n+---+------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "users_dct = [\n",
    "    {'id': 1, 'name': 'George', 'orders': [50.61, 31.32, 20.9]},\n",
    "    {'id': 2, 'name': 'Hugues', 'orders': [133.8, 59.0, 40.03, 27.91]}\n",
    "]\n",
    "users_rdd = sc.parallelize(users_dct)\n",
    "users_df = spark.createDataFrame(users_rdd.map(lambda x: Row(**x))) # this is called unpacking, \n",
    "# try this command with Row(x) and Row(*x) to understand what it does\n",
    "users_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07d49f7b-cdda-467e-ada2-0ee62b228ebf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: long (nullable = true)\n |-- name: string (nullable = true)\n |-- orders: array (nullable = true)\n |    |-- element: double (containsNull = true)\n\n"
     ]
    }
   ],
   "source": [
    "# The .createDataFrame(...) method is able to infer the data schema by itself\n",
    "users_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "207976de-dce9-4efc-a3c8-c297601c8be5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import * # Import types to convert columns using spark sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3aa4815-64b3-43b2-aa0f-3111ed441013",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: integer (nullable = true)\n |-- name: string (nullable = true)\n |-- orders: array (nullable = true)\n |    |-- element: integer (containsNull = true)\n\n+---+------+-----------------+\n| id|  name|           orders|\n+---+------+-----------------+\n|  1|George|     [50, 31, 20]|\n|  2|Hugues|[133, 59, 40, 27]|\n+---+------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "users_dct = [\n",
    "    {'id': 1, 'name': 'George', 'orders': [50, 31, 20]},\n",
    "    {'id': 2, 'name': 'Hugues', 'orders': [133, 59, 40, 27]}\n",
    "]\n",
    "users_rdd = sc.parallelize(users_dct)\n",
    "\n",
    "# we create a variable schema as a list of StructField inside a StructType object\n",
    "schema = StructType([\n",
    "    StructField('id', IntegerType(), True), # the first column is of type Integer\n",
    "    StructField('name', StringType(), True), # the second column is a String\n",
    "    StructField('orders', ArrayType(IntegerType()), True) # the third column contains Array of Integer\n",
    "])\n",
    "\n",
    "users_df = spark.createDataFrame(users_rdd.map(lambda x: Row(**x)), schema=schema) # we feed the schema\n",
    "# to the function using the appropriate argument\n",
    "users_df.printSchema()\n",
    "users_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f737c30-4470-4221-bbe4-149a889af449",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---------------+\n| id|  name|orders_quantity|\n+---+------+---------------+\n|  1|George|              3|\n|  2|Hugues|              4|\n+---+------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "users_df \\\n",
    "    .withColumn('orders_quantity', F.size('orders')) \\\n",
    "    .drop('orders') \\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ad67952-2ce1-43c0-a02e-1286512af91d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: integer (nullable = true)\n |-- name: string (nullable = true)\n |-- orders: integer (nullable = true)\n\n+---+------+------+\n| id|  name|orders|\n+---+------+------+\n|  1|George|    50|\n|  1|George|    31|\n|  1|George|    20|\n|  2|Hugues|   133|\n|  2|Hugues|    59|\n|  2|Hugues|    40|\n|  2|Hugues|    27|\n+---+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "orders_df = users_df.withColumn('orders', F.explode('orders'))\n",
    "orders_df.printSchema()\n",
    "orders_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "646e98de-ef6e-4bd2-8489-68d36ec6d93c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------------------+\n| id|  name|       avg(orders)|\n+---+------+------------------+\n|  1|George|33.666666666666664|\n|  2|Hugues|             64.75|\n+---+------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "orders_df.groupBy('id', 'name') \\\n",
    "    .mean('orders') \\\n",
    "    .show()\n",
    "\n",
    "# here it's ok to just writethe column names, but don't forget that it's usually\n",
    "# better to use the column objects instead to avoid errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f376f923-37e7-4ba1-a37a-69407d2b060e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----------------+\n| id|  name|           orders|\n+---+------+-----------------+\n|  1|George|     [50, 31, 20]|\n|  2|Hugues|[133, 59, 40, 27]|\n+---+------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "orders_df.groupBy('id', 'name') \\\n",
    "    .agg(F.collect_list('orders').alias('orders')) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbd5ec2d-4cb7-4d50-b4b4-b710b6a2ea1a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ce4359a-58ec-4bf3-9abd-2862454f95df",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: integer (nullable = true)\n |-- name: string (nullable = true)\n |-- orders: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- id: integer (nullable = true)\n |    |    |-- value: float (nullable = true)\n\n+---+------+--------------------+\n| id|  name|              orders|\n+---+------+--------------------+\n|  1|George|[{1, 55.1}, {2, 7...|\n|  2|Hughes|[{3, 31.19}, {5, ...|\n+---+------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "users = [\n",
    "    {'id': 1, 'name': 'George', 'orders': [\n",
    "        {'id': 1, 'value': 55.1},\n",
    "        {'id': 2, 'value': 78.31},\n",
    "        {'id': 4, 'value': 52.13}\n",
    "    ]},\n",
    "    {'id': 2, 'name': 'Hughes', 'orders': [\n",
    "        {'id': 3, 'value': 31.19},\n",
    "        {'id': 5, 'value': 131.1}\n",
    "    ]}\n",
    "]\n",
    "users_rdd = sc.parallelize(users)\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('id', IntegerType(), True),\n",
    "    StructField('name', StringType(), True),\n",
    "    StructField('orders', ArrayType(\n",
    "        StructType([\n",
    "            StructField('id', IntegerType(), True),\n",
    "            StructField('value', FloatType(), True)\n",
    "        ])\n",
    "    ), True)\n",
    "])\n",
    "\n",
    "users_df = spark.createDataFrame(users_rdd, schema=schema)\n",
    "users_df.printSchema()\n",
    "users_df.show()\n",
    "\n",
    "# You'll see that the schema this time is a little deeper than before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d018c32c-32fc-44cf-bf5c-bea28ba8bd7a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: integer (nullable = true)\n |-- name: string (nullable = true)\n |-- orders: struct (nullable = true)\n |    |-- id: integer (nullable = true)\n |    |-- value: float (nullable = true)\n\n+---+------+----------+\n| id|  name|    orders|\n+---+------+----------+\n|  1|George| {1, 55.1}|\n|  1|George|{2, 78.31}|\n|  1|George|{4, 52.13}|\n|  2|Hughes|{3, 31.19}|\n|  2|Hughes|{5, 131.1}|\n+---+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Let's explode the orders column start unnesting the schema\n",
    "orders_df = users_df.withColumn('orders', F.explode('orders'))\n",
    "orders_df.printSchema()\n",
    "orders_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01053f3c-a929-4939-9f7c-a08a7df2962b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+--------+\n| id|  name|    orders|order_id|\n+---+------+----------+--------+\n|  1|George| {1, 55.1}|       1|\n|  1|George|{2, 78.31}|       2|\n|  1|George|{4, 52.13}|       4|\n|  2|Hughes|{3, 31.19}|       3|\n|  2|Hughes|{5, 131.1}|       5|\n+---+------+----------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "orders_df \\\n",
    "    .withColumn('order_id', F.col('orders').getField('id')) \\\n",
    "    .show()\n",
    "\n",
    "# F.col(\"col_name\") returns the column object just like df.col_name or df[\"col_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47823d62-dee6-415b-a18d-28a8a2940f1c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+--------+\n| id|  name|    orders|order_id|\n+---+------+----------+--------+\n|  1|George| {1, 55.1}|       1|\n|  1|George|{2, 78.31}|       2|\n|  1|George|{4, 52.13}|       4|\n|  2|Hughes|{3, 31.19}|       3|\n|  2|Hughes|{5, 131.1}|       5|\n+---+------+----------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "orders_df \\\n",
    "    .withColumn('order_id', F.col('orders.id')) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e8dc6c6-5a50-4a3b-9c88-264b4a326367",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+--------+-----------+\n| id|  name|order_id|order_value|\n+---+------+--------+-----------+\n|  1|George|       1|       55.1|\n|  1|George|       2|      78.31|\n|  1|George|       4|      52.13|\n|  2|Hughes|       3|      31.19|\n|  2|Hughes|       5|      131.1|\n+---+------+--------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Let's extract both the nested columns to get a flat schema\n",
    "orders_df_flattened = orders_df \\\n",
    "    .withColumn('order_id', F.col('orders.id')) \\\n",
    "    .withColumn('order_value', F.col('orders.value')) \\\n",
    "    .drop('orders')\n",
    "orders_df_flattened.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a7f8523-ace5-4b75-b64b-b46ab85a74df",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n|  name|  sum(order_value)|\n+------+------------------+\n|Hughes|162.29000663757324|\n|George|185.53999710083008|\n+------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# It is now possible to aggregate this table using goupBy and some aggregation function like .sum\n",
    "orders_df_flattened \\\n",
    "    .groupBy('name') \\\n",
    "    .sum('order_value') \\\n",
    "    .orderBy('sum(order_value)') \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb703b06-8ba0-4c61-964a-58d44fbd7d47",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n|  name|       total_value|\n+------+------------------+\n|George|185.53999710083008|\n|Hughes|162.29000663757324|\n+------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Aliasing inline and descending sort\n",
    "orders_df_flattened \\\n",
    "    .groupBy('name') \\\n",
    "    .agg(F.sum('order_value').alias('total_value')) \\\n",
    "    .orderBy(F.desc('total_value')) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a374f56-c96f-438d-82c6-0aaf59cc8d37",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: integer (nullable = true)\n |-- name: string (nullable = true)\n |-- orders: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- id: integer (nullable = true)\n |    |    |-- items: array (nullable = true)\n |    |    |    |-- element: struct (containsNull = true)\n |    |    |    |    |-- id: integer (nullable = true)\n |    |    |    |    |-- category: string (nullable = true)\n |    |    |    |    |-- price: integer (nullable = true)\n |    |    |    |    |-- quantity: integer (nullable = true)\n\n+---+------+--------------------+\n| id|  name|              orders|\n+---+------+--------------------+\n|  1|George|[{1, [{1, shirt, ...|\n|  2|Hughes|[{2, [{4, shorts,...|\n+---+------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "users = [\n",
    "    {'id': 1, 'name': 'George', 'orders': [\n",
    "        {'id': 1, 'items': [\n",
    "            {'id': 1, 'category': 'shirt', 'price': 80, 'quantity': 4},\n",
    "            {'id': 2, 'category': 'jeans', 'price': 130, 'quantity': 2}\n",
    "        ]},\n",
    "        {'id': 4, 'items': [\n",
    "            {'id': 1, 'category': 'shirt', 'price': 80, 'quantity': 1},\n",
    "            {'id': 3, 'category': 'shoes', 'price': 240, 'quantity': 1}\n",
    "        ]}\n",
    "    ]},\n",
    "    {'id': 2, 'name': 'Hughes', 'orders': [\n",
    "        {'id': 2, 'items': [\n",
    "            {'id': 4, 'category': 'shorts', 'price': 120, 'quantity': 3},\n",
    "            {'id': 1, 'category': 'shirt', 'price': 180, 'quantity': 2},\n",
    "            {'id': 3, 'category': 'shoes', 'prices': 240, 'quantity': 1}\n",
    "        ]},\n",
    "        {'id': 3, 'items': [\n",
    "            {'id': 5, 'category': 'suit', 'price': 2000, 'quantity': 1}\n",
    "        ]}\n",
    "    ]}\n",
    "]\n",
    "users_rdd = sc.parallelize(users)\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('id', IntegerType(), True),\n",
    "    StructField('name', StringType(), True),\n",
    "    StructField('orders', ArrayType(\n",
    "        StructType([\n",
    "            StructField('id', IntegerType(), True),\n",
    "            StructField('items', ArrayType(\n",
    "                StructType([\n",
    "                    StructField('id', IntegerType(), True),\n",
    "                    StructField('category', StringType(), True),\n",
    "                    StructField('price', IntegerType(), True),\n",
    "                    StructField('quantity', IntegerType(), True)\n",
    "                ])\n",
    "            ))\n",
    "        ])\n",
    "    ), True)\n",
    "])\n",
    "\n",
    "users_df = spark.createDataFrame(users_rdd, schema=schema)\n",
    "users_df.printSchema()\n",
    "users_df.show()\n",
    "\n",
    "# This schema is much deeper than the other two!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ac63140-5347-49c9-8727-75e9065743f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+--------------------+\n| id|  name|              orders|\n+---+------+--------------------+\n|  1|George|{1, [{1, shirt, 8...|\n|  1|George|{4, [{1, shirt, 8...|\n|  2|Hughes|{2, [{4, shorts, ...|\n|  2|Hughes|{3, [{5, suit, 20...|\n+---+------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# We start by exploding the orders column, which where the nest resides\n",
    "orders_df = users_df.withColumn('orders', F.explode('orders'))\n",
    "orders_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8146227-33ce-46ce-b693-4c46fe754907",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------+-------+-------------+----------+-------------+-----------+\n|user_id|user_name|order_id|item_id|item_category|item_price|item_quantity|total_price|\n+-------+---------+--------+-------+-------------+----------+-------------+-----------+\n|      1|   George|       1|      1|        shirt|        80|            4|        320|\n|      1|   George|       1|      2|        jeans|       130|            2|        260|\n|      1|   George|       4|      1|        shirt|        80|            1|         80|\n|      1|   George|       4|      3|        shoes|       240|            1|        240|\n|      2|   Hughes|       2|      4|       shorts|       120|            3|        360|\n|      2|   Hughes|       2|      1|        shirt|       180|            2|        360|\n|      2|   Hughes|       2|      3|        shoes|      null|            1|       null|\n|      2|   Hughes|       3|      5|         suit|      2000|            1|       2000|\n+-------+---------+--------+-------+-------------+----------+-------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "items_df = (\n",
    "    orders_df.withColumn('order_id', F.col('orders.id'))\n",
    "    .withColumn('items', F.col('orders.items'))\n",
    "    .drop('orders')\n",
    "    .withColumnRenamed('name', 'user_name')\n",
    "    .withColumnRenamed('id', 'user_id')\n",
    "    .withColumn('items', F.explode('items'))\n",
    "    .withColumn('item_id', F.col('items.id'))\n",
    "    .withColumn('item_category', F.col('items.category'))\n",
    "    .withColumn('item_price', F.col('items.price'))\n",
    "    .withColumn('item_quantity', F.col('items.quantity'))\n",
    "    .withColumn('total_price', F.col('item_price') * F.col('item_quantity'))\n",
    "    .drop('items')\n",
    ")\n",
    "items_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7080da9c-a67f-4fdf-9d2e-b1ae8af45ffd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+\n|item_category|sum(item_quantity)|\n+-------------+------------------+\n|        shirt|                 7|\n|       shorts|                 3|\n|        shoes|                 2|\n|        jeans|                 2|\n|         suit|                 1|\n+-------------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Here we group the data by item category and calculate the sum\n",
    "items_df \\\n",
    "    .groupBy('item_category') \\\n",
    "    .sum('item_quantity') \\\n",
    "    .orderBy(F.desc('sum(item_quantity)')) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e49faa1d-7b69-4a5b-92af-1b4c1b31bdab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n|item_category|total_quantity|\n+-------------+--------------+\n|        shirt|             7|\n|       shorts|             3|\n|        shoes|             2|\n|        jeans|             2|\n|         suit|             1|\n+-------------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "items_df \\\n",
    "    .groupBy('item_category') \\\n",
    "    .agg(F.sum('item_quantity').alias('total_quantity')) \\\n",
    "    .orderBy(F.desc('total_quantity')) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7802efc8-2c8a-4aa8-8937-31d964c9fb78",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+\n|item_category|          avg_sale|\n+-------------+------------------+\n|         suit|            2000.0|\n|        jeans|             130.0|\n|        shoes|             120.0|\n|       shorts|             120.0|\n|        shirt|108.57142857142857|\n+-------------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "items_df \\\n",
    "    .groupBy('item_category') \\\n",
    "    .agg((F.sum('total_price') / F.sum('item_quantity')).alias('avg_sale')) \\\n",
    "    .orderBy(F.desc('avg_sale')) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0189c1ef-9cb7-44a5-b3cb-2e749f8ec7b4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "3-2-Tidy-data-nested-schema.ipynb",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
